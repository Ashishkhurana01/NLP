{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP stuff\n"
     ]
    }
   ],
   "source": [
    "print(\"NLP stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    }
   ],
   "source": [
    "print('testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His name is Ashish.\n",
      "His name is Ashish.\n"
     ]
    }
   ],
   "source": [
    "name = 'Ashish'\n",
    "\n",
    "# Using the old .format() method:\n",
    "print('His name is {var}.'.format(var=name))\n",
    "\n",
    "# Using f-strings:\n",
    "print(f'His name is {name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author     Topic    Pages  \n",
      "Twain      Rafting      601\n",
      "Feynman    Physics       95\n",
      "Hamilton   Mythology     144\n"
     ]
    }
   ],
   "source": [
    "library = [('Author', 'Topic', 'Pages'), ('Twain', 'Rafting', 601), ('Feynman', 'Physics', 95), ('Hamilton', 'Mythology', 144)]\n",
    "\n",
    "for book in library:\n",
    "    print(f'{book[0]:{10}} {book[1]:{8}} {book[2]:{7}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author     Topic      ..Pages\n",
      "Twain      Rafting    ....601\n",
      "Feynman    Physics    .....95\n",
      "Hamilton   Mythology  ....144\n"
     ]
    }
   ],
   "source": [
    "for book in library:\n",
    "    print(f'{book[0]:{10}} {book[1]:{10}} {book[2]:.>{7}}') # here .> was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 27, 2018\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime(year=2018, month=1, day=27)\n",
    "\n",
    "print(f'{today:%B %d, %Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.txt\n",
    "Hello, this is a quick test file.\n",
    "This is the second line of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('whoops.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text.txt file we created earlier\n",
    "myfile = open('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='test.txt' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, this is a quick test file.\\nThis is the second line of the file.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now read the file\n",
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seek to the start of file (index 0)\n",
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, this is a quick test file.\\nThis is the second line of the file.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now read again\n",
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, this is a quick test file.\\nThis is the second line of the file.\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, this is a quick test file.\\n',\n",
       " 'This is the second line of the file.\\n']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readlines returns a list of the lines in the file\n",
    "myfile.seek(0)\n",
    "myfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the file first\n",
    "myfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylines = myfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, this is a quick test file.\\n',\n",
       " 'This is the second line of the file.\\n']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, this\n",
      "This is\n"
     ]
    }
   ],
   "source": [
    "for line in mylines:\n",
    "    print(line.split()[0],line.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing again\n"
     ]
    }
   ],
   "source": [
    "print('testing again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('test.txt','w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.write('MY BRAND NEW TEXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MY BRAND NEW TEXT'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('test.txt','a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.write('My first line in a+ opening')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile = open('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MY BRAND NEW TEXTMy first line in a+ opening'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "not writable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-19131e9e3604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'try writing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnsupportedOperation\u001b[0m: not writable"
     ]
    }
   ],
   "source": [
    "newfile.write('try writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('whoops.txt',mode='a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.write('\\nThis is an added line beacuse i used a + mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is an added line beacus ei used a + mode\\nThis is an added line beacuse i used a + mode\\nThis is an added line beacuse i used a + mode'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(myfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto closing\n",
    "with open('whoops.txt','r') as mynewfile:\n",
    "    myvar = mynewfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is an added line beacus ei used a + mode\\n',\n",
       " 'This is an added line beacuse i used a + mode\\n',\n",
       " 'This is an added line beacuse i used a + mode']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('US_Declaration.pdf', mode = 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_Reader = PyPDF2.PdfFileReader(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_Reader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_one = pdf_Reader.getPage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Type': '/Page',\n",
       " '/Parent': {'/Type': '/Pages',\n",
       "  '/Kids': [IndirectObject(4, 0),\n",
       "   IndirectObject(12, 0),\n",
       "   IndirectObject(14, 0),\n",
       "   IndirectObject(16, 0),\n",
       "   IndirectObject(21, 0)],\n",
       "  '/Count': 5},\n",
       " '/Contents': {},\n",
       " '/MediaBox': [0, 0, 612, 792],\n",
       " '/Resources': {'/Font': {'/F9': {'/Type': '/Font',\n",
       "    '/Subtype': '/Type1',\n",
       "    '/Name': '/F9',\n",
       "    '/Encoding': '/WinAnsiEncoding',\n",
       "    '/FirstChar': 31,\n",
       "    '/LastChar': 255,\n",
       "    '/Widths': [778,\n",
       "     250,\n",
       "     333,\n",
       "     555,\n",
       "     500,\n",
       "     500,\n",
       "     1000,\n",
       "     833,\n",
       "     278,\n",
       "     333,\n",
       "     333,\n",
       "     500,\n",
       "     570,\n",
       "     250,\n",
       "     333,\n",
       "     250,\n",
       "     278,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     333,\n",
       "     333,\n",
       "     570,\n",
       "     570,\n",
       "     570,\n",
       "     500,\n",
       "     930,\n",
       "     722,\n",
       "     667,\n",
       "     722,\n",
       "     722,\n",
       "     667,\n",
       "     611,\n",
       "     778,\n",
       "     778,\n",
       "     389,\n",
       "     500,\n",
       "     778,\n",
       "     667,\n",
       "     944,\n",
       "     722,\n",
       "     778,\n",
       "     611,\n",
       "     778,\n",
       "     722,\n",
       "     556,\n",
       "     667,\n",
       "     722,\n",
       "     722,\n",
       "     1000,\n",
       "     722,\n",
       "     722,\n",
       "     667,\n",
       "     333,\n",
       "     278,\n",
       "     333,\n",
       "     581,\n",
       "     500,\n",
       "     333,\n",
       "     500,\n",
       "     556,\n",
       "     444,\n",
       "     556,\n",
       "     444,\n",
       "     333,\n",
       "     500,\n",
       "     556,\n",
       "     278,\n",
       "     333,\n",
       "     556,\n",
       "     278,\n",
       "     833,\n",
       "     556,\n",
       "     500,\n",
       "     556,\n",
       "     556,\n",
       "     444,\n",
       "     389,\n",
       "     333,\n",
       "     556,\n",
       "     500,\n",
       "     722,\n",
       "     500,\n",
       "     500,\n",
       "     444,\n",
       "     394,\n",
       "     220,\n",
       "     394,\n",
       "     520,\n",
       "     778,\n",
       "     500,\n",
       "     778,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     500,\n",
       "     333,\n",
       "     1000,\n",
       "     556,\n",
       "     333,\n",
       "     1000,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     333,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     350,\n",
       "     500,\n",
       "     1000,\n",
       "     333,\n",
       "     1000,\n",
       "     389,\n",
       "     333,\n",
       "     722,\n",
       "     778,\n",
       "     778,\n",
       "     722,\n",
       "     250,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     220,\n",
       "     500,\n",
       "     333,\n",
       "     747,\n",
       "     300,\n",
       "     500,\n",
       "     570,\n",
       "     333,\n",
       "     747,\n",
       "     500,\n",
       "     400,\n",
       "     549,\n",
       "     300,\n",
       "     300,\n",
       "     333,\n",
       "     576,\n",
       "     540,\n",
       "     250,\n",
       "     333,\n",
       "     300,\n",
       "     330,\n",
       "     500,\n",
       "     750,\n",
       "     750,\n",
       "     750,\n",
       "     500,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     1000,\n",
       "     722,\n",
       "     667,\n",
       "     667,\n",
       "     667,\n",
       "     667,\n",
       "     389,\n",
       "     389,\n",
       "     389,\n",
       "     389,\n",
       "     722,\n",
       "     722,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     570,\n",
       "     778,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     611,\n",
       "     556,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     722,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     278,\n",
       "     278,\n",
       "     278,\n",
       "     278,\n",
       "     500,\n",
       "     556,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     549,\n",
       "     500,\n",
       "     556,\n",
       "     556,\n",
       "     556,\n",
       "     556,\n",
       "     500,\n",
       "     556,\n",
       "     500],\n",
       "    '/BaseFont': '/TimesNewRomanPS-BoldMT',\n",
       "    '/FontDescriptor': {'/Type': '/FontDescriptor',\n",
       "     '/FontName': '/TimesNewRomanPS-BoldMT',\n",
       "     '/Ascent': 677,\n",
       "     '/CapHeight': 500,\n",
       "     '/Descent': -216,\n",
       "     '/Flags': 34,\n",
       "     '/FontBBox': [-558, -307, 2034, 1026],\n",
       "     '/ItalicAngle': 0,\n",
       "     '/StemV': 0,\n",
       "     '/AvgWidth': 427,\n",
       "     '/Leading': 150,\n",
       "     '/MaxWidth': 2592,\n",
       "     '/XHeight': 250,\n",
       "     '/FontFile': {'/Filter': ['/ASCII85Decode'],\n",
       "      '/Length1': 4690,\n",
       "      '/Length2': 46374,\n",
       "      '/Length3': 532}}},\n",
       "   '/F6': {'/Type': '/Font',\n",
       "    '/Subtype': '/Type1',\n",
       "    '/Name': '/F6',\n",
       "    '/Encoding': '/WinAnsiEncoding',\n",
       "    '/FirstChar': 31,\n",
       "    '/LastChar': 255,\n",
       "    '/Widths': [778,\n",
       "     250,\n",
       "     333,\n",
       "     408,\n",
       "     500,\n",
       "     500,\n",
       "     833,\n",
       "     778,\n",
       "     180,\n",
       "     333,\n",
       "     333,\n",
       "     500,\n",
       "     564,\n",
       "     250,\n",
       "     333,\n",
       "     250,\n",
       "     278,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     278,\n",
       "     278,\n",
       "     564,\n",
       "     564,\n",
       "     564,\n",
       "     444,\n",
       "     921,\n",
       "     722,\n",
       "     667,\n",
       "     667,\n",
       "     722,\n",
       "     611,\n",
       "     556,\n",
       "     722,\n",
       "     722,\n",
       "     333,\n",
       "     389,\n",
       "     722,\n",
       "     611,\n",
       "     889,\n",
       "     722,\n",
       "     722,\n",
       "     556,\n",
       "     722,\n",
       "     667,\n",
       "     556,\n",
       "     611,\n",
       "     722,\n",
       "     722,\n",
       "     944,\n",
       "     722,\n",
       "     722,\n",
       "     611,\n",
       "     333,\n",
       "     278,\n",
       "     333,\n",
       "     469,\n",
       "     500,\n",
       "     333,\n",
       "     444,\n",
       "     500,\n",
       "     444,\n",
       "     500,\n",
       "     444,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     278,\n",
       "     278,\n",
       "     500,\n",
       "     278,\n",
       "     778,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     333,\n",
       "     389,\n",
       "     278,\n",
       "     500,\n",
       "     500,\n",
       "     722,\n",
       "     500,\n",
       "     500,\n",
       "     444,\n",
       "     480,\n",
       "     200,\n",
       "     480,\n",
       "     541,\n",
       "     778,\n",
       "     500,\n",
       "     778,\n",
       "     333,\n",
       "     500,\n",
       "     444,\n",
       "     1000,\n",
       "     500,\n",
       "     500,\n",
       "     333,\n",
       "     1000,\n",
       "     556,\n",
       "     333,\n",
       "     889,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     333,\n",
       "     333,\n",
       "     444,\n",
       "     444,\n",
       "     350,\n",
       "     500,\n",
       "     1000,\n",
       "     333,\n",
       "     980,\n",
       "     389,\n",
       "     333,\n",
       "     722,\n",
       "     778,\n",
       "     778,\n",
       "     722,\n",
       "     250,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     200,\n",
       "     500,\n",
       "     333,\n",
       "     760,\n",
       "     276,\n",
       "     500,\n",
       "     564,\n",
       "     333,\n",
       "     760,\n",
       "     500,\n",
       "     400,\n",
       "     549,\n",
       "     300,\n",
       "     300,\n",
       "     333,\n",
       "     576,\n",
       "     453,\n",
       "     250,\n",
       "     333,\n",
       "     300,\n",
       "     310,\n",
       "     500,\n",
       "     750,\n",
       "     750,\n",
       "     750,\n",
       "     444,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     889,\n",
       "     667,\n",
       "     611,\n",
       "     611,\n",
       "     611,\n",
       "     611,\n",
       "     333,\n",
       "     333,\n",
       "     333,\n",
       "     333,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     564,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     556,\n",
       "     500,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     667,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     278,\n",
       "     278,\n",
       "     278,\n",
       "     278,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     549,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500],\n",
       "    '/BaseFont': '/TimesNewRomanPSMT',\n",
       "    '/FontDescriptor': {'/Type': '/FontDescriptor',\n",
       "     '/FontName': '/TimesNewRomanPSMT',\n",
       "     '/Ascent': 693,\n",
       "     '/CapHeight': 500,\n",
       "     '/Descent': -216,\n",
       "     '/Flags': 34,\n",
       "     '/FontBBox': [-568, -307, 2028, 1007],\n",
       "     '/ItalicAngle': 0,\n",
       "     '/StemV': 0,\n",
       "     '/AvgWidth': 401,\n",
       "     '/Leading': 150,\n",
       "     '/MaxWidth': 2597,\n",
       "     '/XHeight': 250,\n",
       "     '/FontFile': {'/Filter': ['/ASCII85Decode'],\n",
       "      '/Length1': 4680,\n",
       "      '/Length2': 46205,\n",
       "      '/Length3': 532}}}},\n",
       "  '/ProcSet': ['/PDF', '/Text']}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext=page_one.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Declaration of IndependenceIN CONGRESS, July 4, 1776. The unanimous Declaration of the thirteen united States of America, When in the Course of human events, it becomes necessary for one people to dissolve the\\npolitical bands which have connected them with another, and to assume among the powers of the\\nearth, the separate and equal station to which the Laws of Nature and of Nature's God entitle\\n\\nthem, a decent respect to the opinions of mankind requires that they should declare the causes\\n\\nwhich impel them to the separation. \\nWe hold these truths to be self-evident, that all men are created equal, that they are endowed by\\n\\ntheir Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit\\nof Happiness.ŠThat to secure these rights, Governments are instituted among Men, deriving\\n\\ntheir just powers from the consent of the governed,ŠThat whenever any Form of Government\\nbecomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to\\ninstitute new Government, laying its foundation on such principles and organizing its powers in\\nsuch form, as to them shall seem most likely to effect their Safety and Happiness. Prudence,\\n\\nindeed, will dictate that Governments long established should not be changed for light and\\ntransient causes; and accordingly all experience hath shewn, that mankind are more disposed to\\nsuffer, while evils are sufferable, than to right themselves by abolishing the forms to which they\\n\\nare accustomed. But when a long train of abuses and usurpations, pursuing invariably the same\\nObject evinces a design to reduce them under absolute Despotism, it is their right, it is their duty,\\nto throw off such Government, and to provide new Guards for their future security.ŠSuch has\\nbeen the patient sufferance of these Colonies; and such is now the necessity which constrains\\n\\nthem to alter their former Systems of Government. The history of the present King of Great\\n\\nBritain is a history of repeated injuries and usurpations, all having in direct object the\\nestablishment of an absolute Tyranny over these States. To prove this, let Facts be submitted to a\\ncandid world. He has refused his Assent to Laws, the most wholesome and necessary for the\\npublic good.\\nHe has forbidden his Governors to pass Laws of immediate and pressing\\nimportance, unless suspended in their operation till his Assent should be obtained;\\nand when so suspended, he has utterly neglected to attend to them.\\n\\nHe has refused to pass other Laws for the accommodation of large districts of\\npeople, unless those people would relinquish the right of Representation in the\\nLegislature, a right inestimable to them and formidable to tyrants only. \\n\\nHe has called together legislative bodies at places unusual, uncomfortable, and distant\\nfrom the depository of their public Records, for the sole purpose of fatiguing them into\\ncompliance with his measures.\\n\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('US_Declaration.pdf', mode='rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='US_Declaration.pdf'>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfreader = PyPDF2.PdfFileReader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyPDF2.pdf.PdfFileReader at 0x1ea6c3afd08>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfreader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_page = pdfreader.getPage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Type': '/Page',\n",
       " '/Parent': {'/Type': '/Pages',\n",
       "  '/Kids': [IndirectObject(4, 0),\n",
       "   IndirectObject(12, 0),\n",
       "   IndirectObject(14, 0),\n",
       "   IndirectObject(16, 0),\n",
       "   IndirectObject(21, 0)],\n",
       "  '/Count': 5},\n",
       " '/Contents': {},\n",
       " '/MediaBox': [0, 0, 612, 792],\n",
       " '/Resources': {'/Font': {'/F9': {'/Type': '/Font',\n",
       "    '/Subtype': '/Type1',\n",
       "    '/Name': '/F9',\n",
       "    '/Encoding': '/WinAnsiEncoding',\n",
       "    '/FirstChar': 31,\n",
       "    '/LastChar': 255,\n",
       "    '/Widths': [778,\n",
       "     250,\n",
       "     333,\n",
       "     555,\n",
       "     500,\n",
       "     500,\n",
       "     1000,\n",
       "     833,\n",
       "     278,\n",
       "     333,\n",
       "     333,\n",
       "     500,\n",
       "     570,\n",
       "     250,\n",
       "     333,\n",
       "     250,\n",
       "     278,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     333,\n",
       "     333,\n",
       "     570,\n",
       "     570,\n",
       "     570,\n",
       "     500,\n",
       "     930,\n",
       "     722,\n",
       "     667,\n",
       "     722,\n",
       "     722,\n",
       "     667,\n",
       "     611,\n",
       "     778,\n",
       "     778,\n",
       "     389,\n",
       "     500,\n",
       "     778,\n",
       "     667,\n",
       "     944,\n",
       "     722,\n",
       "     778,\n",
       "     611,\n",
       "     778,\n",
       "     722,\n",
       "     556,\n",
       "     667,\n",
       "     722,\n",
       "     722,\n",
       "     1000,\n",
       "     722,\n",
       "     722,\n",
       "     667,\n",
       "     333,\n",
       "     278,\n",
       "     333,\n",
       "     581,\n",
       "     500,\n",
       "     333,\n",
       "     500,\n",
       "     556,\n",
       "     444,\n",
       "     556,\n",
       "     444,\n",
       "     333,\n",
       "     500,\n",
       "     556,\n",
       "     278,\n",
       "     333,\n",
       "     556,\n",
       "     278,\n",
       "     833,\n",
       "     556,\n",
       "     500,\n",
       "     556,\n",
       "     556,\n",
       "     444,\n",
       "     389,\n",
       "     333,\n",
       "     556,\n",
       "     500,\n",
       "     722,\n",
       "     500,\n",
       "     500,\n",
       "     444,\n",
       "     394,\n",
       "     220,\n",
       "     394,\n",
       "     520,\n",
       "     778,\n",
       "     500,\n",
       "     778,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     500,\n",
       "     333,\n",
       "     1000,\n",
       "     556,\n",
       "     333,\n",
       "     1000,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     333,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     350,\n",
       "     500,\n",
       "     1000,\n",
       "     333,\n",
       "     1000,\n",
       "     389,\n",
       "     333,\n",
       "     722,\n",
       "     778,\n",
       "     778,\n",
       "     722,\n",
       "     250,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     220,\n",
       "     500,\n",
       "     333,\n",
       "     747,\n",
       "     300,\n",
       "     500,\n",
       "     570,\n",
       "     333,\n",
       "     747,\n",
       "     500,\n",
       "     400,\n",
       "     549,\n",
       "     300,\n",
       "     300,\n",
       "     333,\n",
       "     576,\n",
       "     540,\n",
       "     250,\n",
       "     333,\n",
       "     300,\n",
       "     330,\n",
       "     500,\n",
       "     750,\n",
       "     750,\n",
       "     750,\n",
       "     500,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     1000,\n",
       "     722,\n",
       "     667,\n",
       "     667,\n",
       "     667,\n",
       "     667,\n",
       "     389,\n",
       "     389,\n",
       "     389,\n",
       "     389,\n",
       "     722,\n",
       "     722,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     570,\n",
       "     778,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     611,\n",
       "     556,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     722,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     278,\n",
       "     278,\n",
       "     278,\n",
       "     278,\n",
       "     500,\n",
       "     556,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     549,\n",
       "     500,\n",
       "     556,\n",
       "     556,\n",
       "     556,\n",
       "     556,\n",
       "     500,\n",
       "     556,\n",
       "     500],\n",
       "    '/BaseFont': '/TimesNewRomanPS-BoldMT',\n",
       "    '/FontDescriptor': {'/Type': '/FontDescriptor',\n",
       "     '/FontName': '/TimesNewRomanPS-BoldMT',\n",
       "     '/Ascent': 677,\n",
       "     '/CapHeight': 500,\n",
       "     '/Descent': -216,\n",
       "     '/Flags': 34,\n",
       "     '/FontBBox': [-558, -307, 2034, 1026],\n",
       "     '/ItalicAngle': 0,\n",
       "     '/StemV': 0,\n",
       "     '/AvgWidth': 427,\n",
       "     '/Leading': 150,\n",
       "     '/MaxWidth': 2592,\n",
       "     '/XHeight': 250,\n",
       "     '/FontFile': {'/Filter': ['/ASCII85Decode'],\n",
       "      '/Length1': 4690,\n",
       "      '/Length2': 46374,\n",
       "      '/Length3': 532}}},\n",
       "   '/F6': {'/Type': '/Font',\n",
       "    '/Subtype': '/Type1',\n",
       "    '/Name': '/F6',\n",
       "    '/Encoding': '/WinAnsiEncoding',\n",
       "    '/FirstChar': 31,\n",
       "    '/LastChar': 255,\n",
       "    '/Widths': [778,\n",
       "     250,\n",
       "     333,\n",
       "     408,\n",
       "     500,\n",
       "     500,\n",
       "     833,\n",
       "     778,\n",
       "     180,\n",
       "     333,\n",
       "     333,\n",
       "     500,\n",
       "     564,\n",
       "     250,\n",
       "     333,\n",
       "     250,\n",
       "     278,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     278,\n",
       "     278,\n",
       "     564,\n",
       "     564,\n",
       "     564,\n",
       "     444,\n",
       "     921,\n",
       "     722,\n",
       "     667,\n",
       "     667,\n",
       "     722,\n",
       "     611,\n",
       "     556,\n",
       "     722,\n",
       "     722,\n",
       "     333,\n",
       "     389,\n",
       "     722,\n",
       "     611,\n",
       "     889,\n",
       "     722,\n",
       "     722,\n",
       "     556,\n",
       "     722,\n",
       "     667,\n",
       "     556,\n",
       "     611,\n",
       "     722,\n",
       "     722,\n",
       "     944,\n",
       "     722,\n",
       "     722,\n",
       "     611,\n",
       "     333,\n",
       "     278,\n",
       "     333,\n",
       "     469,\n",
       "     500,\n",
       "     333,\n",
       "     444,\n",
       "     500,\n",
       "     444,\n",
       "     500,\n",
       "     444,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     278,\n",
       "     278,\n",
       "     500,\n",
       "     278,\n",
       "     778,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     333,\n",
       "     389,\n",
       "     278,\n",
       "     500,\n",
       "     500,\n",
       "     722,\n",
       "     500,\n",
       "     500,\n",
       "     444,\n",
       "     480,\n",
       "     200,\n",
       "     480,\n",
       "     541,\n",
       "     778,\n",
       "     500,\n",
       "     778,\n",
       "     333,\n",
       "     500,\n",
       "     444,\n",
       "     1000,\n",
       "     500,\n",
       "     500,\n",
       "     333,\n",
       "     1000,\n",
       "     556,\n",
       "     333,\n",
       "     889,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     778,\n",
       "     333,\n",
       "     333,\n",
       "     444,\n",
       "     444,\n",
       "     350,\n",
       "     500,\n",
       "     1000,\n",
       "     333,\n",
       "     980,\n",
       "     389,\n",
       "     333,\n",
       "     722,\n",
       "     778,\n",
       "     778,\n",
       "     722,\n",
       "     250,\n",
       "     333,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     200,\n",
       "     500,\n",
       "     333,\n",
       "     760,\n",
       "     276,\n",
       "     500,\n",
       "     564,\n",
       "     333,\n",
       "     760,\n",
       "     500,\n",
       "     400,\n",
       "     549,\n",
       "     300,\n",
       "     300,\n",
       "     333,\n",
       "     576,\n",
       "     453,\n",
       "     250,\n",
       "     333,\n",
       "     300,\n",
       "     310,\n",
       "     500,\n",
       "     750,\n",
       "     750,\n",
       "     750,\n",
       "     444,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     889,\n",
       "     667,\n",
       "     611,\n",
       "     611,\n",
       "     611,\n",
       "     611,\n",
       "     333,\n",
       "     333,\n",
       "     333,\n",
       "     333,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     564,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     722,\n",
       "     556,\n",
       "     500,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     667,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     444,\n",
       "     278,\n",
       "     278,\n",
       "     278,\n",
       "     278,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     549,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500,\n",
       "     500],\n",
       "    '/BaseFont': '/TimesNewRomanPSMT',\n",
       "    '/FontDescriptor': {'/Type': '/FontDescriptor',\n",
       "     '/FontName': '/TimesNewRomanPSMT',\n",
       "     '/Ascent': 693,\n",
       "     '/CapHeight': 500,\n",
       "     '/Descent': -216,\n",
       "     '/Flags': 34,\n",
       "     '/FontBBox': [-568, -307, 2028, 1007],\n",
       "     '/ItalicAngle': 0,\n",
       "     '/StemV': 0,\n",
       "     '/AvgWidth': 401,\n",
       "     '/Leading': 150,\n",
       "     '/MaxWidth': 2597,\n",
       "     '/XHeight': 250,\n",
       "     '/FontFile': {'/Filter': ['/ASCII85Decode'],\n",
       "      '/Length1': 4680,\n",
       "      '/Length2': 46205,\n",
       "      '/Length3': 532}}}},\n",
       "  '/ProcSet': ['/PDF', '/Text']}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfwriter = PyPDF2.PdfFileWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfwriter.addPage(first_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyPDF2.pdf.PdfFileWriter at 0x1ea6c3b3788>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_output = open('My_brand_new_file.pdf','wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfwriter.write(pdf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_new = open('My_brand_new_file.pdf',mode='rb')\n",
    "\n",
    "pdf_Reader = PyPDF2.PdfFileReader(brand_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_Reader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('US_Declaration.pdf',mode='rb')\n",
    "\n",
    "pdf_text = []\n",
    "\n",
    "pdf_reader = PyPDF2.PdfFileReader(f)\n",
    "\n",
    "for p in range(pdf_reader.numPages):\n",
    "    page = pdf_reader.getPage(p)\n",
    "    pdf_text.append(page.extractText())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Declaration of IndependenceIN CONGRESS, July 4, 1776. The unanimous Declaration of the thirteen united States of America, When in the Course of human events, it becomes necessary for one people to dissolve the\\npolitical bands which have connected them with another, and to assume among the powers of the\\nearth, the separate and equal station to which the Laws of Nature and of Nature's God entitle\\n\\nthem, a decent respect to the opinions of mankind requires that they should declare the causes\\n\\nwhich impel them to the separation. \\nWe hold these truths to be self-evident, that all men are created equal, that they are endowed by\\n\\ntheir Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit\\nof Happiness.ŠThat to secure these rights, Governments are instituted among Men, deriving\\n\\ntheir just powers from the consent of the governed,ŠThat whenever any Form of Government\\nbecomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to\\ninstitute new Government, laying its foundation on such principles and organizing its powers in\\nsuch form, as to them shall seem most likely to effect their Safety and Happiness. Prudence,\\n\\nindeed, will dictate that Governments long established should not be changed for light and\\ntransient causes; and accordingly all experience hath shewn, that mankind are more disposed to\\nsuffer, while evils are sufferable, than to right themselves by abolishing the forms to which they\\n\\nare accustomed. But when a long train of abuses and usurpations, pursuing invariably the same\\nObject evinces a design to reduce them under absolute Despotism, it is their right, it is their duty,\\nto throw off such Government, and to provide new Guards for their future security.ŠSuch has\\nbeen the patient sufferance of these Colonies; and such is now the necessity which constrains\\n\\nthem to alter their former Systems of Government. The history of the present King of Great\\n\\nBritain is a history of repeated injuries and usurpations, all having in direct object the\\nestablishment of an absolute Tyranny over these States. To prove this, let Facts be submitted to a\\ncandid world. He has refused his Assent to Laws, the most wholesome and necessary for the\\npublic good.\\nHe has forbidden his Governors to pass Laws of immediate and pressing\\nimportance, unless suspended in their operation till his Assent should be obtained;\\nand when so suspended, he has utterly neglected to attend to them.\\n\\nHe has refused to pass other Laws for the accommodation of large districts of\\npeople, unless those people would relinquish the right of Representation in the\\nLegislature, a right inestimable to them and formidable to tyrants only. \\n\\nHe has called together legislative bodies at places unusual, uncomfortable, and distant\\nfrom the depository of their public Records, for the sole purpose of fatiguing them into\\ncompliance with his measures.\\n\",\n",
       " 'He has dissolved Representative Houses repeatedly, for opposing with manlyfirmness his invasions on the rights of the people.He has refused for a long time, after such dissolutions, to cause others to beelected; whereby the Legislative powers, incapable of Annihilation, have returnedto the People at large for their exercise; the State remaining in the mean timeexposed to all the dangers of invasion from without, and convulsions within.He has endeavoured to prevent the population of these States; for that purposeobstructing the Laws for Naturalization of Foreigners; refusing to pass others toencourage their migrations hither, and raising the conditions of newAppropriations of Lands.He has obstructed the Administration of Justice, by refusing his Assent to Lawsfor establishing Judiciary powers.He has made Judges dependent on his Will alone, for the tenure of their offices,and the amount and payment of their salaries.He has erected a multitude of New Offices, and sent hither swarms of Officers toharrass our people, and eat out their substance.He has kept among us, in times of peace, Standing Armies without the Consent ofour legislatures.He has affected to render the Military independent of and superior to the Civil power.He has combined with others to subject us to a jurisdiction foreign to ourconstitution, and unacknowledged by our laws; giving his Assent to their Acts ofpretended Legislation:For Quartering large bodies of armed troops among us:For protecting them, by a mock Trial, from punishment for any Murders whichthey should commit on the Inhabitants of these States:For cutting off our Trade with all parts of the world:For imposing Taxes on us without our Consent: For depriving us in many cases,of the benefits of Trial by Jury:For transporting us beyond Seas to be tried for pretended offencesFor abolishing the free System of English Laws in a neighbouring Province,establishing therein an Arbitrary government, and enlarging its Boundaries so as',\n",
       " 'to render it at once an example and fit instrument for introducing the sameabsolute rule into these Colonies:For taking away our Charters, abolishing our most valuable Laws, and alteringfundamentally the Forms of our Governments:For suspending our own Legislatures, and declaring themselves invested withpower to legislate for us in all cases whatsoever.He has abdicated Government here, by declaring us out of his Protection andwaging War against us.He has plundered our seas, ravaged our Coasts, burnt our towns, and destroyed thelives of our people.He is at this time transporting large Armies of foreign Mercenaries to compleatthe works of death, desolation and tyranny, already begun with circumstances ofCruelty & perfidy scarcely paralleled in the most barbarous ages, and totallyunworthy of the Head of a civilized nation.He has constrained our fellow Citizens taken Captive on the high Seas to bearArms against their Country, to become the executioners of their friends and\\nBrethren, or to fall themselves by their Hands.He has excited domestic insurrections amongst us, and has endeavoured to bringon the inhabitants of our frontiers, the merciless Indian Savages, whose known\\nrule of warfare, is an undistinguished destruction of all ages, sexes and conditions. In every stage of these Oppressions We have Petitioned for Redress in the most humble terms:Our repeated Petitions have been answered only by repeated injury. A Prince whose character isthus marked by every act which may define a Tyrant, is unfit to be the ruler of a free people. Nor have We been wanting in attentions to our Brittish brethren. We have warned them fromtime to time of attempts by their legislature to extend an unwarrantable jurisdiction over us. Wehave reminded them of the circumstances of our emigration and settlement here. We haveappealed to their native justice and magnanimity, and we have conjured them by the ties of ourcommon kindred to disavow these usurpations, which, would inevitably interrupt ourconnections and correspondence. They too have been deaf to the voice of justice and ofconsanguinity. We must, therefore, acquiesce in the necessity, which denounces our Separation,and hold them, as we hold the rest of mankind, Enemies in War, in Peace Friends. We, therefore, the Representatives of the united States of America, in General Congress,Assembled, appealing to the Supreme Judge of the world for the rectitude of our intentions, do,in the Name, and by Authority of the good People of these Colonies, solemnly publish anddeclare, That these United Colonies are, and of Right ought to be Free and Independent States;that they are Absolved from all Allegiance to the British Crown, and that all political connection',\n",
       " 'between them and the State of Great Britain, is and ought to be totally dissolved; and that as Free\\n\\nand Independent States, they have full Power to levy War, conclude Peace, contract Alliances,\\nestablish Commerce, and to do all other Acts and Things which Independent States may of right\\n\\ndo. And for the support of this Declaration, with a firm reliance on the protection of divine\\nProvidence, we mutually pledge to each other our Lives, our Fortunes and our sacred Honor.\\n\\n[The 56 signatures on the Declaration were arranged in six columns:\\n] [Column 1]\\n Georgia:   Button Gwinnett\\n   Lyman \\nHall   George Walton \\n[Column 2]\\n North Carolina:   William Hooper\\n   Joseph Hewes\\n   John Penn\\n South Carolina:   Edward Ru\\ntledge   Thomas Heyward, Jr.\\n  Thomas Lynch, Jr.\\n  Arthur Middleton \\n[Column 3]\\n Massachusetts:   John Hancock\\n\\n Maryland:   Samuel Chase\\n\\n   William Paca\\n\\n   Thomas Stone\\n\\n   Charles Carroll of Carrollton\\n\\n Virginia:   George Wythe\\n\\n   Richard Henry Lee\\n\\n   Thomas Jefferson\\n\\n   Benjamin Harrison\\n\\n   Thomas Nelson, Jr.\\n\\n   Francis Lightfoot Lee\\n\\n   Carter Braxton \\n\\n[Column 4]\\n Pennsylvania:  Robert Morris\\n\\n   Benjamin Rush\\n   Benjamin Fran\\nklin   John Morton\\n',\n",
       " '   George Clymer\\n   James Smith\\n   George Taylor\\n   James Wilson\\n   George Ross\\n Delaware:   Caesar Rodney\\n   George Read\\n   Thomas McKean \\n[Column 5]\\n New York:   Wi\\nlliam Floyd   Philip Livingston\\n   Francis L\\newis   Lewis Morris\\n New Jersey:   Richard Stockton\\n   John Witherspoon\\n   Francis Hopkinson\\n   John Hart\\n   Abraham Clark \\n[Column 6]\\n New Hampshire:   Josiah Bartlett\\n   William Whipple\\n Massachusetts:   Samuel Adams\\n   John Adams\\n   Robert Treat Paine\\n   Elbridge Gerry\\n Rhode Island:   Stephen Hopkins\\n   William Ellery\\n Connecticut:   Roger Sherman\\n   Samuel Huntington\\n   William Williams\\n   Oliver Wolcott\\n New Hampshire: Matthew Thornton\\n ']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declaration of IndependenceIN CONGRESS, July 4, 1776. The unanimous Declaration of the thirteen united States of America, When in the Course of human events, it becomes necessary for one people to dissolve the\n",
      "political bands which have connected them with another, and to assume among the powers of the\n",
      "earth, the separate and equal station to which the Laws of Nature and of Nature's God entitle\n",
      "\n",
      "them, a decent respect to the opinions of mankind requires that they should declare the causes\n",
      "\n",
      "which impel them to the separation. \n",
      "We hold these truths to be self-evident, that all men are created equal, that they are endowed by\n",
      "\n",
      "their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit\n",
      "of Happiness.ŠThat to secure these rights, Governments are instituted among Men, deriving\n",
      "\n",
      "their just powers from the consent of the governed,ŠThat whenever any Form of Government\n",
      "becomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to\n",
      "institute new Government, laying its foundation on such principles and organizing its powers in\n",
      "such form, as to them shall seem most likely to effect their Safety and Happiness. Prudence,\n",
      "\n",
      "indeed, will dictate that Governments long established should not be changed for light and\n",
      "transient causes; and accordingly all experience hath shewn, that mankind are more disposed to\n",
      "suffer, while evils are sufferable, than to right themselves by abolishing the forms to which they\n",
      "\n",
      "are accustomed. But when a long train of abuses and usurpations, pursuing invariably the same\n",
      "Object evinces a design to reduce them under absolute Despotism, it is their right, it is their duty,\n",
      "to throw off such Government, and to provide new Guards for their future security.ŠSuch has\n",
      "been the patient sufferance of these Colonies; and such is now the necessity which constrains\n",
      "\n",
      "them to alter their former Systems of Government. The history of the present King of Great\n",
      "\n",
      "Britain is a history of repeated injuries and usurpations, all having in direct object the\n",
      "establishment of an absolute Tyranny over these States. To prove this, let Facts be submitted to a\n",
      "candid world. He has refused his Assent to Laws, the most wholesome and necessary for the\n",
      "public good.\n",
      "He has forbidden his Governors to pass Laws of immediate and pressing\n",
      "importance, unless suspended in their operation till his Assent should be obtained;\n",
      "and when so suspended, he has utterly neglected to attend to them.\n",
      "\n",
      "He has refused to pass other Laws for the accommodation of large districts of\n",
      "people, unless those people would relinquish the right of Representation in the\n",
      "Legislature, a right inestimable to them and formidable to tyrants only. \n",
      "\n",
      "He has called together legislative bodies at places unusual, uncomfortable, and distant\n",
      "from the depository of their public Records, for the sole purpose of fatiguing them into\n",
      "compliance with his measures.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "He has dissolved Representative Houses repeatedly, for opposing with manlyfirmness his invasions on the rights of the people.He has refused for a long time, after such dissolutions, to cause others to beelected; whereby the Legislative powers, incapable of Annihilation, have returnedto the People at large for their exercise; the State remaining in the mean timeexposed to all the dangers of invasion from without, and convulsions within.He has endeavoured to prevent the population of these States; for that purposeobstructing the Laws for Naturalization of Foreigners; refusing to pass others toencourage their migrations hither, and raising the conditions of newAppropriations of Lands.He has obstructed the Administration of Justice, by refusing his Assent to Lawsfor establishing Judiciary powers.He has made Judges dependent on his Will alone, for the tenure of their offices,and the amount and payment of their salaries.He has erected a multitude of New Offices, and sent hither swarms of Officers toharrass our people, and eat out their substance.He has kept among us, in times of peace, Standing Armies without the Consent ofour legislatures.He has affected to render the Military independent of and superior to the Civil power.He has combined with others to subject us to a jurisdiction foreign to ourconstitution, and unacknowledged by our laws; giving his Assent to their Acts ofpretended Legislation:For Quartering large bodies of armed troops among us:For protecting them, by a mock Trial, from punishment for any Murders whichthey should commit on the Inhabitants of these States:For cutting off our Trade with all parts of the world:For imposing Taxes on us without our Consent: For depriving us in many cases,of the benefits of Trial by Jury:For transporting us beyond Seas to be tried for pretended offencesFor abolishing the free System of English Laws in a neighbouring Province,establishing therein an Arbitrary government, and enlarging its Boundaries so as\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "to render it at once an example and fit instrument for introducing the sameabsolute rule into these Colonies:For taking away our Charters, abolishing our most valuable Laws, and alteringfundamentally the Forms of our Governments:For suspending our own Legislatures, and declaring themselves invested withpower to legislate for us in all cases whatsoever.He has abdicated Government here, by declaring us out of his Protection andwaging War against us.He has plundered our seas, ravaged our Coasts, burnt our towns, and destroyed thelives of our people.He is at this time transporting large Armies of foreign Mercenaries to compleatthe works of death, desolation and tyranny, already begun with circumstances ofCruelty & perfidy scarcely paralleled in the most barbarous ages, and totallyunworthy of the Head of a civilized nation.He has constrained our fellow Citizens taken Captive on the high Seas to bearArms against their Country, to become the executioners of their friends and\n",
      "Brethren, or to fall themselves by their Hands.He has excited domestic insurrections amongst us, and has endeavoured to bringon the inhabitants of our frontiers, the merciless Indian Savages, whose known\n",
      "rule of warfare, is an undistinguished destruction of all ages, sexes and conditions. In every stage of these Oppressions We have Petitioned for Redress in the most humble terms:Our repeated Petitions have been answered only by repeated injury. A Prince whose character isthus marked by every act which may define a Tyrant, is unfit to be the ruler of a free people. Nor have We been wanting in attentions to our Brittish brethren. We have warned them fromtime to time of attempts by their legislature to extend an unwarrantable jurisdiction over us. Wehave reminded them of the circumstances of our emigration and settlement here. We haveappealed to their native justice and magnanimity, and we have conjured them by the ties of ourcommon kindred to disavow these usurpations, which, would inevitably interrupt ourconnections and correspondence. They too have been deaf to the voice of justice and ofconsanguinity. We must, therefore, acquiesce in the necessity, which denounces our Separation,and hold them, as we hold the rest of mankind, Enemies in War, in Peace Friends. We, therefore, the Representatives of the united States of America, in General Congress,Assembled, appealing to the Supreme Judge of the world for the rectitude of our intentions, do,in the Name, and by Authority of the good People of these Colonies, solemnly publish anddeclare, That these United Colonies are, and of Right ought to be Free and Independent States;that they are Absolved from all Allegiance to the British Crown, and that all political connection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "between them and the State of Great Britain, is and ought to be totally dissolved; and that as Free\n",
      "\n",
      "and Independent States, they have full Power to levy War, conclude Peace, contract Alliances,\n",
      "establish Commerce, and to do all other Acts and Things which Independent States may of right\n",
      "\n",
      "do. And for the support of this Declaration, with a firm reliance on the protection of divine\n",
      "Providence, we mutually pledge to each other our Lives, our Fortunes and our sacred Honor.\n",
      "\n",
      "[The 56 signatures on the Declaration were arranged in six columns:\n",
      "] [Column 1]\n",
      " Georgia:   Button Gwinnett\n",
      "   Lyman \n",
      "Hall   George Walton \n",
      "[Column 2]\n",
      " North Carolina:   William Hooper\n",
      "   Joseph Hewes\n",
      "   John Penn\n",
      " South Carolina:   Edward Ru\n",
      "tledge   Thomas Heyward, Jr.\n",
      "  Thomas Lynch, Jr.\n",
      "  Arthur Middleton \n",
      "[Column 3]\n",
      " Massachusetts:   John Hancock\n",
      "\n",
      " Maryland:   Samuel Chase\n",
      "\n",
      "   William Paca\n",
      "\n",
      "   Thomas Stone\n",
      "\n",
      "   Charles Carroll of Carrollton\n",
      "\n",
      " Virginia:   George Wythe\n",
      "\n",
      "   Richard Henry Lee\n",
      "\n",
      "   Thomas Jefferson\n",
      "\n",
      "   Benjamin Harrison\n",
      "\n",
      "   Thomas Nelson, Jr.\n",
      "\n",
      "   Francis Lightfoot Lee\n",
      "\n",
      "   Carter Braxton \n",
      "\n",
      "[Column 4]\n",
      " Pennsylvania:  Robert Morris\n",
      "\n",
      "   Benjamin Rush\n",
      "   Benjamin Fran\n",
      "klin   John Morton\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   George Clymer\n",
      "   James Smith\n",
      "   George Taylor\n",
      "   James Wilson\n",
      "   George Ross\n",
      " Delaware:   Caesar Rodney\n",
      "   George Read\n",
      "   Thomas McKean \n",
      "[Column 5]\n",
      " New York:   Wi\n",
      "lliam Floyd   Philip Livingston\n",
      "   Francis L\n",
      "ewis   Lewis Morris\n",
      " New Jersey:   Richard Stockton\n",
      "   John Witherspoon\n",
      "   Francis Hopkinson\n",
      "   John Hart\n",
      "   Abraham Clark \n",
      "[Column 6]\n",
      " New Hampshire:   Josiah Bartlett\n",
      "   William Whipple\n",
      " Massachusetts:   Samuel Adams\n",
      "   John Adams\n",
      "   Robert Treat Paine\n",
      "   Elbridge Gerry\n",
      " Rhode Island:   Stephen Hopkins\n",
      "   William Ellery\n",
      " Connecticut:   Roger Sherman\n",
      "   Samuel Huntington\n",
      "   William Williams\n",
      "   Oliver Wolcott\n",
      " New Hampshire: Matthew Thornton\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for page in pdf_text:\n",
    "    print(page)\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The phone number of agent is 444-555-1234. Call soon!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(4, 9), match='phone'>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_match = re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my phone is a phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first match\n",
    "match = re.search(pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the matches\n",
    "all_matches = re.findall('phone',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phone', 'phone']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n",
      "(14, 19)\n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer('phone',text):\n",
    "    print(match.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my phone is a phone'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'My tel number is 444-555-3333'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My tel number is 444-555-3333'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_num = re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(17, 29), match='444-555-3333'>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'444-555-3333'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_num.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\d{3}-\\d{3}-\\d{4}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'444-555-3333'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_num = re.search(pattern, text)\n",
    "ph_num.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "-\n",
      "5\n",
      "5\n",
      "5\n",
      "-\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'444'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"(\\d{3})-(\\d{3})-(\\d{4})\"\n",
    "ph_num = re.search(pattern, text)\n",
    "for i in ph_num.group():\n",
    "    print(i)\n",
    "ph_num.group(1)\n",
    "#ph_num.group(2)\n",
    "#ph_num.group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(4, 9), match='woman'>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"man|woman\", \"The woman was here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' cat', ' hat', ' sat', 'plat']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"..at\",\"The cat with hat sat splat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\d$\",\"This ends with a 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"^\\d\",\"2 This ends with a 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " ' ',\n",
       " 'n',\n",
       " 'u',\n",
       " 'm',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " ' ',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 's',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"[^\\d]\",\"There are 2 numbers 35 inside 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are ', ' numbers ', ' inside ']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"[^\\d]+\",\"There are 2 numbers 35 inside 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punct\n",
    "test_ph = \"This sentence has punct. I need to remove it, although carefully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = re.findall(r\"[^!.? , ]+\",test_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'sentence',\n",
       " 'has',\n",
       " 'punct',\n",
       " 'I',\n",
       " 'need',\n",
       " 'to',\n",
       " 'remove',\n",
       " 'it',\n",
       " 'although',\n",
       " 'carefully']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This sentence has punct I need to remove it although carefully'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1ea75667888>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla 96 PROPN nsubj\n",
      "is 87 AUX aux\n",
      "looking 100 VERB ROOT\n",
      "at 85 ADP prep\n",
      "buying 100 VERB pcomp\n",
      "U.S. 96 PROPN compound\n",
      "startup 92 NOUN dobj\n",
      "for 85 ADP prep\n",
      "$ 99 SYM quantmod\n",
      "6 93 NUM compound\n",
      "million 93 NUM pobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos, token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1ea77c0d348>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1ea77c0d528>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1ea77c170b8>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1ea77c17208>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1ea77c6e708>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1ea77c50348>)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't looking into startups anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla 96 PROPN nsubj\n",
      "is 87 AUX aux\n",
      "n't 94 PART neg\n",
      "looking 100 VERB ROOT\n",
      "into 85 ADP prep\n",
      "startups 92 NOUN pobj\n",
      "anymore 86 ADV advmod\n",
      ". 97 PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.pos, token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", the phrase \"Life is what happens to us while we are making other plans\" was written by cartoonist Allen Saunders and published in Reader's Digest in 1957, when Lennon was 17."
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_quote = doc3[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is the second sentence. This is the third sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the second sentence.\n",
      "This is the third sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring = '\"We\\'re moving to L.A.!\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "We\n",
      "'re\n",
      "moving\n",
      "to\n",
      "L.A.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "snail\n",
      "-\n",
      "mail\n",
      ",\n",
      "email\n",
      "support@oursite.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "at\n",
      "http://www.oursite.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for t in doc2:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.vocab.Vocab at 0x1ea75e48dc8>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u\"It is better to give than receive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "It"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "It is better to give than"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc8 =nlp(u'Apple to build a factory in HK for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | factory | in | HK | for | $ | 6 | million | "
     ]
    }
   ],
   "source": [
    "for token in doc8:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "\n",
      "\n",
      "$6 million\n",
      "MONEY\n",
      "Monetary values, including unit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entity in doc8.ents:\n",
    "    print(entity)\n",
    "    print(entity.label_)\n",
    "    print(str(spacy.explain(entity.label_)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Autonomous cars\n",
      "\n",
      "\n",
      "Autonomous cars cars nsubj shift\n",
      "\n",
      "\n",
      "insurance liability\n",
      "\n",
      "\n",
      "insurance liability liability dobj shift\n",
      "\n",
      "\n",
      "manufacturers\n",
      "\n",
      "\n",
      "manufacturers manufacturers pobj toward\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc9.noun_chunks:\n",
    "    print('\\n')\n",
    "    print(chunk)\n",
    "    print('\\n')\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Apple is going to build a U.K. factory for $6 million.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"58f0c88715cc4bf584ebdc661e39ecd0-0\" class=\"displacy\" width=\"1370\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,112.0 810.0,112.0 810.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-6\" stroke-width=\"2px\" d=\"M510,222.0 C510,57.0 815.0,57.0 815.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M815.0,224.0 L823.0,212.0 807.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-7\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L938.0,212.0 922.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-8\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,112.0 1250.0,112.0 1250.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,224.0 L1052,212.0 1068,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,167.0 1245.0,167.0 1245.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-10\" stroke-width=\"2px\" d=\"M950,222.0 C950,57.0 1255.0,57.0 1255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-58f0c88715cc4bf584ebdc661e39ecd0-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1255.0,224.0 L1263.0,212.0 1247.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep',jupyter=True, options={'distance':110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to build a \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " factory for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'This is a sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"343f6acbe56c410e940a972daf4dac55-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-343f6acbe56c410e940a972daf4dac55-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-343f6acbe56c410e940a972daf4dac55-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-343f6acbe56c410e940a972daf4dac55-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-343f6acbe56c410e940a972daf4dac55-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-343f6acbe56c410e940a972daf4dac55-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-343f6acbe56c410e940a972daf4dac55-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run---->run\n",
      "runner---->runner\n",
      "ran---->ran\n",
      "runs---->run\n",
      "easily---->easili\n",
      "fairly---->fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '---->' +p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because i love to run since i ran.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "i \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "i \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      ". \t PUNCT \t 12646065887601541794 \t .\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.lemma,'\\t',token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_:{28}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"I saw ten mice today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   4690420944186131903    I                           \n",
      "saw          VERB   11925638236994514241   see                         \n",
      "ten          NUM    7970704286052693043    ten                         \n",
      "mice         NOUN   1384165645700560590    mouse                       \n",
      "today        NOUN   11042482332948150395   today                       \n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this', 'name', 'thus', 'along', 'my', 'three', 'why', 'each', 'via', 'their', 'had', 'few', 'those', 'what', 'i', 'himself', 'elsewhere', 'before', '’m', 'front', 'nobody', 'anything', 'does', 'within', 'below', '‘ve', 'almost', 'whither', 'where', 'and', 'throughout', \"'re\", 'put', 'because', '’s', 'but', 'hereafter', 'do', 'ten', 'whole', 'anyhow', 'herself', 'never', 'have', 'thereby', 'cannot', 'please', 'someone', 'herein', 'due', 'being', 'always', 'during', 'so', \"n't\", 'toward', 'too', 'there', 'must', 'she', 'latterly', 'enough', 'who', 'nevertheless', '‘re', 'namely', 'all', 'call', 'make', 'for', 'down', 'alone', 'done', 'sometime', 'back', 'first', 'an', 'thereafter', 'own', 'whereafter', 'although', 'formerly', 'here', 'empty', 'against', 'after', 'again', 'last', 'out', 'anywhere', 'quite', 'twelve', 'of', 'whom', 'since', 'whether', 'he', 'is', 'hundred', 'seemed', 'how', 'take', '‘ll', 'top', 'get', 'be', 'five', 'amount', 'should', 'amongst', 'noone', 'whereas', 'twenty', 'just', 'onto', 'towards', '’ve', 'am', 'others', 'hereby', 'them', 'whence', 'between', 'move', 'would', 'beyond', \"'ll\", 'however', 'these', 'mostly', \"'d\", 'rather', 'can', 'up', 'least', 'something', 'becoming', 'at', 'very', 'has', 'whereby', 'say', 'off', 'hers', 'used', 'it', 'are', 'you', 'above', 'fifteen', 'sometimes', 'per', 'did', 'any', 'other', '‘d', '’d', 'in', 'less', 'upon', 'will', 'already', 'bottom', 'may', 'third', 'nowhere', 'same', 'could', 'from', 'using', 'ca', 'various', 'more', 'further', 'unless', 'often', 'yet', 'among', 'until', 'into', 'somehow', 'without', 'became', 'thereupon', 'they', 'many', 'ours', '’re', 'whatever', 'fifty', 'wherever', 'him', 'anyone', 'yours', 'that', 'still', 'wherein', 'a', \"'s\", 'if', 'four', 'no', 'latter', 'seems', 'everything', 'anyway', 'on', 'whereupon', 'else', 'keep', 'though', 'we', '’ll', 'beforehand', 'thru', 'several', 'not', 'both', 'perhaps', 'sixty', 'meanwhile', 'eleven', 'six', 'the', 'nor', 'me', \"'ve\", 'such', 'themselves', \"'m\", 'across', 'our', 'made', 'regarding', 'hence', 'moreover', 'was', 'mine', 'therein', 'than', 'seem', 'or', 'once', 'either', 'while', 'whose', 'whenever', 'eight', 'full', 'also', 'hereupon', 'ourselves', 'besides', 'myself', 'nine', 'then', 'beside', 'itself', 'your', 'next', 'serious', 'one', 'every', 'everywhere', 'side', 're', 'whoever', 'only', 'go', 'otherwise', 'somewhere', 'behind', 'give', 'yourself', 'to', 'some', 'ever', 'n’t', 'neither', '‘m', 'another', 'really', 'two', 'around', 'therefore', '‘s', 'its', 'former', 'about', 'afterwards', 'indeed', 'together', 'even', 'nothing', 'yourselves', 'become', 'now', 'when', 'through', 'by', 'might', 'well', 'everyone', 'forty', 'except', 'been', 'doing', 'see', 'much', 'her', 'thence', 'were', 'with', 'over', 'his', 'n‘t', 'most', 'becomes', 'us', 'show', 'as', 'part', 'seeming', 'which', 'under', 'none'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['is'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]\n",
    "\n",
    "matcher.add('SolarPower', [pattern1, pattern2, pattern3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power is good. I like solar-power bike. The SOLARPOWER works.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 8, 11), (8656102463236116519, 14, 15)]\n",
      "Solar Power\n",
      "solar-power\n",
      "SOLARPOWER\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)\n",
    "for _,start,end in found_matches:\n",
    "    span = doc[start:end]\n",
    "    print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower',[pattern1,pattern2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Solarpower is solar-power.!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 1), (8656102463236116519, 2, 5)]\n",
      "Solarpower\n",
      "solar-power\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)\n",
    "for _,start,end in found_matches:\n",
    "    span = doc2[start:end]\n",
    "    print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/reaganomics.txt') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAGANOMICS\n",
       "https://en.wikipedia.org/wiki/Reaganomics\n",
       "\n",
       "Reaganomics (a portmanteau of [Ronald] Reagan and economics attributed to Paul Harvey)[1] refers to the economic policies promoted by U.S. President Ronald Reagan during the 1980s. These policies are commonly associated with supply-side economics, referred to as trickle-down economics or voodoo economics by political opponents, and free-market economics by political advocates.\n",
       "\n",
       "The four pillars of Reagan's economic policy were to reduce the growth of government spending, reduce the federal income tax and capital gains tax, reduce government regulation, and tighten the money supply in order to reduce inflation.[2]\n",
       "\n",
       "The results of Reaganomics are still debated. Supporters point to the end of stagflation, stronger GDP growth, and an entrepreneur revolution in the decades that followed.[3][4] Critics point to the widening income gap, an atmosphere of greed, and the national debt tripling in eight years which ultimately reversed the post-World War II trend of a shrinking national debt as percentage of GDP.[5][6]\n",
       "\n",
       "HISTORICAL CONTEXT\n",
       "\n",
       "Prior to the Reagan administration, the United States economy experienced a decade of high unemployment and persistently high inflation (known as stagflation). Attacks on Keynesian economic orthodoxy as well as empirical economic models such as the Phillips Curve grew. Political pressure favored stimulus resulting in an expansion of the money supply. President Richard Nixon's wage and price controls were phased out.[7] The federal oil reserves were created to ease any future short term shocks. President Jimmy Carter had begun phasing out price controls on petroleum while he created the Department of Energy. Much of the credit for the resolution of the stagflation is given to two causes: a three-year contraction of the money supply by the Federal Reserve Board under Paul Volcker, initiated in the last year of Carter's presidency, and long-term easing of supply and pricing in oil during the 1980s oil glut.[citation needed]\n",
       "\n",
       "In stating that his intention was to lower taxes, Reagan's approach was a departure from his immediate predecessors. Reagan enacted lower marginal tax rates as well as simplified income tax codes and continued deregulation. During Reagan's eight year presidency, the annual deficits averaged 4.0% of GDP, compared to a 2.2% average during the preceding eight years.[8] The real (inflation adjusted) average rate of growth in federal spending fell from 4% under Jimmy Carter to 2.5% under Ronald Reagan.[9][10] GDP per employed person increased at an average 1.5% rate during the Reagan administration, compared to an average 0.6% during the preceding eight years.[11] Private sector productivity growth, measured as real output per hour of all persons, increased at an average rate of 1.9% during Reagan's eight years, compared to an average 1.3% during the preceding eight years.[12] Federal net outlays as a percent of GDP averaged 21.4% under Reagan, compared to 19.1% during the preceding eight years.[13]\n",
       "\n",
       "During the Nixon and Ford Administrations, before Reagan's election, a combined supply and demand side policy was considered unconventional by the moderate wing of the Republican Party. While running against Reagan for the Presidential nomination in 1980, George H. W. Bush had derided Reaganomics as \"voodoo economics\".[14] Similarly, in 1976, Gerald Ford had severely criticized Reagan's proposal to turn back a large part of the Federal budget to the states.\n",
       "\n",
       "JUSTIFICATIONS\n",
       "\n",
       "In his 1980 campaign speeches, Reagan presented his economic proposals as a return to the free enterprise principles, free market economy that had been in favor before the Great Depression and FDR's New Deal policies. At the same time he attracted a following from the supply-side economics movement, which formed in opposition to Keynesian demand-stimulus economics. This movement produced some of the strongest supporters for Reagan's policies during his term in office.\n",
       "\n",
       "The contention of the proponents, that the tax rate cuts would more than cover any increases in federal debt, was influenced by a theoretical taxation model based on the elasticity of tax rates, known as the Laffer curve. Arthur Laffer's model predicts that excessive tax rates actually reduce potential tax revenues, by lowering the incentive to produce; the model also predicts that insufficient tax rates (rates below the optimum level for a given economy) lead directly to a reduction in tax revenues.\n",
       "\n",
       "POLICIES\n",
       "\n",
       "Reagan lifted remaining domestic petroleum price and allocation controls on January 28, 1981,[15] and lowered the oil windfall profits tax in August 1981. He ended the oil windfall profits tax in 1988.[16] During the first year of Reagan's presidency, federal income tax rates were lowered significantly with the signing of the Economic Recovery Tax Act of 1981,[17] which lowered the top marginal tax bracket from 70% to 50% and the lowest bracket from 14% to 11%. This act slashed estate taxes and trimmed taxes paid by business corporations by $150 billion over a five-year period. In 1982 Reagan agreed to a rollback of corporate tax cuts and a smaller rollback of individual income tax cuts. The 1982 tax increase undid a third of the initial tax cut. In 1983 Reagan instituted a payroll tax increase on Social Security and Medicare hospital insurance.[18] In 1984 another bill was introduced that closed tax loopholes. According to tax historian Joseph Thorndike, the bills of 1982 and 1984 \"constituted the biggest tax increase ever enacted during peacetime\".[19]\n",
       "\n",
       "With the Tax Reform Act of 1986, Reagan and Congress sought to simplify the tax system by eliminating many deductions, reducing the highest marginal rates, and reducing the number of tax brackets.[20][21][22][23] In 1983, Democrats Bill Bradley and Dick Gephardt had offered a proposal; in 1984 Reagan had the Treasury Department produce its own plan. The 1986 act aimed to be revenue-neutral: while it reduced the top marginal rate, it also cleaned up the tax base by removing certain tax write-offs, preferences, and exceptions, thus raising the effective tax on activities previously specially favored by the code. Ultimately, the combination of the decrease in deductions and decrease in rates raised revenue equal to about 4% of existing tax revenue.[24]\n",
       "\n",
       "Federal revenue share of GDP fell from 19.6% in fiscal 1981 to 17.3% in 1984, before rising back to 18.4% by fiscal year 1989. Personal income tax revenues fell during this period relative to GDP, while payroll tax revenues rose relative to GDP.[25] Reagan's 1981 cut in the top regular tax rate on unearned income reduced the maximum capital gains rate to only 20% – its lowest level since the Hoover administration.[26] The 1986 act set tax rates on capital gains at the same level as the rates on ordinary income like salaries and wages, with both topping out at 28%.[27]\n",
       "\n",
       "Reagan significantly increased public expenditures, primarily the Department of Defense, which rose (in constant 2000 dollars) from $267.1 billion in 1980 (4.9% of GDP and 22.7% of public expenditure) to $393.1 billion in 1988 (5.8% of GDP and 27.3% of public expenditure); most of those years military spending was about 6% of GDP, exceeding this number in 4 different years. All these numbers had not been seen since the end of U.S. involvement in the Vietnam War in 1973.[28] In 1981, Reagan significantly reduced the maximum tax rate, which affected the highest income earners, and lowered the top marginal tax rate from 70% to 50%; in 1986 he further reduced the rate to 28%.[29] The federal deficit under Reagan peaked at 6% of GDP in 1983, falling to 3.2% of GDP in 1987[30] and to 3.1% of GDP in his final budget.[31] The inflation-adjusted rate of growth in federal spending fell from 4% under Jimmy Carter to 2.5% under Ronald Reagan. This was the slowest rate of growth in inflation adjusted spending since Eisenhower. However, federal deficit as percent of GDP was up throughout the Reagan presidency from 2.7% at the end of (and throughout) the Carter administration.[9][31][32] As a short-run strategy to reduce inflation and lower nominal interest rates, the U.S. borrowed both domestically and abroad to cover the Federal budget deficits, raising the national debt from $997 billion to $2.85 trillion.[33] This led to the U.S. moving from the world's largest international creditor to the world's largest debtor nation.[5] Reagan described the new debt as the \"greatest disappointment\" of his presidency.[34]\n",
       "\n",
       "According to William A. Niskanen, one of the architects of Reaganomics, \"Reagan delivered on each of his four major policy objectives, although not to the extent that he and his supporters had hoped\", and notes that the most substantial change was in the tax code, where the top marginal individual income tax rate fell from 70.1% to 28.4%, and there was a \"major reversal in the tax treatment of business income\", with effect of \"reducing the tax bias among types of investment but increasing the average effective tax rate on new investment\". Roger Porter, another architect of the program, acknowledges that the program was weakened by the many hands that changed the President's calculus, such as Congress.[2][35] President Reagan raised taxes eleven times over the course of his presidency, but the overall tax burden went down during his presidency.[36][37] According to Paul Krugman, \"Over all, the 1982 tax increase undid about a third of the 1981 cut; as a share of GDP, the increase was substantially larger than Mr. Clinton's 1993 tax increase.\"[18] According to historian and domestic policy adviser Bruce Bartlett, Reagan's tax increases over the course of his presidency took back half of the 1981 tax cut. Though since the Reagan tax reductions, top marginal tax rates have remained lower than at any point in US history since 1931, when the top marginal rate was raised from 25% to 63%.[38]\n",
       "\n",
       "RESULTS\n",
       "\n",
       "Overview\n",
       "\n",
       "Spending during the years Reagan budgeted (FY 1982–89) averaged 21.6% GDP, roughly tied with President Obama for the highest among any recent President. Each faced a severe recession early in their administration. In addition, the public debt rose from 26% GDP in 1980 to 41% GDP by 1988. In dollar terms, the public debt rose from $712 billion in 1980 to $2.052 trillion in 1988, a roughly three-fold increase.[25]:143 The unemployment rate rose from 7% in 1980 to 11% in 1982, then declined to 5% in 1988. The inflation rate declined from 10% in 1980 to 4% in 1988.[2]\n",
       "\n",
       "Some economists have stated that Reagan's policies were an important part of bringing about the third longest peacetime economic expansion in U.S. history.[39][40] During the Reagan administration, real GDP growth averaged 3.5%, compared to 2.9% during the preceding eight years.[41] The annual average unemployment rate declined by 1.7 percentage points, from 7.2% in 1980 to 5.5% in 1988, after it had increased by 1.6 percentage points over the preceding eight years.[42][43] Nonfarm employment increased by 16.1 million during Reagan's presidency, compared to 15.4 million during the preceding eight years,[44] while manufacturing employment declined by 582,000 after rising 363,000 during the preceding eight years.[45] Reagan's administration is the only one not to have raised the minimum wage.[46] The inflation rate, 13.5% in 1980, fell to 4.1% in 1988, due to the Federal Reserve increasing interest rates (prime rate peaking at 20.5% in August 1981[47]).[48] The latter contributed to a recession from July 1981 to November 1982 during which unemployment rose to 9.7% and GDP fell by 1.9%. Additionally, income growth slowed for middle- and lower-class (2.4% to 1.8%) and rose for the upper-class (2.2% to 4.83%).[49]\n",
       "\n",
       "The misery index, defined as the inflation rate added to the unemployment rate, shrank from 19.33 when he began his administration to 9.72 when he left, the greatest improvement record for a President since Harry S. Truman left office.[50] In terms of American households, the percentage of total households making less than $10,000 a year (in real 2007 dollars) shrank from 8.8% in 1980 to 8.3% in 1988 while the percentage of households making over $75,000 went from 20.2% to 25.7% during that period, both signs of progress.[51]\n",
       "\n",
       "Employment and wages\n",
       "\n",
       "The job growth (measured for non-farm payrolls) under the Reagan administration averaged 168,000 per month, versus 216,000 for Carter, 55,000 for H.W. Bush, and 239,000 for Clinton. Measuring the number of jobs created per month is limited for longer time periods as the population grows. To address this, we can measure annual job growth percentages, comparing the beginning and ending number of jobs during their time in office to determine an annual growth rate. Jobs grew by 2.0% annually under Reagan, versus 3.1% under Carter, 0.6% under H.W. Bush, and 2.4% under Clinton.[52]\n",
       "\n",
       "The unemployment rate averaged 7.5% under Reagan, compared to an average 6.6% during the preceding eight years. Declining steadily after December 1982, the rate was 5.4% the month Reagan left office.[53]\n",
       "\n",
       "The average real hourly wage for production and nonsupervisory workers continued the decline that had begun in 1973, albeit at a slower rate, and remained below the pre-Reagan level in every Reagan year.[54]\n",
       "\n",
       "The labor force participation rate increased by 2.6 percentage points during Reagan's eight years, compared to 3.9 percentage points during the preceding eight years.[55]\n",
       "\n",
       "Growth rates\n",
       "\n",
       "Following the 1981 recession, the unemployment rate had averaged slightly higher (6.75% vs. 6.35%), productivity growth lower (1.38% vs. 1.92%), and private investment as a percentage of GDP slightly less (16.08% vs. 16.86%).[citation needed] In the 1980's, industrial productivity growth in the United States matched that of its trading partners after trailing them in the 1970's. By 1990, manufacturing's share of GNP exceeded the post-World War II low hit in 1982 and matched \"the level of output achieved in the 1960's when American factories hummed at a feverish clip\".[56]\n",
       "\n",
       "GDP growth\n",
       "\n",
       "Real GDP grew over one-third during Reagan’s presidency, an over $2 trillion increase. The compound annual growth rate of GDP was 3.6% during Reagan's eight years, compared to 2.7% during the preceding eight years.[57] Real GDP per capita grew 2.6% under Reagan, compared to 1.9% average growth during the preceding eight years.[58]\n",
       "\n",
       "Income and wealth\n",
       "In nominal terms, median household income grew at a compound annual growth rate (CAGR) of 5.5% during the Reagan presidency, compared to 8.5% during the preceding five years (pre-1975 data are unavailable).[59] Real median family income grew by $4,492 during the Reagan period, compared to a $1,270 increase during the preceding eight years.[60] After declining from 1974 through 1980, real mean personal income rose $4,708 by 1988.[61] Nominal household net worth increased by a CAGR of 8.4%, compared to 9.3% during the preceding eight years.[62]\n",
       "\n",
       "Poverty level\n",
       "\n",
       "The percentage of the total population below the poverty level increased from 13.0% in 1980 to 15.2% in 1983, then declined back to 13.0% in 1988.[64] During Reagan's first term, critics noted homelessness as a visible problem in U.S. urban centers.[65] In the closing weeks of his presidency, Reagan told David Brinkley that the homeless \"make it their own choice for staying out there,\" noting his belief that there \"are shelters in virtually every city, and shelters here, and those people still prefer out there on the grates or the lawn to going into one of those shelters\". He also stated that \"a large proportion\" of them are \"mentally impaired.\" A result (he believed) of ACLU (and similar organizations) lawsuits against institutions.[66] His policies became widely known as \"trickle-down economics\", due to the significant cuts in the upper tax brackets, as that extra money for the wealthy could trickle along to low-income groups.[67]\n",
       "\n",
       "Federal income tax and payroll tax levels\n",
       "\n",
       "During the Reagan administration, fiscal year federal receipts grew from $599 billion to $991 billion (an increase of 65%) while fiscal year federal outlays grew from $678 billion to $1144 billion (an increase of 69%).[68][69] According to a 1996 report of the Joint Economic Committee of the United States Congress, during Reagan's two terms, and through 1993, the top 10% of taxpayers paid an increased share of income taxes (not including payroll taxes) to the Federal government, while the lowest 50% of taxpayers paid a reduced share of income tax revenue.[70] Personal income tax revenues declined from 9.4% GDP in 1981 to 8.3% GDP in 1989, while payroll tax revenues increased from 6.0% GDP to 6.7% GDP during the same period.[25]\n",
       "\n",
       "Tax receipts\n",
       "\n",
       "According to a 2003 Treasury study, the tax cuts in the Economic Recovery Tax Act of 1981 resulted in a significant decline in revenue relative to a baseline without the cuts, approximately $111 billion (in 1992 dollars) on average during the first four years after implementation or nearly 3% GDP annually.[71][72] Other tax bills had neutral or, in the case of the Tax Equity and Fiscal Responsibility Act of 1982, a (~+1% of GDP) increase in revenue as a share of GDP. It should be noted, however, that the study did not examine the longer-term impact of Reagan tax policy, including sunset clauses and \"the long-run, fully-phased-in effect of the tax bills\".[72] The fact that tax receipts as a percentage of GDP fell following the Economic Recovery Tax Act of 1981 shows a decrease in tax burden as share of GDP and a commensurate increase in the deficit, as spending did not fall relative to GDP. Total federal tax receipts increased in every Reagan year except 1982, at an annual average rate of 6.2% compared to 10.8% during the preceding eight years.[73]\n",
       "\n",
       "The effect of Reagan's 1981 tax cuts (reduced revenue relative to a baseline without the cuts) were at least partially offset by phased in Social Security payroll tax increases that had been enacted by President Jimmy Carter and the 95th Congress in 1977, and further increases by Reagan in 1983[74] and following years, also to counter the uses of tax shelters.[75] An accounting indicated nominal tax receipts increased from $599 billion in 1981 to $1.032 trillion in 1990, an increase of 72% in current dollars. In 2005 dollars, the tax receipts in 1990 were $1.5 trillion, an increase of 20% above inflation.[76]\n",
       "\n",
       "Debt and government expenditures\n",
       "Reagan was inaugurated in January 1981, so the first fiscal year (FY) he budgeted was 1982 and the final year was 1989.\n",
       "\n",
       "During Reagan's presidency, the federal debt held by the public nearly tripled in nominal terms, from $738 billion to $2.1 trillion.[77] This led to the U.S. moving from the world's largest international creditor to the world's largest debtor nation.[5] Reagan described the new debt as the \"greatest disappointment\" of his presidency.[34]\n",
       "The federal deficit as percentage of GDP rose from 2.5% of GDP in fiscal year 1981 to a peak of 5.7% of GDP in 1983, then fell to 2.7% GDP in 1989.[78]\n",
       "Total federal outlays averaged of 21.8% of GDP from 1981–88, versus the 1974–1980 average of 20.1% of GDP. This was the highest of any President from Carter through Obama.[79]\n",
       "Total federal revenues averaged 17.7% of GDP from 1981–88, versus the 1974–80 average of 17.6% of GDP.[80]\n",
       "Federal individual income tax revenues fell from 8.7% of GDP in 1980 to a trough of 7.5% of GDP in 1984, then rose to 7.8% of GDP in 1988.[81]\n",
       "Business and market performance\n",
       "Nominal after-tax corporate profits grew at a compound annual growth rate of 3.0% during Reagan's eight years, compared to 13.0% during the preceding eight years.[82] The S&P 500 Index increased 113.3% during the 2024 trading days under Reagan, compared to 10.4% during the preceding 2024 trading days.[83] The business sector share of GDP, measured as gross private domestic investment, declined by 0.7 percentage points under Reagan, after increasing 0.7 percentage points during the preceding eight years.[84]\n",
       "\n",
       "Size of federal government\n",
       "The federal government's share of GDP increased 0.2 percentage points under Reagan, while it decreased 1.5 percentage points during the preceding eight years.[85] The number of federal civilian employees increased 4.2% during Reagan's eight years, compared to 6.5% during the preceding eight years.[86]\n",
       "\n",
       "As a candidate, Reagan asserted he would shrink government by abolishing the Cabinet-level departments of energy and education. He abolished neither, but elevated veterans affairs from independent agency status to Cabinet-level department status.[87][88]\n",
       "\n",
       "Income distribution\n",
       "Further information: Income inequality in the United States\n",
       "Continuing a trend that began in the 1970s, income inequality grew and accelerated in the 1980s. The Economist wrote in 2006: \"After the 1973 oil shocks, productivity growth suddenly slowed. A few years later, at the start of the 1980s, the gap between rich and poor began to widen.\"[89] According to the CBO:\n",
       "\n",
       "The top 1% of income earners' share of income before transfers and taxes rose from 9.0% in 1979 to a peak of 13.8% in 1986, before falling to 12.3% in 1989.\n",
       "The top 1% share of income earners' of income after transfers and taxes rose from 7.4% in 1979 to a peak of 12.8% in 1986, before falling to 11.0% in 1989.\n",
       "The bottom 90% had a lower share of the income in 1989 vs. 1979.[90]\n",
       "\n",
       "ANALYSIS\n",
       "\n",
       "According to a 1996 study[93] by the Cato Institute, a libertarian think tank, on 8 of the 10 key economic variables examined, the American economy performed better during the Reagan years than during the pre- and post-Reagan years. The study asserted that real median family income grew by $4,000 and during the eight Reagan years and experienced a loss of almost $1,500 in the post-Reagan years. Interest rates, inflation, and unemployment fell faster under Reagan than they did immediately before or after his presidency. The only economic variable that was lower during period than in both the pre- and post-Reagan years was the savings rate, which fell rapidly in the 1980s. The productivity rate was higher in the pre-Reagan years but lower in the post-Reagan years.[93] The Cato study was dismissive of any positive effects of tightening, and subsequent loosening, of Federal Reserve monetary policy under \"inflation hawk\" Paul Volcker, whom President Carter had appointed in 1979 to halt the persistent inflation of the 1970s.\n",
       "\n",
       "Economic analyst Stephen Moore stated in the Cato analysis, \"No act in the last quarter century had a more profound impact on the U.S. economy of the eighties and nineties than the Reagan tax cut of 1981.\" He argued that Reagan's tax cuts, combined with an emphasis on federal monetary policy, deregulation, and expansion of free trade created a sustained economic expansion, the greatest American sustained wave of prosperity ever. He also claims that the American economy grew by more than a third in size, producing a $15 trillion increase in American wealth. Consumer and investor confidence soared. Cutting federal income taxes, cutting the U.S. government spending budget, cutting useless programs, scaling down the government work force, maintaining low interest rates, and keeping a watchful inflation hedge on the monetary supply was Ronald Reagan's formula for a successful economic turnaround.[93]\n",
       "\n",
       "Milton Friedman stated, \"Reaganomics had four simple principles: Lower marginal tax rates, less regulation, restrained government spending, noninflationary monetary policy. Though Reagan did not achieve all of his goals, he made good progress.\"[94]\n",
       "\n",
       "The Tax Reform Act of 1986 and its impact on the alternative minimum tax (AMT) reduced nominal rates on the wealthy and eliminated tax deductions, while raising tax rates on lower-income individuals.[94][95][96][97] The across the board tax system reduced marginal rates and further reduced bracket creep from inflation. The highest income earners (with incomes exceeding $1,000,000) received a tax break, restoring a flatter tax system.[98] In 2006, the IRS's National Taxpayer Advocate's report characterized the effective rise in the AMT for individuals as a problem with the tax code.[99] Through 2007, the revised AMT had brought in more tax revenue than the former tax code, which has made it difficult for Congress to reform.[98][100]\n",
       "\n",
       "Economist Paul Krugman argued the economic expansion during the Reagan administration was primarily the result of the business cycle and the monetary policy by Paul Volcker.[101] Krugman argues that there was nothing unusual about the economy under Reagan because unemployment was reducing from a high peak and that it is consistent with Keynesian economics for the economy to grow as employment increases if inflation remains low.[102]\n",
       "\n",
       "The CBO Historical Tables indicate that federal spending during Reagan's two terms (FY 1981–88) averaged 22.4% GDP, well above the 20.6% GDP average from 1971 to 2009. In addition, the public debt rose from 26.1% GDP in 1980 to 41.0% GDP by 1988. In dollar terms, the public debt rose from $712 billion in 1980 to $2,052 billion in 1988, a three-fold increase.[25] Krugman argued in June 2012 that Reagan's policies were consistent with Keynesian stimulus theories, pointing to the significant increase in per-capita spending under Reagan.[103]\n",
       "\n",
       "William Niskanen noted that during the Reagan years, privately held federal debt increased from 22% to 38% of GDP, despite a long peacetime expansion. Second, the savings and loan problem led to an additional debt of about $125 billion. Third, greater enforcement of U.S. trade laws increased the share of U.S. imports subjected to trade restrictions from 12% in 1980 to 23% in 1988.[2]\n",
       "\n",
       "Economists Raghuram Rajan and Luigi Zingales pointed out that many deregulation efforts had either taken place or had begun before Reagan (note the deregulation of airlines and trucking under Carter, and the beginning of deregulatory reform in railroads, telephones, natural gas, and banking). They stated, \"The move toward markets preceded the leader [Reagan] who is seen as one of their saviors.\"[104] Economists Paul Joskow and Roger Noll made a similar contention.[105]\n",
       "\n",
       "Economist William A. Niskanen, a member of Reagan's Council of Economic Advisers wrote that deregulation had the \"lowest priority\" of the items on the Reagan agenda[2] given that Reagan \"failed to sustain the momentum for deregulation initiated in the 1970s\" and that he \"added more trade barriers than any administration since Hoover.\" By contrast, economist Milton Friedman has pointed to the number of pages added to the Federal Register each year as evidence of Reagan's anti-regulation presidency (the Register records the rules and regulations that federal agencies issue per year). The number of pages added to the Register each year declined sharply at the start of the Ronald Reagan presidency breaking a steady and sharp increase since 1960. The increase in the number of pages added per year resumed an upward, though less steep, trend after Reagan left office. In contrast, the number of pages being added each year increased under Ford, Carter, George H. W. Bush, Clinton, George W. Bush, and Obama.[106] The number of pages in Federal Register is however criticized as an extremely crude measure of regulatory activity, because it can be easily manipulated (e.g. font sizes have been changed to keep page count low).[107] The apparent contradiction between Niskanen's statements and Friedman's data may be resolved by seeing Niskanen as referring to statutory deregulation (laws passed by Congress) and Friedman to administrative deregulation (rules and regulations implemented by federal agencies). A 2016 study by the Congressional Research Service found that Reagan's average annual number of final federal regulatory rules published in the Federal Register was higher than during the Clinton, George W. Bush or Obama's administrations, even though the Reagan economy was considerably smaller than during those later presidents.[108] Another study by the QuantGov project of the libertarian Mercatus Center found that the Reagan administration added restrictive regulations — containing such terms as \"shall,\" \"prohibited\" or \"may not\" — at a faster average annual rate than did Clinton, Bush or Obama.[109]\n",
       "\n",
       "Greg Mankiw, a conservative Republican economist who served as chairman of the Council of Economic Advisors under President George W. Bush, wrote in 2007:\n",
       "\n",
       "I used the phrase \"charlatans and cranks\" in the first edition of my principles textbook to describe some of the economic advisers to Ronald Reagan, who told him that broad-based income tax cuts would have such large supply-side effects that the tax cuts would raise tax revenue. I did not find such a claim credible, based on the available evidence. I never have, and I still don't...My other work has remained consistent with this view. In a paper on dynamic scoring, written while I was working at the White House, Matthew Weinzierl and I estimated that a broad-based income tax cut (applying to both capital and labor income) would recoup only about a quarter of the lost revenue through supply-side growth effects. For a cut in capital income taxes, the feedback is larger — about 50 percent — but still well under 100 percent. A chapter on dynamic scoring in the 2004 Economic Report of the President says about the the [sic] same thing.[110]\n",
       "\n",
       "Glenn Hubbard, who preceded Mankiw as Bush's CEA chair, also disputed the assertion that tax cuts increase tax revenues, writing in his 2003 Economic Report of the President: \"Although the economy grows in response to tax reductions (because of higher consumption in the short run and improved incentives in the long run), it is unlikely to grow so much that lost tax revenue is completely recovered by the higher level of economic activity.\"[111]\n",
       "\n",
       "In 1986, Martin Feldstein — a self-described \"traditional supply sider\" who served as Reagan's chairman of the Council of Economic Advisors from 1982 to 1984 — characterized the \"new supply siders\" who emerged circa 1980:\n",
       "\n",
       "What distinguished the new supply siders from the traditional supply siders as the 1980s began was not the policies they advocated but the claims that they made for those policies...The \"new\" supply siders were much more extravagant in their claims. They projected rapid growth, dramatic increases in tax revenue, a sharp rise in saving, and a relatively painless reduction in inflation. The height of supply side hyperbole was the \"Laffer curve\" proposition that the tax cut would actually increase tax revenue because it would unleash an enormously depressed supply of effort. Another remarkable proposition was the claim that even if the tax cuts did lead to an increased budget deficit, that would not reduce the funds available for investment in plant and equipment because tax changes would raise the saving rate by enough to finance the increased deficit...Nevertheless, I have no doubt that the loose talk of the supply side extremists gave fundamentally good policies a bad name and led to quantitative mistakes that not only contributed to subsequent budget deficits but that also made it more difficult to modify policy when those deficits became apparent.[112]\n",
       "\n",
       "FOOTNOTES\n",
       "\n",
       "https://en.wikipedia.org/wiki/Reaganomics#Footnotes"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['voodoo economics','supply-side economics','trickle-down economics','free-market economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[voodoo economics,\n",
       " supply-side economics,\n",
       " trickle-down economics,\n",
       " free-market economics]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phrase_patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('Econmatcher',None, *phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14516527939337228634, 41, 45),\n",
       " (14516527939337228634, 49, 53),\n",
       " (14516527939337228634, 54, 56),\n",
       " (14516527939337228634, 61, 65),\n",
       " (14516527939337228634, 673, 677),\n",
       " (14516527939337228634, 2987, 2991)]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches = matcher(doc3)\n",
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14516527939337228634 Econmatcher 41 45 during the 1980s. These policies are commonly associated with supply-side economics, referred to as trickle-down economics or voodoo\n",
      "14516527939337228634 Econmatcher 49 53 associated with supply-side economics, referred to as trickle-down economics or voodoo economics by political opponents, and free-\n",
      "14516527939337228634 Econmatcher 54 56 economics, referred to as trickle-down economics or voodoo economics by political opponents, and free-market economics by\n",
      "14516527939337228634 Econmatcher 61 65 down economics or voodoo economics by political opponents, and free-market economics by political advocates.\n",
      "\n",
      "The four pillars of Reagan\n",
      "14516527939337228634 Econmatcher 673 677 At the same time he attracted a following from the supply-side economics movement, which formed in opposition to Keynesian demand-\n",
      "14516527939337228634 Econmatcher 2987 2991 against institutions.[66] His policies became widely known as \"trickle-down economics\", due to the significant cuts in the upper\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc3[start-10:end+10]\n",
    "    print(match_id,string_id,start,end,span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumped over the lazy dog's back\n"
     ]
    }
   ],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumped\n"
     ]
    }
   ],
   "source": [
    "print(doc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBD\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET        DT         determiner\n",
      "quick      ADJ        JJ         adjective\n",
      "brown      ADJ        JJ         adjective\n",
      "fox        NOUN       NN         noun, singular or mass\n",
      "jumped     VERB       VBD        verb, past tense\n",
      "over       ADP        IN         conjunction, subordinating or preposition\n",
      "the        DET        DT         determiner\n",
      "lazy       ADJ        JJ         adjective\n",
      "dog        NOUN       NN         noun, singular or mass\n",
      "'s         PART       POS        possessive ending\n",
      "back       NOUN       NN         noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I read books on NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB       VBD        verb, past tense\n"
     ]
    }
   ],
   "source": [
    "token = word\n",
    "print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I read a book on NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB       VBD        verb, past tense\n"
     ]
    }
   ],
   "source": [
    "word = doc[1]\n",
    "token = word\n",
    "print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The quick brown fox jumped over the lazy dog's back"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts = doc.count_by(spacy.attrs.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{90: 2, 84: 3, 92: 3, 100: 1, 85: 1, 94: 1}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ   3\n",
      "85. ADP   1\n",
      "90. DET   2\n",
      "92. NOUN  3\n",
      "94. PART  1\n",
      "100. VERB  1\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f\"{k}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"5852c1c6e6844830b729f7c75fdeb81b-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5852c1c6e6844830b729f7c75fdeb81b-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5852c1c6e6844830b729f7c75fdeb81b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5852c1c6e6844830b729f7c75fdeb81b-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5852c1c6e6844830b729f7c75fdeb81b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5852c1c6e6844830b729f7c75fdeb81b-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5852c1c6e6844830b729f7c75fdeb81b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5852c1c6e6844830b729f7c75fdeb81b-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5852c1c6e6844830b729f7c75fdeb81b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5852c1c6e6844830b729f7c75fdeb81b-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5852c1c6e6844830b729f7c75fdeb81b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5852c1c6e6844830b729f7c75fdeb81b-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5852c1c6e6844830b729f7c75fdeb81b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5852c1c6e6844830b729f7c75fdeb81b-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5852c1c6e6844830b729f7c75fdeb81b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5852c1c6e6844830b729f7c75fdeb81b-0-7\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5852c1c6e6844830b729f7c75fdeb81b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'distance':110,'compact':'True', 'color':'yellow','bg':'#09a3d5','font':'Times'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a76fb895e5b84025aec8bcee0dda4976-0\" class=\"displacy\" width=\"1040\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: yellow; background: #09a3d5; font-family: Times; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a76fb895e5b84025aec8bcee0dda4976-0-0\" stroke-width=\"2px\" d=\"M62,167.0 62,112.0 380.0,112.0 380.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a76fb895e5b84025aec8bcee0dda4976-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,169.0 L58,161.0 66,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a76fb895e5b84025aec8bcee0dda4976-0-1\" stroke-width=\"2px\" d=\"M172,167.0 172,130.33333333333334 377.0,130.33333333333334 377.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a76fb895e5b84025aec8bcee0dda4976-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M172,169.0 L168,161.0 176,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a76fb895e5b84025aec8bcee0dda4976-0-2\" stroke-width=\"2px\" d=\"M282,167.0 282,148.66666666666666 374.0,148.66666666666666 374.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a76fb895e5b84025aec8bcee0dda4976-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M282,169.0 L278,161.0 286,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a76fb895e5b84025aec8bcee0dda4976-0-3\" stroke-width=\"2px\" d=\"M392,167.0 392,148.66666666666666 484.0,148.66666666666666 484.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a76fb895e5b84025aec8bcee0dda4976-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M392,169.0 L388,161.0 396,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a76fb895e5b84025aec8bcee0dda4976-0-4\" stroke-width=\"2px\" d=\"M502,167.0 502,148.66666666666666 594.0,148.66666666666666 594.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a76fb895e5b84025aec8bcee0dda4976-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M594.0,169.0 L598.0,161.0 590.0,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a76fb895e5b84025aec8bcee0dda4976-0-5\" stroke-width=\"2px\" d=\"M722,167.0 722,130.33333333333334 927.0,130.33333333333334 927.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a76fb895e5b84025aec8bcee0dda4976-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M722,169.0 L718,161.0 726,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a76fb895e5b84025aec8bcee0dda4976-0-6\" stroke-width=\"2px\" d=\"M832,167.0 832,148.66666666666666 924.0,148.66666666666666 924.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a76fb895e5b84025aec8bcee0dda4976-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M832,169.0 L828,161.0 836,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a76fb895e5b84025aec8bcee0dda4976-0-7\" stroke-width=\"2px\" d=\"M612,167.0 612,112.0 930.0,112.0 930.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a76fb895e5b84025aec8bcee0dda4976-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M930.0,169.0 L934.0,161.0 926.0,161.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep',jupyter=True, options = options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"This is a sentence. This is another sentence, possibly longer than the other.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = list(doc2.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[This is a sentence., This is another sentence, possibly longer than the other.]\n"
     ]
    }
   ],
   "source": [
    "print(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0d2a33d5e892419a84ab9772d86cb5fe-0\" class=\"displacy\" width=\"490\" height=\"247.0\" direction=\"ltr\" style=\"max-width: none; height: 247.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-0-0\" stroke-width=\"2px\" d=\"M70,112.0 C70,57.0 155.0,57.0 155.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,114.0 L62,102.0 78,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-0-1\" stroke-width=\"2px\" d=\"M290,112.0 C290,57.0 375.0,57.0 375.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,114.0 L282,102.0 298,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-0-2\" stroke-width=\"2px\" d=\"M180,112.0 C180,2.0 380.0,2.0 380.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M380.0,114.0 L388.0,102.0 372.0,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0d2a33d5e892419a84ab9772d86cb5fe-1\" class=\"displacy\" width=\"1040\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">another</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">sentence,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">possibly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">longer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">than</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">other.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,112.0 150.0,112.0 150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-1\" stroke-width=\"2px\" d=\"M290,167.0 C290,112.0 370.0,112.0 370.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,169.0 L282,157.0 298,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-2\" stroke-width=\"2px\" d=\"M180,167.0 C180,57.0 375.0,57.0 375.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M375.0,169.0 L383.0,157.0 367.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-3\" stroke-width=\"2px\" d=\"M510,167.0 C510,112.0 590.0,112.0 590.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M510,169.0 L502,157.0 518,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-4\" stroke-width=\"2px\" d=\"M180,167.0 C180,2.0 600.0,2.0 600.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M600.0,169.0 L608.0,157.0 592.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-5\" stroke-width=\"2px\" d=\"M620,167.0 C620,112.0 700.0,112.0 700.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700.0,169.0 L708.0,157.0 692.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-6\" stroke-width=\"2px\" d=\"M840,167.0 C840,112.0 920.0,112.0 920.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,169.0 L832,157.0 848,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-7\" stroke-width=\"2px\" d=\"M730,167.0 C730,57.0 925.0,57.0 925.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0d2a33d5e892419a84ab9772d86cb5fe-1-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,169.0 L933.0,157.0 917.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(spans, style='dep',options = {'distance':110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text + ' - '+ent.label_ + ' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No entities found!')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'May i go now?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entities found!\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I want to visit Statue of Liberty in the month of June 2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statue of Liberty - FAC - Buildings, airports, highways, bridges, etc.\n",
      "the month of June 2021 - DATE - Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Tesla to build a factory for $6 million in India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$6 million - MONEY - Monetary values, including unit\n",
      "India - GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG = doc.vocab.strings[u\"ORG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ent = Span(doc,0,1,label=ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc.ents = list(doc.spans) + [new_ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAmed Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Our company created a brand new vacuum cleaner.' \n",
    "          u'This vacuum-cleaner is best in show.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entities found!\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['vacuum cleaner','vacuum-cleaner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('newproduct',None,*phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2689272359382549672, 6, 8), (2689272359382549672, 10, 13)]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD = doc.vocab.strings[u\"PRODUCT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2689272359382549672, 6, 8), (2689272359382549672, 10, 13)]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ents = [Span(doc,match[1],match[2],label=PROD) for match in found_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "vacuum-cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### render ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Over the last quarter, Apple sold nearly 20 thousand iPhones for a profit of $6 million.\"\n",
    "         u\"By contraast, SOny only sold 8 thousand Walkman music players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".By contraast, SOny only sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    8 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Walkman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " music players</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By contraast, SOny only sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    8 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Walkman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " music players</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    displacy.render(nlp(sent.text),style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'ORG':'red'}\n",
    "options = {'ents':['PRODUCT','ORG'],'colors':colors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over the last quarter, \n",
       "<mark class=\"entity\" style=\"background: red; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold nearly 20 thousand \n",
       "<mark class=\"entity\" style=\"background: red; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for a profit of $6 million.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By contraast, SOny only sold 8 thousand \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Walkman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " music players</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    displacy.render(nlp(sent.text),style='ent',jupyter=True,options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"This is the first sentence. This is another sentence. This is the last sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is the first sentence."
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'\"Management is doing the right things; leadership is doing the right things.\" - Peter D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Management is doing the right things; leadership is doing the right things.\" - Peter D'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing the right things; leadership is doing the right things.\"\n",
      "\n",
      "\n",
      "-\n",
      "\n",
      "\n",
      "Peter D\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'set_custom_boundaries',\n",
       " 'parser',\n",
       " 'ner',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer']"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"set_custom_boundaries\",before='parser')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'\"Management is doing the right things; leadership is doing the right things.\" - Peter D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing the right things;\n",
      "leadership is doing the right things.\"\n",
      "-\n",
      "Peter D\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spacy.pipeline import SentenceSegmenter\n",
    "from spacy.language import Language\n",
    "@Language.component(\"split_on_newlines\")\n",
    "\n",
    "def split_on_newlines(doc):\n",
    "    start = 0\n",
    "    seen_newline = False\n",
    "    \n",
    "    for word in doc:\n",
    "        if seen_newline:\n",
    "            yield doc[start:word.i]\n",
    "            start = word.i\n",
    "            seen_newline = False\n",
    "        elif word.text.startswith('\\n'):\n",
    "            seen_newline = True\n",
    "            \n",
    "    yield doc[start:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sbd = SentenceSegmenter(nlp.vocab,strategy=split_on_newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E007] 'split_on_newlines' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'set_custom_boundaries', 'split_on_newlines', 'parser', 'senter', 'ner', 'attribute_ruler', 'lemmatizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-454-dc84399ff404>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#nlp.add_pipe(sbd)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"split_on_newlines\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbefore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE007\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# We're loading the component from a model. After loading the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E007] 'split_on_newlines' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'set_custom_boundaries', 'split_on_newlines', 'parser', 'senter', 'ner', 'attribute_ruler', 'lemmatizer']"
     ]
    }
   ],
   "source": [
    "#nlp.add_pipe(sbd)\n",
    "\n",
    "nlp.add_pipe(\"split_on_newlines\",before=\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mystring = \"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another.\n",
      "\n",
      "\n",
      "This is a \n",
      "third sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users\\khura/Documents/Ashish/Career related/Git/NLP/smsspamcollection.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  message  length  punct\n",
       "0     False    False   False  False\n",
       "1     False    False   False  False\n",
       "2     False    False   False  False\n",
       "3     False    False   False  False\n",
       "4     False    False   False  False\n",
       "...     ...      ...     ...    ...\n",
       "5567  False    False   False  False\n",
       "5568  False    False   False  False\n",
       "5569  False    False   False  False\n",
       "5570  False    False   False  False\n",
       "5571  False    False   False  False\n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "        ... \n",
       "5567    spam\n",
       "5568     ham\n",
       "5569     ham\n",
       "5570     ham\n",
       "5571     ham\n",
       "Name: label, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15*(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['length'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['length'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15*(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['punct'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['punct'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X features, y labels\n",
    "X = df[['length','punct']]\n",
    "y= df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1672, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1672,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708     ham\n",
       "4338    ham\n",
       "5029    ham\n",
       "4921    ham\n",
       "2592    ham\n",
       "       ... \n",
       "3772    ham\n",
       "5191    ham\n",
       "5226    ham\n",
       "5390    ham\n",
       "860     ham\n",
       "Name: label, Length: 3900, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245     ham\n",
       "944      ham\n",
       "1044     ham\n",
       "2484     ham\n",
       "812      ham\n",
       "        ... \n",
       "2505     ham\n",
       "2525    spam\n",
       "4975     ham\n",
       "650     spam\n",
       "4463     ham\n",
       "Name: label, Length: 1672, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr_model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245     ham\n",
       "944      ham\n",
       "1044     ham\n",
       "2484     ham\n",
       "812      ham\n",
       "        ... \n",
       "2505     ham\n",
       "2525    spam\n",
       "4975     ham\n",
       "650     spam\n",
       "4463     ham\n",
       "Name: label, Length: 1672, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1404,   44],\n",
       "       [ 219,    5]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1404</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1404    44\n",
       "spam   219     5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['ham','spam'],columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.91      1448\n",
      "        spam       0.10      0.02      0.04       224\n",
      "\n",
      "    accuracy                           0.84      1672\n",
      "   macro avg       0.48      0.50      0.48      1672\n",
      "weighted avg       0.76      0.84      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427033492822966\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1438   10]\n",
      " [ 224    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X_train,y_train)\n",
    "\n",
    "predictions = nb_model.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1438</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1438    10\n",
       "spam   224     0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['ham','spam'],columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8600478468899522\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.92      1448\n",
      "        spam       0.00      0.00      0.00       224\n",
      "\n",
      "    accuracy                           0.86      1672\n",
      "   macro avg       0.43      0.50      0.46      1672\n",
      "weighted avg       0.75      0.86      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1373   75]\n",
      " [ 121  103]]\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(gamma='auto')\n",
    "svc_model.fit(X_train,y_train)\n",
    "predictions = svc_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8827751196172249\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text FEature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users\\khura/Documents/Ashish/Career related/Git/NLP/smsspamcollection.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3733x7082 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 49992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfTransformer used to give weights to words which are more important\n",
    "# PAss count vectors in tfidftransformer instance\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1586    7]\n",
      " [  12  234]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.97      0.95      0.96       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.98      0.97      0.98      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989668297988037"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"You wona  lottery of 500000 Rupees, let's gehter togather to celebrete this victrey. TEXT 455500\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie review practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/khura/Documents/Ashish/Career related/Git/NLP/moviereviews.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1965"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking empty strings\n",
    "blanks=[]\n",
    "\n",
    "for i,lb,rv in df.itertuples():\n",
    "    if rv.isspace():\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57,\n",
       " 71,\n",
       " 147,\n",
       " 151,\n",
       " 283,\n",
       " 307,\n",
       " 313,\n",
       " 323,\n",
       " 343,\n",
       " 351,\n",
       " 427,\n",
       " 501,\n",
       " 633,\n",
       " 675,\n",
       " 815,\n",
       " 851,\n",
       " 977,\n",
       " 1079,\n",
       " 1299,\n",
       " 1455,\n",
       " 1493,\n",
       " 1525,\n",
       " 1531,\n",
       " 1763,\n",
       " 1851,\n",
       " 1905,\n",
       " 1993]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blanks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  49]\n",
      " [ 49 283]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.84      0.84       308\n",
      "         pos       0.85      0.85      0.85       332\n",
      "\n",
      "    accuracy                           0.85       640\n",
      "   macro avg       0.85      0.85      0.85       640\n",
      "weighted avg       0.85      0.85      0.85       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word vectors with Spacy and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'fox').vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.049945  ,  0.053725  ,  0.20525   , -0.0105055 , -0.173665  ,\n",
       "        0.31194   , -0.038755  ,  0.108413  ,  0.609482  ,  1.546705  ,\n",
       "       -0.02152   , -0.360115  , -0.47591   , -0.0627449 , -0.347965  ,\n",
       "        0.30854   , -0.0881895 ,  0.49901   , -0.1050725 , -0.340445  ,\n",
       "       -0.34565252,  0.1045825 ,  0.11942   , -0.21643   ,  0.16901049,\n",
       "        0.0925955 , -0.32559502,  0.084052  , -0.169115  , -0.0250445 ,\n",
       "       -0.33641   , -0.07693   ,  0.3783455 , -0.306474  , -0.0187885 ,\n",
       "       -0.07780001, -0.11146501, -0.19961   , -0.06702   ,  0.13874099,\n",
       "        0.0843545 ,  0.45318502, -0.1510275 ,  0.0115    ,  0.1327575 ,\n",
       "        0.1490885 , -0.23852   , -0.22235501, -0.12563501,  0.165457  ,\n",
       "        0.00664   ,  0.121729  ,  0.011205  , -0.1158115 , -0.21391499,\n",
       "        0.10549255,  0.28629   ,  0.39518   , -0.12843099, -0.08453999,\n",
       "        0.00337   ,  0.1745925 , -0.01421499,  0.005781  , -0.031485  ,\n",
       "       -0.57041   ,  0.0769865 ,  0.093595  ,  0.16210599, -0.14208499,\n",
       "       -0.0280945 , -0.22301999, -0.026069  ,  0.006984  , -0.15548399,\n",
       "        0.042615  , -0.11257999,  0.165935  ,  0.047605  ,  0.095661  ,\n",
       "       -0.3116425 , -0.121474  ,  0.19843501, -0.03446001, -0.058295  ,\n",
       "        0.15937   ,  0.739555  ,  0.27352098,  0.387025  , -0.01097   ,\n",
       "        0.23895301,  0.44705498, -0.022375  , -0.85669005,  0.34948   ,\n",
       "       -0.24239501,  0.06134999, -0.019465  ,  0.058985  , -0.01911   ,\n",
       "        0.271445  , -0.00587   , -0.14644599,  0.017975  ,  0.033315  ,\n",
       "       -0.5271    ,  0.07429899,  0.003335  , -0.16397001, -0.1759575 ,\n",
       "       -0.02460499, -0.12524   , -0.15724501, -0.01273499, -0.0065    ,\n",
       "        0.398135  ,  0.0272465 ,  0.133349  ,  0.10507751,  0.1049065 ,\n",
       "        0.1549235 , -0.0372825 ,  0.325995  , -0.60782   , -0.51576   ,\n",
       "        0.065467  ,  0.0023595 ,  0.274515  , -0.21065651, -0.356005  ,\n",
       "       -0.056324  ,  0.28762   ,  0.0145985 ,  0.11610999,  0.045703  ,\n",
       "       -0.2065565 , -0.191125  , -0.12835498,  0.24805   , -0.118665  ,\n",
       "       -1.9667001 , -0.212569  ,  0.31939   , -0.028176  ,  0.42515498,\n",
       "        0.02916   , -0.168135  , -0.348585  , -0.1341665 ,  0.034515  ,\n",
       "       -0.04026   ,  0.11452949,  0.18024701, -0.01863   ,  0.059327  ,\n",
       "       -0.1144065 , -0.23353   ,  0.27453   , -0.145586  ,  0.0883805 ,\n",
       "        0.06223   , -0.3937143 , -0.2274    , -0.053295  ,  0.110396  ,\n",
       "        0.0617285 , -0.31761   , -0.25773   , -0.1563    , -0.20596799,\n",
       "       -0.01689   ,  0.17018971, -0.42855   , -0.038075  , -0.21994   ,\n",
       "        0.32631502,  0.1889    , -0.014415  ,  0.01146   ,  0.350005  ,\n",
       "        0.2385125 , -0.1558207 , -0.095515  ,  0.12649849,  0.1426475 ,\n",
       "        0.238215  ,  0.21388   , -0.070762  ,  0.32891   ,  0.0936221 ,\n",
       "        0.141489  ,  0.122679  ,  0.13614899, -0.10263335, -0.115137  ,\n",
       "        0.28328502, -0.063142  , -0.13279599,  0.193275  , -0.089568  ,\n",
       "       -0.37251002,  0.1470535 , -0.410835  ,  0.103415  ,  0.149254  ,\n",
       "       -0.0833285 , -0.10359301, -0.315535  , -0.0914025 , -0.256005  ,\n",
       "       -0.406275  ,  0.03688999,  0.36357   ,  0.424105  , -0.0439545 ,\n",
       "        0.0897165 , -0.253481  ,  0.271595  , -0.22367   ,  0.206834  ,\n",
       "        0.17470649,  0.0808555 ,  0.0126035 , -0.0534187 , -0.31809577,\n",
       "        0.16239001,  0.611     ,  0.277075  ,  0.268175  ,  0.56304   ,\n",
       "       -0.09004501, -0.137445  ,  0.13364   ,  0.11612301,  0.0670625 ,\n",
       "        0.0125285 ,  0.35744   , -0.1925    , -0.079045  ,  0.387095  ,\n",
       "       -0.1934955 , -0.1697    ,  0.015645  ,  0.158     ,  0.05162   ,\n",
       "       -0.317305  ,  0.12011349,  0.37933502, -0.1531    , -0.1524105 ,\n",
       "        0.109896  , -0.19593   ,  0.05954   ,  0.16069   ,  0.0480475 ,\n",
       "       -0.106784  ,  0.119065  ,  0.063765  , -0.06724   , -0.39038998,\n",
       "        0.54516   ,  0.30905   ,  0.23410001, -0.374215  ,  0.473715  ,\n",
       "       -0.2609965 , -0.0860165 ,  0.01305   ,  0.00689   , -0.11654001,\n",
       "       -0.32248   ,  0.16029501,  0.12455665,  0.28219998,  0.113065  ,\n",
       "        0.02579   ,  0.11029001, -0.082115  , -0.18291003,  0.0098435 ,\n",
       "        0.136485  ,  0.22912   , -0.195376  ,  0.20897   ,  0.104429  ,\n",
       "        0.158918  , -0.061111  , -0.32828498,  0.1030745 , -0.32914   ,\n",
       "       -0.32187   , -0.06835   , -0.3353    ,  0.152425  , -0.159344  ,\n",
       "       -0.43391   ,  0.3846915 , -0.02483   , -0.3084215 , -0.39942002],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'fox runs').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u'lion cat pet horse dog elephant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion lion 1.0\n",
      "lion cat 0.52654374\n",
      "lion pet 0.39923766\n",
      "lion horse 0.45301145\n",
      "lion dog 0.47424486\n",
      "lion elephant 0.71239567\n",
      "cat lion 0.52654374\n",
      "cat cat 1.0\n",
      "cat pet 0.7505456\n",
      "cat horse 0.48473355\n",
      "cat dog 0.80168545\n",
      "cat elephant 0.48571128\n",
      "pet lion 0.39923766\n",
      "pet cat 0.7505456\n",
      "pet pet 1.0\n",
      "pet horse 0.47499648\n",
      "pet dog 0.8057452\n",
      "pet elephant 0.3863391\n",
      "horse lion 0.45301145\n",
      "horse cat 0.48473355\n",
      "horse pet 0.47499648\n",
      "horse horse 1.0\n",
      "horse dog 0.6246276\n",
      "horse elephant 0.49068308\n",
      "dog lion 0.47424486\n",
      "dog cat 0.80168545\n",
      "dog pet 0.8057452\n",
      "dog horse 0.6246276\n",
      "dog dog 1.0\n",
      "dog elephant 0.45768416\n",
      "elephant lion 0.71239567\n",
      "elephant cat 0.48571128\n",
      "elephant pet 0.3863391\n",
      "elephant horse 0.49068308\n",
      "elephant dog 0.45768416\n",
      "elephant elephant 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u'dog cat marcially')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "marcially False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token.text,token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "cosine_similarity = lambda vec1, vec2: 1- spatial.distance.cosine(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = nlp.vocab['king'].vector\n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.1542e-01, -3.5068e-01,  4.2923e-01, -5.3825e-01, -1.8480e-01,\n",
       "       -3.1082e-01,  2.9196e-01, -7.1030e-01, -2.3867e-01,  1.8471e+00,\n",
       "       -3.6446e-01, -5.1282e-01,  1.2210e-01,  3.8909e-01, -7.3204e-02,\n",
       "        3.5462e-02,  3.3289e-01,  6.6466e-01,  2.7175e-02,  4.2021e-01,\n",
       "       -1.4520e-01,  3.7991e-01, -6.0520e-01,  1.0695e-01, -6.4716e-01,\n",
       "       -1.0739e-02, -3.9754e-01,  3.8857e-01, -2.0134e-01,  6.9813e-01,\n",
       "       -3.2411e-01,  7.3085e-01, -1.0930e-01, -2.3511e-01,  1.8482e-01,\n",
       "       -1.1595e-01, -7.1003e-01, -2.2974e-01, -4.1979e-01,  8.1004e-03,\n",
       "       -1.0504e-01, -4.4802e-01, -7.3928e-02, -4.2380e-01,  2.8482e-01,\n",
       "       -7.4517e-02,  9.8161e-02,  6.4602e-01, -2.5832e-01, -2.0452e-02,\n",
       "       -6.6863e-02,  5.1501e-01,  1.6758e-01,  1.2329e-01,  1.9636e-01,\n",
       "        1.1958e-01, -1.8296e-01, -1.4325e-01, -2.7758e-01,  5.0597e-02,\n",
       "       -6.6122e-02, -1.8920e-01,  3.3300e-01,  2.5319e-01,  6.6355e-01,\n",
       "        6.6735e-01,  4.9969e-01,  1.5481e-01, -8.4247e-02, -2.2947e-01,\n",
       "       -6.8367e-01, -2.9783e-01, -1.8651e-01, -4.7121e-01,  1.8272e-01,\n",
       "       -3.2604e-01, -6.8030e-02,  7.0073e-01,  3.3159e-01,  7.0393e-02,\n",
       "       -7.6987e-01,  5.9069e-01,  2.0592e-01,  1.7976e-01,  6.9525e-03,\n",
       "        5.7855e-02,  7.2047e-01, -7.7249e-01, -5.4188e-01, -1.2189e-01,\n",
       "       -3.1734e-03, -1.5960e-01,  1.6970e-01, -1.2546e-01,  8.7069e-01,\n",
       "       -4.6478e-01, -1.9302e-01, -4.5618e-01, -1.5419e-01,  8.1190e-01,\n",
       "       -2.0544e-01,  3.9454e-01, -3.1178e-01, -6.4318e-02, -4.4443e-02,\n",
       "       -5.8338e-01, -1.4792e-01,  1.7083e-02,  8.3239e-01, -1.1280e-01,\n",
       "        5.7826e-02,  1.7024e-01, -1.3635e-01, -2.8894e-01, -4.0590e-01,\n",
       "       -5.0685e-02,  4.9856e-01,  6.0885e-02,  1.9437e-01, -1.9811e-01,\n",
       "       -2.2335e-01, -2.5909e-02,  3.9846e-01,  4.4087e-01,  2.3195e-02,\n",
       "        9.8666e-02, -1.3004e-01, -2.0339e-01, -4.2958e-01, -7.9760e-03,\n",
       "       -3.2016e-01, -4.1094e-01, -1.0304e-01, -7.5565e-01,  1.7748e-02,\n",
       "       -2.0037e-01,  1.7185e-01,  2.1787e-01, -3.1685e-01,  2.2068e-02,\n",
       "       -2.5559e+00, -9.9115e-02,  1.8434e-01,  1.2448e-01, -5.9413e-02,\n",
       "       -4.5649e-02,  7.9018e-01,  2.4556e-01, -1.5059e-02, -7.8996e-01,\n",
       "        2.9087e-01, -3.9419e-01,  3.7617e-01,  1.5718e-01,  5.1356e-01,\n",
       "       -3.4219e-01,  5.0628e-02, -3.3254e-01, -1.4157e-01,  3.3355e-01,\n",
       "        4.4398e-01, -2.5451e-01, -3.3201e-02, -2.0958e-01,  3.8870e-01,\n",
       "       -2.4565e-01,  5.2391e-01,  4.3247e-01, -4.1701e-01,  2.9031e-01,\n",
       "       -7.8001e-01,  3.0100e-02, -6.1446e-02, -1.4029e-01, -5.5354e-01,\n",
       "       -1.9175e-01,  6.7279e-01, -1.1104e-01, -3.5486e-01, -2.8601e-01,\n",
       "        1.1720e-01, -4.5021e-01,  1.4004e-01, -5.7484e-01, -2.2531e-01,\n",
       "        4.1572e-01, -1.5950e-01, -2.7877e-01,  7.9785e-02,  1.9120e-02,\n",
       "       -9.8357e-01, -5.6998e-01, -3.4023e-02,  1.7382e-02, -1.7157e-02,\n",
       "       -2.8211e-01,  1.5573e-01, -1.3556e-01, -2.6296e-01, -7.4571e-01,\n",
       "        1.2015e-01,  5.4234e-01,  5.6783e-02, -7.5675e-02,  2.1820e-01,\n",
       "       -2.5679e-01,  2.3552e-01, -2.7111e-02, -1.9342e-01, -3.1088e-01,\n",
       "       -1.0600e-01,  4.9512e-01,  5.7932e-02,  3.8773e-01,  9.3160e-02,\n",
       "       -1.3782e-01,  2.4244e-01,  3.8098e-01,  9.1109e-04,  8.8338e-01,\n",
       "        4.3823e-01, -7.7041e-02,  1.1541e-01,  3.4702e-01,  5.9785e-01,\n",
       "        6.7012e-01, -6.0953e-02, -4.3872e-02, -4.0800e-01,  7.5721e-01,\n",
       "        2.4773e-01,  8.8926e-02, -1.8493e-01, -5.2339e-01,  8.5809e-02,\n",
       "       -6.0880e-01, -7.7463e-02, -2.6829e-01, -3.9021e-01, -1.5002e-01,\n",
       "        5.4297e-01, -4.1076e-01, -9.5215e-02, -2.9787e-01,  1.0041e-01,\n",
       "       -3.7774e-01,  7.5511e-01, -4.3910e-01, -6.1722e-01, -1.0360e+00,\n",
       "        6.9651e-01,  1.4157e-01, -4.4533e-01,  3.2702e-01,  3.8306e-02,\n",
       "        2.6765e-01,  5.4242e-02, -3.0242e-02, -4.5133e-01,  6.2505e-03,\n",
       "        2.7504e-01, -5.2413e-02, -1.9870e-01, -1.7869e-01, -2.4658e-01,\n",
       "       -3.7369e-01,  2.6174e-01,  4.1482e-01, -5.9277e-01,  6.1446e-02,\n",
       "        6.6261e-02,  1.0970e-01, -1.4388e-01, -3.2442e-01, -3.9016e-04,\n",
       "       -2.1392e-01,  3.2963e-01,  5.0402e-01,  1.3454e-01, -5.6133e-01,\n",
       "        1.0422e+00,  5.8985e-01,  1.4473e-01,  1.7745e-01,  1.6160e-01,\n",
       "        3.3230e-01,  2.2909e-01,  1.5774e-01, -3.5463e-01, -4.7642e-01,\n",
       "       -2.5822e-01,  2.3677e-01, -4.0255e-01, -3.5364e-01, -1.6697e-01,\n",
       "        7.0677e-01,  8.4272e-02,  1.1427e-01,  5.8221e-01, -1.0559e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector = king - man + woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_similarities = []\n",
    "\n",
    "# for all words in vocab , look for new vector similarity\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity = cosine_similarity(new_vector, word.vector)\n",
    "                computed_similarities.append((word,similarity))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_similarities = sorted(computed_similarities, key = lambda item:-item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'woman', 'she', 'lion', 'who', 'fox', 'elephant', 'when', 'dare', 'horse']\n"
     ]
    }
   ],
   "source": [
    "print([t[0].text for t in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis with NLTK (vader lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\khura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"This is an awesome tv series!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.532, 'pos': 0.468, 'compound': 0.6588}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= \"This was the best, and most awesome move EVER MADE!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.458, 'pos': 0.542, 'compound': 0.8877}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= \"This was the best and worst scenario\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.308, 'neu': 0.376, 'pos': 0.316, 'compound': 0.0258}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/amazonreviews.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>pos</td>\n",
       "      <td>A revelation of life in small town America in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>pos</td>\n",
       "      <td>Great biography of a very interesting journali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>neg</td>\n",
       "      <td>Interesting Subject; Poor Presentation: You'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>neg</td>\n",
       "      <td>Don't buy: The box looked used and it is obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pos</td>\n",
       "      <td>Beautiful Pen and Fast Delivery.: The pen was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                             review\n",
       "0      pos  Stuning even for the non-gamer: This sound tra...\n",
       "1      pos  The best soundtrack ever to anything.: I'm rea...\n",
       "2      pos  Amazing!: This soundtrack is my favorite music...\n",
       "3      pos  Excellent Soundtrack: I truly like this soundt...\n",
       "4      pos  Remember, Pull Your Jaw Off The Floor After He...\n",
       "...    ...                                                ...\n",
       "9995   pos  A revelation of life in small town America in ...\n",
       "9996   pos  Great biography of a very interesting journali...\n",
       "9997   neg  Interesting Subject; Poor Presentation: You'd ...\n",
       "9998   neg  Don't buy: The box looked used and it is obvio...\n",
       "9999   pos  Beautiful Pen and Fast Delivery.: The pen was ...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5097\n",
       "pos    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks=[]\n",
    "for i,lb,rv in df.itertuples():\n",
    "    if type(rv) == str:\n",
    "        if rv.isspace():\n",
    "            blanks.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'compound': 0.9454}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(df.iloc[0]['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['compound'] = df['scores'].apply(lambda d:d['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comp_score'] = df['compound'].apply(lambda score: 'pos' if score>=0 else 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound comp_score  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454        pos  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957        pos  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858        pos  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814        pos  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781        pos  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7092"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['label'],df['comp_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.51      0.64      5097\n",
      "         pos       0.64      0.91      0.75      4903\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.70     10000\n",
      "weighted avg       0.75      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['label'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = pd.read_csv('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11992"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(npr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df = 0.9,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document transform matrix\n",
    "dtm = cv.fit_transform(npr['Article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=7, random_state=42)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54777"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab of words\n",
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rotated'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()[42120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'commercialize'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_word_id = random.randint(0,33434)\n",
    "cv.get_feature_names()[random_word_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the topics\n",
    "len(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 54777)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.64332806e+00, 2.38014333e+03, 1.42900522e-01, ...,\n",
       "        1.43006821e-01, 1.42902042e-01, 1.42861626e-01],\n",
       "       [2.76191749e+01, 5.36394437e+02, 1.42857148e-01, ...,\n",
       "        1.42861973e-01, 1.42857147e-01, 1.42906875e-01],\n",
       "       [7.22783888e+00, 8.24033986e+02, 1.42857148e-01, ...,\n",
       "        6.14236247e+00, 2.14061364e+00, 1.42923753e-01],\n",
       "       ...,\n",
       "       [3.11488651e+00, 3.50409655e+02, 1.42857147e-01, ...,\n",
       "        1.42859912e-01, 1.42857146e-01, 1.42866614e-01],\n",
       "       [4.61486388e+01, 5.14408600e+01, 3.14281373e+00, ...,\n",
       "        1.43107628e-01, 1.43902481e-01, 2.14271779e+00],\n",
       "       [4.93991422e-01, 4.18841042e+02, 1.42857151e-01, ...,\n",
       "        1.42857146e-01, 1.43760101e-01, 1.42866201e-01]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.64332806e+00, 2.38014333e+03, 1.42900522e-01, ...,\n",
       "       1.43006821e-01, 1.42902042e-01, 1.42861626e-01])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2475, 18302, 35285, ..., 22673, 42561, 42993], dtype=int64)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowest to highest value\n",
    "single_topic.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33390, 36310, 21228, 10425, 31464,  8149, 36283, 22673, 42561,\n",
       "       42993], dtype=int64)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33390, 36310, 21228, 10425, 31464,  8149, 36283, 22673, 42561,\n",
       "       42993], dtype=int64)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_words = single_topic.argsort()[-10:]\n",
    "top_ten_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n",
      "percent\n",
      "government\n",
      "company\n",
      "million\n",
      "care\n",
      "people\n",
      "health\n",
      "said\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "for index in top_ten_words:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the highest probability words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for a topic #0\n",
      "['companies', 'money', 'year', 'federal', '000', 'new', 'percent', 'government', 'company', 'million', 'care', 'people', 'health', 'said', 'says']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #1\n",
      "['military', 'house', 'security', 'russia', 'government', 'npr', 'reports', 'says', 'news', 'people', 'told', 'police', 'president', 'trump', 'said']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #2\n",
      "['way', 'world', 'family', 'home', 'day', 'time', 'water', 'city', 'new', 'years', 'food', 'just', 'people', 'like', 'says']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #3\n",
      "['time', 'new', 'don', 'years', 'medical', 'disease', 'patients', 'just', 'children', 'study', 'like', 'women', 'health', 'people', 'says']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #4\n",
      "['voters', 'vote', 'election', 'party', 'new', 'obama', 'court', 'republican', 'campaign', 'people', 'state', 'president', 'clinton', 'said', 'trump']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #5\n",
      "['years', 'going', 've', 'life', 'don', 'new', 'way', 'music', 'really', 'time', 'know', 'think', 'people', 'just', 'like']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #6\n",
      "['student', 'years', 'data', 'science', 'university', 'people', 'time', 'schools', 'just', 'education', 'new', 'like', 'students', 'school', 'says']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(LDA.components_):\n",
    "    print(f\"The top 15 words for a topic #{i}\")\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article\n",
       "0      In the Washington of 2016, even when the polic...\n",
       "1        Donald Trump has used Twitter  —   his prefe...\n",
       "2        Donald Trump is unabashedly praising Russian...\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4      From photography, illustration and video, to d...\n",
       "...                                                  ...\n",
       "11987  The number of law enforcement officers shot an...\n",
       "11988    Trump is busy these days with victory tours,...\n",
       "11989  It’s always interesting for the Goats and Soda...\n",
       "11990  The election of Donald Trump was a surprise to...\n",
       "11991  Voters in the English city of Sunderland did s...\n",
       "\n",
       "[11992 rows x 1 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.68, 0.  , 0.  , 0.3 , 0.  , 0.  ])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].round(2)\n",
    "# array([0.02, 0.68, 0.  , 0.  , 0.3 , 0.  , 0.  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the Washington of 2016, even when the policy can be bipartisan, the politics cannot. And in that sense, this year shows little sign of ending on Dec. 31. When President Obama moved to sanction Russia over its alleged interference in the U. S. election just concluded, some Republicans who had long called for similar or more severe measures could scarcely bring themselves to approve. House Speaker Paul Ryan called the Obama measures ”appropriate” but also ”overdue” and ”a prime example of this administration’s ineffective foreign policy that has left America weaker in the eyes of the world.” Other GOP leaders sounded much the same theme. ”[We have] been urging President Obama for years to take strong action to deter Russia’s worldwide aggression, including its   operations,” wrote Rep. Devin Nunes,  . chairman of the House Intelligence Committee. ”Now with just a few weeks left in office, the president has suddenly decided that some stronger measures are indeed warranted.” Appearing on CNN, frequent Obama critic Trent Franks,  . called for ”much tougher” actions and said three times that Obama had ”finally found his tongue.” Meanwhile, at    and on Fox News, various spokesmen for   Trump said Obama’s real target was not the Russians at all but the man poised to take over the White House in less than three weeks. They spoke of Obama trying to ”tie Trump’s hands” or ”box him in,” meaning the   would be forced either to keep the sanctions or be at odds with Republicans who want to be tougher still on Moscow. Throughout 2016, Trump has repeatedly called not for sanctions but for closer ties with Russia, including cooperation in the fight against ISIS. Russia has battled ISIS in Syria on behalf of that country’s embattled dictator, Bashar Assad, bombing the besieged   city of Aleppo that fell to Assad’s forces this week. During the campaign, Trump even urged Russia to ”find” missing emails from the private server of his opponent, Hillary Clinton. He has exchanged public encomiums with Russian President Vladimir Putin on several occasions and added his doubts about the current U. S. levels of support for NATO  —   Putin’s longtime nemesis. There have also been suggestions that Trump’s extensive business dealings with various Russians are the reason he refuses to release his tax returns. All those issues have been disquieting to some Republicans for many months. Sens. John McCain,  . and Lindsay Graham,  . C. prominent senior members of the Armed Services Committee, have accepted the assessment of 17 U. S. intelligence agencies regarding the role of Russia in the hacking of various Democratic committees last year. That includes the FBI and CIA consensus that the Russian goal was not just to discredit American democracy but to defeat Clinton and elect Trump. They say the great majority of their Senate colleagues agree with them, and McCain has slated an Armed Services hearing on cyberthreats for Jan. 5. But the politicizing of the Russian actions  —   the idea that they helped Trump win  —   has also made the issue difficult for Republican leaders. It has allowed Trump supporters to push back on the intelligence agencies and say the entire issue is designed to undermine Trump’s legitimacy. Senate Majority Leader Mitch McConnell has so far resisted calls for a select committee to look into the Russian interference in the 2016 campaign. He has said it is enough for Sen. Richard Burr,  . C. to look into it as chairman of the Senate Intelligence Committee. Typically, Republican leaders and spokesmen say there is no evidence that the actual voting or tallying on Nov. 8 was compromised, and that is true. But it is also a red herring, as interference in those functions has not been alleged and is not the focus of the U. S. intelligence agencies’ concern. For his part, Trump has shown little interest in delving into what happened. He has cast doubt on the U. S. intelligence reports to date and suggested ”no one really knows what happened.” He also has suggested that computers make it very difficult to know who is using them. This week, Trump said it was time to ”get on with our lives and do more important things.” However, at week’s end he did agree to have an intelligence briefing on the subject next week. The   has not wanted the daily intelligence briefings available to him in recent weeks, preferring that they be given to the men he has chosen as his vice president (Mike Pence) and national security adviser (Mike Flynn) with Trump taking them only occasionally. The irony of this controversy arising at the eleventh hour of the Obama presidency can scarcely be overstated, and it defines the dilemma facing both the outgoing president and the incoming party in control. Obama appears to have been reluctant to retaliate against the Russian hacking before the election for fear of seeming to interfere with the election himself. The Republicans, meanwhile, have for years called for greater confrontation with the Russians, with Obama usually resisting. Obama did join with NATO in punishing the Russians with economic sanctions over the annexation of Crimea. Those sanctions may have been painful, coming as they did alongside falling prices for oil  —   the commodity that keeps the Russian economy afloat. On other occasions, despite Russian provocations through surrogates in Syria and elsewhere, Obama did not make overt moves to force Russia’s hand. That includes occasions when Russia was believed to be hacking critical computer systems in neighboring Ukraine, Estonia and Poland. But this week, following a chorus of confirmation from the U. S. intelligence community regarding the Russian role in computer hacking in the political campaign, Obama acted. He imposed a set of mostly diplomatic actions such as sanctioning some Russian officials, closing two diplomatic compounds and expelling 35 Russian diplomats. There may have been more damaging measures taken covertly, and some Russophobes in Washington held out hope for that. But the visible portion of the program scarcely amounted to major retribution. And Putin saw fit to diminish the Obama sanctions further by declining to respond. Although his government has steadfastly denied any interference in the U. S. election, Putin rejected his own foreign minister’s recommended package of    responses. (He even sent an invitation for U. S. diplomats to send their children to a holiday party in Moscow.) That allowed Putin to appear for the moment to be ”the bigger man,” even as he spurned Obama and kept up what has looked like a public bromance with Trump, who tweeted: ”Great move on delay (by V. Putin)   I always knew he was very smart!” At the moment it may seem that the overall Russia question amounts to the first crisis facing the Trump presidency. Whether forced by this campaign interference issue or not, Trump must grasp the nettle of a relationship Mitt Romney once called the greatest threat to U. S. security in the world. To be sure, Trump needs to dispel doubts about his ability to stand up to Putin, who has bullied and cajoled his way to center stage in recent world affairs. But Trump also seems determined to turn the page on past U. S. commitments, from free trade philosophy to funding of NATO and the United Nations. And if his Twitter account is any guide, Trump shows little concern about the conundrum others perceive to be facing him. Above all, Trump has shown himself determined to play by his own rules. A year ago, many were confident that would not work for him in the world of presidential politics. We are about to find out whether it works for him in the Oval Office.'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr['Article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article  Topic\n",
       "0      In the Washington of 2016, even when the polic...      1\n",
       "1        Donald Trump has used Twitter  —   his prefe...      1\n",
       "2        Donald Trump is unabashedly praising Russian...      1\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...      1\n",
       "4      From photography, illustration and video, to d...      2\n",
       "...                                                  ...    ...\n",
       "11987  The number of law enforcement officers shot an...      1\n",
       "11988    Trump is busy these days with victory tours,...      4\n",
       "11989  It’s always interesting for the Goats and Soda...      3\n",
       "11990  The election of Donald Trump was a surprise to...      4\n",
       "11991  Voters in the English city of Sunderland did s...      0\n",
       "\n",
       "[11992 rows x 2 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-neg matrix factorization: unsupervised - dimensionality reduction and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "npr = pd.read_csv('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article\n",
       "0      In the Washington of 2016, even when the polic...\n",
       "1        Donald Trump has used Twitter  —   his prefe...\n",
       "2        Donald Trump is unabashedly praising Russian...\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4      From photography, illustration and video, to d...\n",
       "...                                                  ...\n",
       "11987  The number of law enforcement officers shot an...\n",
       "11988    Trump is busy these days with victory tours,...\n",
       "11989  It’s always interesting for the Goats and Soda...\n",
       "11990  The election of Donald Trump was a surprise to...\n",
       "11991  Voters in the English city of Sunderland did s...\n",
       "\n",
       "[11992 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.95,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tfidf.fit_transform(npr['Article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=7, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alienated'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()[2399]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for a topic #0\n",
      "['new', 'research', 'like', 'patients', 'health', 'disease', 'percent', 'women', 'virus', 'study', 'water', 'food', 'people', 'zika', 'says']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #1\n",
      "['gop', 'pence', 'presidential', 'russia', 'administration', 'election', 'republican', 'obama', 'white', 'house', 'donald', 'campaign', 'said', 'president', 'trump']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #2\n",
      "['senate', 'house', 'people', 'act', 'law', 'tax', 'plan', 'republicans', 'affordable', 'obamacare', 'coverage', 'medicaid', 'insurance', 'care', 'health']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #3\n",
      "['officers', 'syria', 'security', 'department', 'law', 'isis', 'russia', 'government', 'state', 'attack', 'president', 'reports', 'court', 'said', 'police']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #4\n",
      "['primary', 'cruz', 'election', 'democrats', 'percent', 'party', 'delegates', 'vote', 'state', 'democratic', 'hillary', 'campaign', 'voters', 'sanders', 'clinton']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #5\n",
      "['love', 've', 'don', 'album', 'way', 'time', 'song', 'life', 'really', 'know', 'people', 'think', 'just', 'music', 'like']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #6\n",
      "['teacher', 'state', 'high', 'says', 'parents', 'devos', 'children', 'college', 'kids', 'teachers', 'student', 'education', 'schools', 'school', 'students']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"The top 15 words for a topic #{i}\")\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = nmf_model.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Topic\n",
       "0  In the Washington of 2016, even when the polic...      1\n",
       "1    Donald Trump has used Twitter  —   his prefe...      1\n",
       "2    Donald Trump is unabashedly praising Russian...      1\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...      3\n",
       "4  From photography, illustration and video, to d...      6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytopic_dict = {0:'health',1:'election',2:'legis',3:'poli',4:'election',5:'music',6:'edu'}\n",
    "npr['Topic Label'] = npr['Topic'].map(mytopic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>3</td>\n",
       "      <td>poli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>6</td>\n",
       "      <td>edu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Topic Topic Label\n",
       "0  In the Washington of 2016, even when the polic...      1    election\n",
       "1    Donald Trump has used Twitter  —   his prefe...      1    election\n",
       "2    Donald Trump is unabashedly praising Russian...      1    election\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...      3        poli\n",
       "4  From photography, illustration and video, to d...      6         edu"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for target var\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_obj = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_obj.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler_obj.transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler_obj.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_dim=4,activation='relu'))\n",
    "model.add(Dense(8,input_dim=4,activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 - 0s - loss: 1.1131 - accuracy: 0.3500\n",
      "Epoch 2/150\n",
      "4/4 - 0s - loss: 1.0980 - accuracy: 0.3500\n",
      "Epoch 3/150\n",
      "4/4 - 0s - loss: 1.0833 - accuracy: 0.3500\n",
      "Epoch 4/150\n",
      "4/4 - 0s - loss: 1.0703 - accuracy: 0.3500\n",
      "Epoch 5/150\n",
      "4/4 - 0s - loss: 1.0579 - accuracy: 0.3500\n",
      "Epoch 6/150\n",
      "4/4 - 0s - loss: 1.0476 - accuracy: 0.3500\n",
      "Epoch 7/150\n",
      "4/4 - 0s - loss: 1.0373 - accuracy: 0.3600\n",
      "Epoch 8/150\n",
      "4/4 - 0s - loss: 1.0292 - accuracy: 0.3600\n",
      "Epoch 9/150\n",
      "4/4 - 0s - loss: 1.0211 - accuracy: 0.3600\n",
      "Epoch 10/150\n",
      "4/4 - 0s - loss: 1.0149 - accuracy: 0.3500\n",
      "Epoch 11/150\n",
      "4/4 - 0s - loss: 1.0083 - accuracy: 0.3500\n",
      "Epoch 12/150\n",
      "4/4 - 0s - loss: 1.0023 - accuracy: 0.3500\n",
      "Epoch 13/150\n",
      "4/4 - 0s - loss: 0.9961 - accuracy: 0.3400\n",
      "Epoch 14/150\n",
      "4/4 - 0s - loss: 0.9904 - accuracy: 0.3400\n",
      "Epoch 15/150\n",
      "4/4 - 0s - loss: 0.9839 - accuracy: 0.3600\n",
      "Epoch 16/150\n",
      "4/4 - 0s - loss: 0.9777 - accuracy: 0.3600\n",
      "Epoch 17/150\n",
      "4/4 - 0s - loss: 0.9716 - accuracy: 0.3600\n",
      "Epoch 18/150\n",
      "4/4 - 0s - loss: 0.9655 - accuracy: 0.3700\n",
      "Epoch 19/150\n",
      "4/4 - 0s - loss: 0.9599 - accuracy: 0.4100\n",
      "Epoch 20/150\n",
      "4/4 - 0s - loss: 0.9542 - accuracy: 0.4000\n",
      "Epoch 21/150\n",
      "4/4 - 0s - loss: 0.9487 - accuracy: 0.4700\n",
      "Epoch 22/150\n",
      "4/4 - 0s - loss: 0.9430 - accuracy: 0.4800\n",
      "Epoch 23/150\n",
      "4/4 - 0s - loss: 0.9374 - accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "4/4 - 0s - loss: 0.9318 - accuracy: 0.5300\n",
      "Epoch 25/150\n",
      "4/4 - 0s - loss: 0.9263 - accuracy: 0.5600\n",
      "Epoch 26/150\n",
      "4/4 - 0s - loss: 0.9202 - accuracy: 0.5600\n",
      "Epoch 27/150\n",
      "4/4 - 0s - loss: 0.9141 - accuracy: 0.5600\n",
      "Epoch 28/150\n",
      "4/4 - 0s - loss: 0.9077 - accuracy: 0.5900\n",
      "Epoch 29/150\n",
      "4/4 - 0s - loss: 0.9017 - accuracy: 0.6100\n",
      "Epoch 30/150\n",
      "4/4 - 0s - loss: 0.8960 - accuracy: 0.6000\n",
      "Epoch 31/150\n",
      "4/4 - 0s - loss: 0.8903 - accuracy: 0.6100\n",
      "Epoch 32/150\n",
      "4/4 - 0s - loss: 0.8852 - accuracy: 0.6100\n",
      "Epoch 33/150\n",
      "4/4 - 0s - loss: 0.8800 - accuracy: 0.6100\n",
      "Epoch 34/150\n",
      "4/4 - 0s - loss: 0.8753 - accuracy: 0.6200\n",
      "Epoch 35/150\n",
      "4/4 - 0s - loss: 0.8706 - accuracy: 0.6100\n",
      "Epoch 36/150\n",
      "4/4 - 0s - loss: 0.8658 - accuracy: 0.6200\n",
      "Epoch 37/150\n",
      "4/4 - 0s - loss: 0.8611 - accuracy: 0.6200\n",
      "Epoch 38/150\n",
      "4/4 - 0s - loss: 0.8565 - accuracy: 0.6200\n",
      "Epoch 39/150\n",
      "4/4 - 0s - loss: 0.8521 - accuracy: 0.6200\n",
      "Epoch 40/150\n",
      "4/4 - 0s - loss: 0.8480 - accuracy: 0.6300\n",
      "Epoch 41/150\n",
      "4/4 - 0s - loss: 0.8436 - accuracy: 0.6300\n",
      "Epoch 42/150\n",
      "4/4 - 0s - loss: 0.8394 - accuracy: 0.6400\n",
      "Epoch 43/150\n",
      "4/4 - 0s - loss: 0.8354 - accuracy: 0.6400\n",
      "Epoch 44/150\n",
      "4/4 - 0s - loss: 0.8311 - accuracy: 0.6400\n",
      "Epoch 45/150\n",
      "4/4 - 0s - loss: 0.8270 - accuracy: 0.6600\n",
      "Epoch 46/150\n",
      "4/4 - 0s - loss: 0.8231 - accuracy: 0.6600\n",
      "Epoch 47/150\n",
      "4/4 - 0s - loss: 0.8187 - accuracy: 0.6700\n",
      "Epoch 48/150\n",
      "4/4 - 0s - loss: 0.8144 - accuracy: 0.6600\n",
      "Epoch 49/150\n",
      "4/4 - 0s - loss: 0.8104 - accuracy: 0.6800\n",
      "Epoch 50/150\n",
      "4/4 - 0s - loss: 0.8061 - accuracy: 0.6600\n",
      "Epoch 51/150\n",
      "4/4 - 0s - loss: 0.8016 - accuracy: 0.6600\n",
      "Epoch 52/150\n",
      "4/4 - 0s - loss: 0.7973 - accuracy: 0.6600\n",
      "Epoch 53/150\n",
      "4/4 - 0s - loss: 0.7932 - accuracy: 0.6600\n",
      "Epoch 54/150\n",
      "4/4 - 0s - loss: 0.7893 - accuracy: 0.6600\n",
      "Epoch 55/150\n",
      "4/4 - 0s - loss: 0.7852 - accuracy: 0.6600\n",
      "Epoch 56/150\n",
      "4/4 - 0s - loss: 0.7812 - accuracy: 0.6600\n",
      "Epoch 57/150\n",
      "4/4 - 0s - loss: 0.7771 - accuracy: 0.6600\n",
      "Epoch 58/150\n",
      "4/4 - 0s - loss: 0.7732 - accuracy: 0.6600\n",
      "Epoch 59/150\n",
      "4/4 - 0s - loss: 0.7693 - accuracy: 0.6500\n",
      "Epoch 60/150\n",
      "4/4 - 0s - loss: 0.7654 - accuracy: 0.6500\n",
      "Epoch 61/150\n",
      "4/4 - 0s - loss: 0.7615 - accuracy: 0.6500\n",
      "Epoch 62/150\n",
      "4/4 - 0s - loss: 0.7578 - accuracy: 0.6500\n",
      "Epoch 63/150\n",
      "4/4 - 0s - loss: 0.7541 - accuracy: 0.6500\n",
      "Epoch 64/150\n",
      "4/4 - 0s - loss: 0.7501 - accuracy: 0.6500\n",
      "Epoch 65/150\n",
      "4/4 - 0s - loss: 0.7469 - accuracy: 0.6500\n",
      "Epoch 66/150\n",
      "4/4 - 0s - loss: 0.7431 - accuracy: 0.6500\n",
      "Epoch 67/150\n",
      "4/4 - 0s - loss: 0.7396 - accuracy: 0.6500\n",
      "Epoch 68/150\n",
      "4/4 - 0s - loss: 0.7358 - accuracy: 0.6600\n",
      "Epoch 69/150\n",
      "4/4 - 0s - loss: 0.7320 - accuracy: 0.6500\n",
      "Epoch 70/150\n",
      "4/4 - 0s - loss: 0.7280 - accuracy: 0.6500\n",
      "Epoch 71/150\n",
      "4/4 - 0s - loss: 0.7243 - accuracy: 0.6500\n",
      "Epoch 72/150\n",
      "4/4 - 0s - loss: 0.7204 - accuracy: 0.6500\n",
      "Epoch 73/150\n",
      "4/4 - 0s - loss: 0.7171 - accuracy: 0.6500\n",
      "Epoch 74/150\n",
      "4/4 - 0s - loss: 0.7144 - accuracy: 0.6700\n",
      "Epoch 75/150\n",
      "4/4 - 0s - loss: 0.7109 - accuracy: 0.6700\n",
      "Epoch 76/150\n",
      "4/4 - 0s - loss: 0.7073 - accuracy: 0.6700\n",
      "Epoch 77/150\n",
      "4/4 - 0s - loss: 0.7038 - accuracy: 0.6700\n",
      "Epoch 78/150\n",
      "4/4 - 0s - loss: 0.7006 - accuracy: 0.6700\n",
      "Epoch 79/150\n",
      "4/4 - 0s - loss: 0.6972 - accuracy: 0.6900\n",
      "Epoch 80/150\n",
      "4/4 - 0s - loss: 0.6940 - accuracy: 0.7000\n",
      "Epoch 81/150\n",
      "4/4 - 0s - loss: 0.6909 - accuracy: 0.7100\n",
      "Epoch 82/150\n",
      "4/4 - 0s - loss: 0.6876 - accuracy: 0.7200\n",
      "Epoch 83/150\n",
      "4/4 - 0s - loss: 0.6846 - accuracy: 0.7600\n",
      "Epoch 84/150\n",
      "4/4 - 0s - loss: 0.6815 - accuracy: 0.7600\n",
      "Epoch 85/150\n",
      "4/4 - 0s - loss: 0.6785 - accuracy: 0.7800\n",
      "Epoch 86/150\n",
      "4/4 - 0s - loss: 0.6752 - accuracy: 0.7800\n",
      "Epoch 87/150\n",
      "4/4 - 0s - loss: 0.6718 - accuracy: 0.7700\n",
      "Epoch 88/150\n",
      "4/4 - 0s - loss: 0.6686 - accuracy: 0.7700\n",
      "Epoch 89/150\n",
      "4/4 - 0s - loss: 0.6650 - accuracy: 0.7700\n",
      "Epoch 90/150\n",
      "4/4 - 0s - loss: 0.6613 - accuracy: 0.7700\n",
      "Epoch 91/150\n",
      "4/4 - 0s - loss: 0.6578 - accuracy: 0.7700\n",
      "Epoch 92/150\n",
      "4/4 - 0s - loss: 0.6545 - accuracy: 0.7500\n",
      "Epoch 93/150\n",
      "4/4 - 0s - loss: 0.6507 - accuracy: 0.7500\n",
      "Epoch 94/150\n",
      "4/4 - 0s - loss: 0.6473 - accuracy: 0.7400\n",
      "Epoch 95/150\n",
      "4/4 - 0s - loss: 0.6438 - accuracy: 0.7200\n",
      "Epoch 96/150\n",
      "4/4 - 0s - loss: 0.6405 - accuracy: 0.7200\n",
      "Epoch 97/150\n",
      "4/4 - 0s - loss: 0.6371 - accuracy: 0.7400\n",
      "Epoch 98/150\n",
      "4/4 - 0s - loss: 0.6338 - accuracy: 0.7500\n",
      "Epoch 99/150\n",
      "4/4 - 0s - loss: 0.6306 - accuracy: 0.7500\n",
      "Epoch 100/150\n",
      "4/4 - 0s - loss: 0.6275 - accuracy: 0.7600\n",
      "Epoch 101/150\n",
      "4/4 - 0s - loss: 0.6238 - accuracy: 0.7700\n",
      "Epoch 102/150\n",
      "4/4 - 0s - loss: 0.6204 - accuracy: 0.7400\n",
      "Epoch 103/150\n",
      "4/4 - 0s - loss: 0.6181 - accuracy: 0.7200\n",
      "Epoch 104/150\n",
      "4/4 - 0s - loss: 0.6143 - accuracy: 0.7200\n",
      "Epoch 105/150\n",
      "4/4 - 0s - loss: 0.6113 - accuracy: 0.7200\n",
      "Epoch 106/150\n",
      "4/4 - 0s - loss: 0.6085 - accuracy: 0.7100\n",
      "Epoch 107/150\n",
      "4/4 - 0s - loss: 0.6051 - accuracy: 0.7200\n",
      "Epoch 108/150\n",
      "4/4 - 0s - loss: 0.6023 - accuracy: 0.7200\n",
      "Epoch 109/150\n",
      "4/4 - 0s - loss: 0.5993 - accuracy: 0.7200\n",
      "Epoch 110/150\n",
      "4/4 - 0s - loss: 0.5963 - accuracy: 0.7200\n",
      "Epoch 111/150\n",
      "4/4 - 0s - loss: 0.5936 - accuracy: 0.7200\n",
      "Epoch 112/150\n",
      "4/4 - 0s - loss: 0.5903 - accuracy: 0.7200\n",
      "Epoch 113/150\n",
      "4/4 - 0s - loss: 0.5876 - accuracy: 0.7100\n",
      "Epoch 114/150\n",
      "4/4 - 0s - loss: 0.5848 - accuracy: 0.7100\n",
      "Epoch 115/150\n",
      "4/4 - 0s - loss: 0.5817 - accuracy: 0.7100\n",
      "Epoch 116/150\n",
      "4/4 - 0s - loss: 0.5783 - accuracy: 0.7200\n",
      "Epoch 117/150\n",
      "4/4 - 0s - loss: 0.5753 - accuracy: 0.7700\n",
      "Epoch 118/150\n",
      "4/4 - 0s - loss: 0.5724 - accuracy: 0.8100\n",
      "Epoch 119/150\n",
      "4/4 - 0s - loss: 0.5705 - accuracy: 0.8700\n",
      "Epoch 120/150\n",
      "4/4 - 0s - loss: 0.5682 - accuracy: 0.9100\n",
      "Epoch 121/150\n",
      "4/4 - 0s - loss: 0.5652 - accuracy: 0.9200\n",
      "Epoch 122/150\n",
      "4/4 - 0s - loss: 0.5621 - accuracy: 0.9200\n",
      "Epoch 123/150\n",
      "4/4 - 0s - loss: 0.5593 - accuracy: 0.8700\n",
      "Epoch 124/150\n",
      "4/4 - 0s - loss: 0.5561 - accuracy: 0.8300\n",
      "Epoch 125/150\n",
      "4/4 - 0s - loss: 0.5532 - accuracy: 0.8100\n",
      "Epoch 126/150\n",
      "4/4 - 0s - loss: 0.5506 - accuracy: 0.8000\n",
      "Epoch 127/150\n",
      "4/4 - 0s - loss: 0.5482 - accuracy: 0.8100\n",
      "Epoch 128/150\n",
      "4/4 - 0s - loss: 0.5454 - accuracy: 0.8400\n",
      "Epoch 129/150\n",
      "4/4 - 0s - loss: 0.5428 - accuracy: 0.8700\n",
      "Epoch 130/150\n",
      "4/4 - 0s - loss: 0.5404 - accuracy: 0.8700\n",
      "Epoch 131/150\n",
      "4/4 - 0s - loss: 0.5378 - accuracy: 0.8700\n",
      "Epoch 132/150\n",
      "4/4 - 0s - loss: 0.5350 - accuracy: 0.8600\n",
      "Epoch 133/150\n",
      "4/4 - 0s - loss: 0.5323 - accuracy: 0.8600\n",
      "Epoch 134/150\n",
      "4/4 - 0s - loss: 0.5296 - accuracy: 0.8500\n",
      "Epoch 135/150\n",
      "4/4 - 0s - loss: 0.5271 - accuracy: 0.8600\n",
      "Epoch 136/150\n",
      "4/4 - 0s - loss: 0.5243 - accuracy: 0.8500\n",
      "Epoch 137/150\n",
      "4/4 - 0s - loss: 0.5217 - accuracy: 0.8300\n",
      "Epoch 138/150\n",
      "4/4 - 0s - loss: 0.5194 - accuracy: 0.8100\n",
      "Epoch 139/150\n",
      "4/4 - 0s - loss: 0.5168 - accuracy: 0.8000\n",
      "Epoch 140/150\n",
      "4/4 - 0s - loss: 0.5142 - accuracy: 0.8100\n",
      "Epoch 141/150\n",
      "4/4 - 0s - loss: 0.5117 - accuracy: 0.8300\n",
      "Epoch 142/150\n",
      "4/4 - 0s - loss: 0.5095 - accuracy: 0.8300\n",
      "Epoch 143/150\n",
      "4/4 - 0s - loss: 0.5069 - accuracy: 0.8700\n",
      "Epoch 144/150\n",
      "4/4 - 0s - loss: 0.5043 - accuracy: 0.8600\n",
      "Epoch 145/150\n",
      "4/4 - 0s - loss: 0.5019 - accuracy: 0.8400\n",
      "Epoch 146/150\n",
      "4/4 - 0s - loss: 0.4997 - accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150\n",
      "4/4 - 0s - loss: 0.4973 - accuracy: 0.8500\n",
      "Epoch 148/150\n",
      "4/4 - 0s - loss: 0.4947 - accuracy: 0.8500\n",
      "Epoch 149/150\n",
      "4/4 - 0s - loss: 0.4924 - accuracy: 0.8800\n",
      "Epoch 150/150\n",
      "4/4 - 0s - loss: 0.4903 - accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d1819b53c8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train,y_train,epochs=150, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 2, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 2, 0,\n",
       "       0, 1, 2, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict_classes(scaled_X_test) ------deprecated\n",
    "np.argmax(model.predict(scaled_X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0],\n",
       "       [ 0,  9,  6],\n",
       "       [ 0,  0, 16]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.argmax(axis=1),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.60      0.75        15\n",
      "           2       0.73      1.00      0.84        16\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.91      0.87      0.86        50\n",
      "weighted avg       0.91      0.88      0.87        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.argmax(axis=1),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('irismodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('irismodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x2d181012e48>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation with LSTM - using KEras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "        \n",
    "    return str_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en',disable=['parser','tagger','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623\n",
    "# picked 1198623 from full text moby dick book for future scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25 + 1\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956,\n",
       " 14,\n",
       " 263,\n",
       " 51,\n",
       " 261,\n",
       " 408,\n",
       " 87,\n",
       " 219,\n",
       " 129,\n",
       " 111,\n",
       " 954,\n",
       " 260,\n",
       " 50,\n",
       " 43,\n",
       " 38,\n",
       " 315,\n",
       " 7,\n",
       " 23,\n",
       " 546,\n",
       " 3,\n",
       " 150,\n",
       " 259,\n",
       " 6,\n",
       " 2712,\n",
       " 14,\n",
       " 24]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'the',\n",
       " 2: 'a',\n",
       " 3: 'and',\n",
       " 4: 'of',\n",
       " 5: 'i',\n",
       " 6: 'to',\n",
       " 7: 'in',\n",
       " 8: 'it',\n",
       " 9: 'that',\n",
       " 10: 'he',\n",
       " 11: 'his',\n",
       " 12: 'was',\n",
       " 13: 'but',\n",
       " 14: 'me',\n",
       " 15: 'with',\n",
       " 16: 'as',\n",
       " 17: 'at',\n",
       " 18: 'this',\n",
       " 19: 'you',\n",
       " 20: 'is',\n",
       " 21: 'all',\n",
       " 22: 'for',\n",
       " 23: 'my',\n",
       " 24: 'on',\n",
       " 25: 'be',\n",
       " 26: \"'s\",\n",
       " 27: 'not',\n",
       " 28: 'from',\n",
       " 29: 'there',\n",
       " 30: 'one',\n",
       " 31: 'up',\n",
       " 32: 'what',\n",
       " 33: 'him',\n",
       " 34: 'so',\n",
       " 35: 'bed',\n",
       " 36: 'now',\n",
       " 37: 'about',\n",
       " 38: 'no',\n",
       " 39: 'into',\n",
       " 40: 'by',\n",
       " 41: 'were',\n",
       " 42: 'out',\n",
       " 43: 'or',\n",
       " 44: 'harpooneer',\n",
       " 45: 'had',\n",
       " 46: 'then',\n",
       " 47: 'have',\n",
       " 48: 'an',\n",
       " 49: 'upon',\n",
       " 50: 'little',\n",
       " 51: 'some',\n",
       " 52: 'old',\n",
       " 53: 'like',\n",
       " 54: 'if',\n",
       " 55: 'they',\n",
       " 56: 'would',\n",
       " 57: 'do',\n",
       " 58: 'over',\n",
       " 59: 'landlord',\n",
       " 60: 'thought',\n",
       " 61: 'room',\n",
       " 62: 'when',\n",
       " 63: 'could',\n",
       " 64: \"n't\",\n",
       " 65: 'night',\n",
       " 66: 'here',\n",
       " 67: 'head',\n",
       " 68: 'such',\n",
       " 69: 'which',\n",
       " 70: 'man',\n",
       " 71: 'did',\n",
       " 72: 'sea',\n",
       " 73: 'time',\n",
       " 74: 'other',\n",
       " 75: 'very',\n",
       " 76: 'go',\n",
       " 77: 'these',\n",
       " 78: 'more',\n",
       " 79: 'though',\n",
       " 80: 'first',\n",
       " 81: 'sort',\n",
       " 82: 'said',\n",
       " 83: 'last',\n",
       " 84: 'down',\n",
       " 85: 'most',\n",
       " 86: 'been',\n",
       " 87: 'never',\n",
       " 88: 'your',\n",
       " 89: 'them',\n",
       " 90: 'must',\n",
       " 91: 'tell',\n",
       " 92: 'much',\n",
       " 93: 'good',\n",
       " 94: 'see',\n",
       " 95: 'off',\n",
       " 96: 'myself',\n",
       " 97: 'are',\n",
       " 98: 'yet',\n",
       " 99: 'sleep',\n",
       " 100: 'who',\n",
       " 101: 'seemed',\n",
       " 102: 'light',\n",
       " 103: 'way',\n",
       " 104: 'their',\n",
       " 105: 'just',\n",
       " 106: 'being',\n",
       " 107: 'than',\n",
       " 108: 'place',\n",
       " 109: 'queequeg',\n",
       " 110: 'great',\n",
       " 111: 'long',\n",
       " 112: 'before',\n",
       " 113: 'get',\n",
       " 114: 'round',\n",
       " 115: 'where',\n",
       " 116: 'still',\n",
       " 117: 'any',\n",
       " 118: 'too',\n",
       " 119: 'only',\n",
       " 120: 'door',\n",
       " 121: 'can',\n",
       " 122: 'himself',\n",
       " 123: 'heads',\n",
       " 124: 'come',\n",
       " 125: 'ever',\n",
       " 126: 'two',\n",
       " 127: 'enough',\n",
       " 128: 'made',\n",
       " 129: 'how',\n",
       " 130: 'hand',\n",
       " 131: 'same',\n",
       " 132: 'looking',\n",
       " 133: 'something',\n",
       " 134: 'may',\n",
       " 135: \"'\",\n",
       " 136: 'almost',\n",
       " 137: 'say',\n",
       " 138: 'should',\n",
       " 139: 'side',\n",
       " 140: 'why',\n",
       " 141: 'own',\n",
       " 142: 'we',\n",
       " 143: 'new',\n",
       " 144: 'again',\n",
       " 145: 'came',\n",
       " 146: 'arm',\n",
       " 147: 'house',\n",
       " 148: 'away',\n",
       " 149: 'might',\n",
       " 150: 'nothing',\n",
       " 151: 'take',\n",
       " 152: 'towards',\n",
       " 153: 'will',\n",
       " 154: 'under',\n",
       " 155: 'going',\n",
       " 156: 'make',\n",
       " 157: 'whale',\n",
       " 158: 'stood',\n",
       " 159: 'boots',\n",
       " 160: 'ye',\n",
       " 161: 'back',\n",
       " 162: \"'ll\",\n",
       " 163: 'tomahawk',\n",
       " 164: 'part',\n",
       " 165: 'world',\n",
       " 166: 'soon',\n",
       " 167: 'water',\n",
       " 168: 'against',\n",
       " 169: 'those',\n",
       " 170: 'between',\n",
       " 171: 'after',\n",
       " 172: 'whaling',\n",
       " 173: 'lay',\n",
       " 174: 'took',\n",
       " 175: 'half',\n",
       " 176: 'began',\n",
       " 177: 'face',\n",
       " 178: 'streets',\n",
       " 179: 'land',\n",
       " 180: 'better',\n",
       " 181: 'once',\n",
       " 182: 'voyage',\n",
       " 183: 'give',\n",
       " 184: 'rather',\n",
       " 185: 'well',\n",
       " 186: 'however',\n",
       " 187: 'else',\n",
       " 188: 'heard',\n",
       " 189: 'put',\n",
       " 190: 'stop',\n",
       " 191: 'dark',\n",
       " 192: 'went',\n",
       " 193: 'black',\n",
       " 194: 'window',\n",
       " 195: 'cannibal',\n",
       " 196: 'fire',\n",
       " 197: 'every',\n",
       " 198: 'ship',\n",
       " 199: 'stand',\n",
       " 200: 'strange',\n",
       " 201: 'without',\n",
       " 202: 'feet',\n",
       " 203: 'whether',\n",
       " 204: 'because',\n",
       " 205: 'eyes',\n",
       " 206: 'think',\n",
       " 207: 'thinks',\n",
       " 208: 'idea',\n",
       " 209: 'bag',\n",
       " 210: 'nantucket',\n",
       " 211: 'late',\n",
       " 212: 'cold',\n",
       " 213: 'our',\n",
       " 214: 'found',\n",
       " 215: 'full',\n",
       " 216: 'morning',\n",
       " 217: 'sleeping',\n",
       " 218: 'got',\n",
       " 219: 'mind',\n",
       " 220: 'her',\n",
       " 221: 'right',\n",
       " 222: 'its',\n",
       " 223: 'look',\n",
       " 224: 'town',\n",
       " 225: 'south',\n",
       " 226: 'does',\n",
       " 227: 'let',\n",
       " 228: 'set',\n",
       " 229: 'yourself',\n",
       " 230: 'image',\n",
       " 231: 'saw',\n",
       " 232: 'am',\n",
       " 233: 'besides',\n",
       " 234: 'sailor',\n",
       " 235: 'seas',\n",
       " 236: 'rolled',\n",
       " 237: 'till',\n",
       " 238: 'day',\n",
       " 239: 'sign',\n",
       " 240: 'looked',\n",
       " 241: 'hard',\n",
       " 242: 'moment',\n",
       " 243: 'corner',\n",
       " 244: 'entry',\n",
       " 245: 'four',\n",
       " 246: 'wall',\n",
       " 247: 'savage',\n",
       " 248: 'table',\n",
       " 249: 'indeed',\n",
       " 250: 'bench',\n",
       " 251: 'chest',\n",
       " 252: 'while',\n",
       " 253: 'stranger',\n",
       " 254: 'possible',\n",
       " 255: 'feeling',\n",
       " 256: 'floor',\n",
       " 257: 'squares',\n",
       " 258: 'hat',\n",
       " 259: 'particular',\n",
       " 260: 'having',\n",
       " 261: 'years',\n",
       " 262: 'harpoon',\n",
       " 263: 'ishmael',\n",
       " 264: 'whenever',\n",
       " 265: 'mouth',\n",
       " 266: 'high',\n",
       " 267: 'knew',\n",
       " 268: 'men',\n",
       " 269: 'hours',\n",
       " 270: 'green',\n",
       " 271: 'bit',\n",
       " 272: 'within',\n",
       " 273: 'picture',\n",
       " 274: 'told',\n",
       " 275: 'story',\n",
       " 276: 'mean',\n",
       " 277: 'speak',\n",
       " 278: 'order',\n",
       " 279: 'making',\n",
       " 280: 'even',\n",
       " 281: 'perhaps',\n",
       " 282: 'things',\n",
       " 283: 'answer',\n",
       " 284: 'parts',\n",
       " 285: 'wild',\n",
       " 286: 'reason',\n",
       " 287: 'young',\n",
       " 288: 'craft',\n",
       " 289: 'business',\n",
       " 290: 'dead',\n",
       " 291: 'another',\n",
       " 292: 'middle',\n",
       " 293: 'sure',\n",
       " 294: 'candle',\n",
       " 295: 'presently',\n",
       " 296: 'low',\n",
       " 297: 'turned',\n",
       " 298: 'teeth',\n",
       " 299: 'dim',\n",
       " 300: 'euroclydon',\n",
       " 301: 'kept',\n",
       " 302: 'glass',\n",
       " 303: 'afterwards',\n",
       " 304: 'large',\n",
       " 305: 'three',\n",
       " 306: 'telling',\n",
       " 307: 'getting',\n",
       " 308: 'small',\n",
       " 309: 'next',\n",
       " 310: 'seeing',\n",
       " 311: 'sell',\n",
       " 312: 'felt',\n",
       " 313: 'sun',\n",
       " 314: 'e',\n",
       " 315: 'money',\n",
       " 316: 'sail',\n",
       " 317: 'coffin',\n",
       " 318: 'especially',\n",
       " 319: 'street',\n",
       " 320: 'city',\n",
       " 321: 'few',\n",
       " 322: 'previous',\n",
       " 323: 'sight',\n",
       " 324: 'days',\n",
       " 325: 'straight',\n",
       " 326: 'nigh',\n",
       " 327: 'legs',\n",
       " 328: 'try',\n",
       " 329: 'yes',\n",
       " 330: 'unless',\n",
       " 331: 'poor',\n",
       " 332: 'coat',\n",
       " 333: 'passenger',\n",
       " 334: 'taking',\n",
       " 335: 'true',\n",
       " 336: 'thing',\n",
       " 337: 'ai',\n",
       " 338: 'always',\n",
       " 339: 'us',\n",
       " 340: 'really',\n",
       " 341: 'marvellous',\n",
       " 342: 'heaven',\n",
       " 343: 'air',\n",
       " 344: 'far',\n",
       " 345: 'second',\n",
       " 346: 'many',\n",
       " 347: 'has',\n",
       " 348: 'unaccountable',\n",
       " 349: 'grand',\n",
       " 350: 'jolly',\n",
       " 351: 'open',\n",
       " 352: 'shirt',\n",
       " 353: 'cape',\n",
       " 354: 'bedford',\n",
       " 355: 'fine',\n",
       " 356: 'further',\n",
       " 357: 'ice',\n",
       " 358: 'frost',\n",
       " 359: 'foot',\n",
       " 360: 'wide',\n",
       " 361: 'white',\n",
       " 362: 'tall',\n",
       " 363: 'i.',\n",
       " 364: 'wooden',\n",
       " 365: 'worse',\n",
       " 366: 'death',\n",
       " 367: 'mine',\n",
       " 368: 'lazarus',\n",
       " 369: 'keep',\n",
       " 370: 'along',\n",
       " 371: 'hung',\n",
       " 372: 'throwing',\n",
       " 373: 'centre',\n",
       " 374: 'rest',\n",
       " 375: 'fact',\n",
       " 376: 'hair',\n",
       " 377: 'broken',\n",
       " 378: 'kill',\n",
       " 379: 'through',\n",
       " 380: 'chimney',\n",
       " 381: 'fancy',\n",
       " 382: 'bar',\n",
       " 383: 'trying',\n",
       " 384: 'dumplings',\n",
       " 385: 'heavens',\n",
       " 386: 'manner',\n",
       " 387: 'devil',\n",
       " 388: 'together',\n",
       " 389: 'seen',\n",
       " 390: 'deal',\n",
       " 391: 'know',\n",
       " 392: 'skin',\n",
       " 393: 'ca',\n",
       " 394: 'shavings',\n",
       " 395: 'peddling',\n",
       " 396: 'sunday',\n",
       " 397: 'counterpane',\n",
       " 398: 'mat',\n",
       " 399: 'christian',\n",
       " 400: 'commenced',\n",
       " 401: 'thinking',\n",
       " 402: 'similar',\n",
       " 403: 'afraid',\n",
       " 404: 'length',\n",
       " 405: 'idol',\n",
       " 406: 'sabbee',\n",
       " 407: 'waking',\n",
       " 408: 'ago',\n",
       " 409: 'find',\n",
       " 410: 'damp',\n",
       " 411: 'soul',\n",
       " 412: 'strong',\n",
       " 413: 'account',\n",
       " 414: 'sword',\n",
       " 415: 'quietly',\n",
       " 416: 'degree',\n",
       " 417: 'left',\n",
       " 418: 'around',\n",
       " 419: 'fixed',\n",
       " 420: 'ships',\n",
       " 421: 'miles',\n",
       " 422: 'country',\n",
       " 423: 'stream',\n",
       " 424: 'lead',\n",
       " 425: 'american',\n",
       " 426: 'artist',\n",
       " 427: 'each',\n",
       " 428: 'goes',\n",
       " 429: 'deep',\n",
       " 430: 'distant',\n",
       " 431: 'winds',\n",
       " 432: 'blue',\n",
       " 433: 'among',\n",
       " 434: 'suddenly',\n",
       " 435: 'feel',\n",
       " 436: 'meaning',\n",
       " 437: 'phantom',\n",
       " 438: 'life',\n",
       " 439: 'passengers',\n",
       " 440: 'nor',\n",
       " 441: 'kind',\n",
       " 442: 'quite',\n",
       " 443: 'care',\n",
       " 444: 'board',\n",
       " 445: 'somehow',\n",
       " 446: 'broiled',\n",
       " 447: 'mast',\n",
       " 448: 'sense',\n",
       " 449: 'knowing',\n",
       " 450: 'either',\n",
       " 451: 'passed',\n",
       " 452: 'hands',\n",
       " 453: 'paying',\n",
       " 454: 'pay',\n",
       " 455: 'penny',\n",
       " 456: 'sailors',\n",
       " 457: 'exactly',\n",
       " 458: 'short',\n",
       " 459: 'easy',\n",
       " 460: 'portentous',\n",
       " 461: 'island',\n",
       " 462: 'nameless',\n",
       " 463: 'sounds',\n",
       " 464: 'since',\n",
       " 465: 'snow',\n",
       " 466: 'saturday',\n",
       " 467: 'matter',\n",
       " 468: 'red',\n",
       " 469: 'partly',\n",
       " 470: 'ere',\n",
       " 471: 'became',\n",
       " 472: 'meanwhile',\n",
       " 473: 'pocket',\n",
       " 474: 'darkness',\n",
       " 475: 'fish',\n",
       " 476: 'inn',\n",
       " 477: 'watch',\n",
       " 478: 'broad',\n",
       " 479: 'entering',\n",
       " 480: 'ha',\n",
       " 481: 'ashes',\n",
       " 482: 'opened',\n",
       " 483: 'spouter',\n",
       " 484: 'name',\n",
       " 485: 'suppose',\n",
       " 486: 'quiet',\n",
       " 487: 'best',\n",
       " 488: 'tempestuous',\n",
       " 489: 'says',\n",
       " 490: 'thou',\n",
       " 491: 'both',\n",
       " 492: 'occurred',\n",
       " 493: 'dives',\n",
       " 494: 'holding',\n",
       " 495: 'frozen',\n",
       " 496: 'altogether',\n",
       " 497: 'plain',\n",
       " 498: 'whom',\n",
       " 499: 'clean',\n",
       " 500: 'human',\n",
       " 501: 'entered',\n",
       " 502: 'wrinkled',\n",
       " 503: 'shelf',\n",
       " 504: 'jonah',\n",
       " 505: 'blanket',\n",
       " 506: \"goin'\",\n",
       " 507: 'bitter',\n",
       " 508: 'supper',\n",
       " 509: 'sat',\n",
       " 510: 'settle',\n",
       " 511: 'chap',\n",
       " 512: 'help',\n",
       " 513: 'spend',\n",
       " 514: 'landed',\n",
       " 515: 'standing',\n",
       " 516: 'held',\n",
       " 517: 'somewhat',\n",
       " 518: 'sober',\n",
       " 519: 'whole',\n",
       " 520: 'dam',\n",
       " 521: 'brown',\n",
       " 522: 'bulkington',\n",
       " 523: \"o'clock\",\n",
       " 524: 'none',\n",
       " 525: 'coming',\n",
       " 526: \"'ve\",\n",
       " 527: 'wait',\n",
       " 528: 'plane',\n",
       " 529: 'saying',\n",
       " 530: 'grinning',\n",
       " 531: 'placed',\n",
       " 532: 'shouted',\n",
       " 533: 'bedfellow',\n",
       " 534: 'zealand',\n",
       " 535: 'sal',\n",
       " 536: 'wash',\n",
       " 537: 'thrown',\n",
       " 538: 'purplish',\n",
       " 539: 'turn',\n",
       " 540: 'completely',\n",
       " 541: 'fear',\n",
       " 542: 'grego',\n",
       " 543: 'baby',\n",
       " 544: 'slowly',\n",
       " 545: 'civilized',\n",
       " 546: 'purse',\n",
       " 547: 'monkey',\n",
       " 548: 'involuntarily',\n",
       " 549: 'pausing',\n",
       " 550: 'warehouses',\n",
       " 551: 'requires',\n",
       " 552: 'people',\n",
       " 553: 'nearly',\n",
       " 554: 'ocean',\n",
       " 555: 'indian',\n",
       " 556: 'waterward',\n",
       " 557: 'battery',\n",
       " 558: 'noble',\n",
       " 559: 'washed',\n",
       " 560: 'crowds',\n",
       " 561: 'sabbath',\n",
       " 562: 'afternoon',\n",
       " 563: 'thence',\n",
       " 564: 'silent',\n",
       " 565: 'thousands',\n",
       " 566: 'reveries',\n",
       " 567: 'leaning',\n",
       " 568: 'seated',\n",
       " 569: 'bulwarks',\n",
       " 570: 'aloft',\n",
       " 571: 'week',\n",
       " 572: 'plaster',\n",
       " 573: 'gone',\n",
       " 574: 'bound',\n",
       " 575: 'content',\n",
       " 576: 'yonder',\n",
       " 577: 'falling',\n",
       " 578: 'north',\n",
       " 579: 'please',\n",
       " 580: 'ten',\n",
       " 581: 'leaves',\n",
       " 582: 'magic',\n",
       " 583: 'plunged',\n",
       " 584: 'metaphysical',\n",
       " 585: 'chief',\n",
       " 586: 'trunk',\n",
       " 587: 'meadow',\n",
       " 588: 'smoke',\n",
       " 589: 'reaching',\n",
       " 590: 'hill',\n",
       " 591: 'thus',\n",
       " 592: 'pine',\n",
       " 593: 'sighs',\n",
       " 594: 'shepherd',\n",
       " 595: 'june',\n",
       " 596: 'scores',\n",
       " 597: 'thousand',\n",
       " 598: 'sadly',\n",
       " 599: 'robust',\n",
       " 600: 'healthy',\n",
       " 601: 'boy',\n",
       " 602: 'crazy',\n",
       " 603: 'hold',\n",
       " 604: 'holy',\n",
       " 605: 'brother',\n",
       " 606: 'ourselves',\n",
       " 607: 'begin',\n",
       " 608: 'grow',\n",
       " 609: 'inferred',\n",
       " 610: 'needs',\n",
       " 611: \"don't\",\n",
       " 612: 'themselves',\n",
       " 613: 'commodore',\n",
       " 614: 'captain',\n",
       " 615: 'cook',\n",
       " 616: 'glory',\n",
       " 617: 'whatsoever',\n",
       " 618: 'confess',\n",
       " 619: 'officer',\n",
       " 620: 'respectfully',\n",
       " 621: 'horse',\n",
       " 622: 'huge',\n",
       " 623: 'houses',\n",
       " 624: 'forecastle',\n",
       " 625: 'jump',\n",
       " 626: 'spar',\n",
       " 627: 'particularly',\n",
       " 628: 'putting',\n",
       " 629: 'tar',\n",
       " 630: 'schoolmaster',\n",
       " 631: 'boys',\n",
       " 632: 'transition',\n",
       " 633: 'grin',\n",
       " 634: 'bear',\n",
       " 635: 'hunks',\n",
       " 636: 'sweep',\n",
       " 637: 'weighed',\n",
       " 638: 'anything',\n",
       " 639: 'less',\n",
       " 640: 'thump',\n",
       " 641: 'point',\n",
       " 642: 'view',\n",
       " 643: 'single',\n",
       " 644: 'difference',\n",
       " 645: 'act',\n",
       " 646: 'uncomfortable',\n",
       " 647: 'compare',\n",
       " 648: 'earthly',\n",
       " 649: 'enter',\n",
       " 650: 'deck',\n",
       " 651: 'quarter',\n",
       " 652: 'leaders',\n",
       " 653: 'smelt',\n",
       " 654: 'fates',\n",
       " 655: 'doubtless',\n",
       " 656: 'formed',\n",
       " 657: 'run',\n",
       " 658: 'stage',\n",
       " 659: 'shabby',\n",
       " 660: 'others',\n",
       " 661: 'circumstances',\n",
       " 662: 'motives',\n",
       " 663: 'various',\n",
       " 664: 'mysterious',\n",
       " 665: 'curiosity',\n",
       " 666: 'tormented',\n",
       " 667: 'everlasting',\n",
       " 668: 'wonder',\n",
       " 669: 'purpose',\n",
       " 670: 'floated',\n",
       " 671: 'stuffed',\n",
       " 672: 'horn',\n",
       " 673: 'arrived',\n",
       " 674: 'offer',\n",
       " 675: 'following',\n",
       " 676: 'embark',\n",
       " 677: 'pleased',\n",
       " 678: 'original',\n",
       " 679: 'stranded',\n",
       " 680: 'leviathan',\n",
       " 681: 'whales',\n",
       " 682: 'nay',\n",
       " 683: 'dismal',\n",
       " 684: 'wherever',\n",
       " 685: 'dreary',\n",
       " 686: 'crossed',\n",
       " 687: 'expensive',\n",
       " 688: 'bright',\n",
       " 689: 'windows',\n",
       " 690: 'packed',\n",
       " 691: 'inches',\n",
       " 692: 'thick',\n",
       " 693: 'hear',\n",
       " 694: 'tinkling',\n",
       " 695: 'glasses',\n",
       " 696: 'blackness',\n",
       " 697: 'moving',\n",
       " 698: 'hour',\n",
       " 699: 'proved',\n",
       " 700: 'meant',\n",
       " 701: 'public',\n",
       " 702: 'box',\n",
       " 703: 'flying',\n",
       " 704: 'harpoons',\n",
       " 705: 'trap',\n",
       " 706: 'loud',\n",
       " 707: 'voice',\n",
       " 708: 'sitting',\n",
       " 709: 'beyond',\n",
       " 710: 'negro',\n",
       " 711: 'creaking',\n",
       " 712: 'swinging',\n",
       " 713: 'painting',\n",
       " 714: 'representing',\n",
       " 715: 'connexion',\n",
       " 716: 'peter',\n",
       " 717: 'itself',\n",
       " 718: 'carted',\n",
       " 719: 'burnt',\n",
       " 720: 'spot',\n",
       " 721: 'queer',\n",
       " 722: 'gable',\n",
       " 723: 'ended',\n",
       " 724: 'sharp',\n",
       " 725: 'wind',\n",
       " 726: 'howling',\n",
       " 727: 'nevertheless',\n",
       " 728: 'called',\n",
       " 729: 'outside',\n",
       " 730: 'passage',\n",
       " 731: 'body',\n",
       " 732: 'curbstone',\n",
       " 733: 'corn',\n",
       " 734: 'pooh',\n",
       " 735: 'northern',\n",
       " 736: 'lights',\n",
       " 737: 'summer',\n",
       " 738: 'lengthwise',\n",
       " 739: 'gods',\n",
       " 740: 'lie',\n",
       " 741: 'plenty',\n",
       " 742: 'study',\n",
       " 743: 'series',\n",
       " 744: 'arrive',\n",
       " 745: 'shadows',\n",
       " 746: 'dint',\n",
       " 747: 'conclusion',\n",
       " 748: 'confounded',\n",
       " 749: 'limber',\n",
       " 750: 'truly',\n",
       " 751: 'drive',\n",
       " 752: 'unimaginable',\n",
       " 753: 'midnight',\n",
       " 754: 'unnatural',\n",
       " 755: 'breaking',\n",
       " 756: 'design',\n",
       " 757: 'opposite',\n",
       " 758: 'monstrous',\n",
       " 759: 'knots',\n",
       " 760: 'vast',\n",
       " 761: 'handle',\n",
       " 762: 'wondered',\n",
       " 763: 'mixed',\n",
       " 764: 'deformed',\n",
       " 765: 'flung',\n",
       " 766: 'iron',\n",
       " 767: 'arched',\n",
       " 768: 'cut',\n",
       " 769: 'times',\n",
       " 770: 'beneath',\n",
       " 771: 'covered',\n",
       " 772: 'gathered',\n",
       " 773: 'stands',\n",
       " 774: 'rude',\n",
       " 775: 'bone',\n",
       " 776: 'abominable',\n",
       " 777: 'measure',\n",
       " 778: 'seamen',\n",
       " 779: 'skrimshander',\n",
       " 780: 'sought',\n",
       " 781: 'added',\n",
       " 782: 'forehead',\n",
       " 783: 'objections',\n",
       " 784: \"'d\",\n",
       " 785: 'used',\n",
       " 786: 'depend',\n",
       " 787: 'decent',\n",
       " 788: 'want',\n",
       " 789: 'ready',\n",
       " 790: 'working',\n",
       " 791: 'space',\n",
       " 792: 'lips',\n",
       " 793: 'fingers',\n",
       " 794: 'fare',\n",
       " 795: 'fellow',\n",
       " 796: 'nightmare',\n",
       " 797: 'nt',\n",
       " 798: 'complexioned',\n",
       " 799: 'eats',\n",
       " 800: \"'em\",\n",
       " 801: 'afore',\n",
       " 802: 'resolved',\n",
       " 803: 'noise',\n",
       " 804: 'offing',\n",
       " 805: 'shaggy',\n",
       " 806: 'woollen',\n",
       " 807: 'stiff',\n",
       " 808: 'labrador',\n",
       " 809: 'wake',\n",
       " 810: 'bad',\n",
       " 811: 'mounted',\n",
       " 812: 'generally',\n",
       " 813: 'shipmates',\n",
       " 814: 'become',\n",
       " 815: 'height',\n",
       " 816: 'seem',\n",
       " 817: 'plan',\n",
       " 818: 'private',\n",
       " 819: 'unknown',\n",
       " 820: 'apartment',\n",
       " 821: 'hammock',\n",
       " 822: 'linen',\n",
       " 823: 'home',\n",
       " 824: 'hole',\n",
       " 825: 'mattress',\n",
       " 826: 'planing',\n",
       " 827: 'knot',\n",
       " 828: 'near',\n",
       " 829: 'sake',\n",
       " 830: 'chair',\n",
       " 831: 'narrow',\n",
       " 832: 'leaving',\n",
       " 833: 'interval',\n",
       " 834: 'met',\n",
       " 835: 'inside',\n",
       " 836: 'violent',\n",
       " 837: 'ones',\n",
       " 838: 'comprehension',\n",
       " 839: 'bird',\n",
       " 840: 'airley',\n",
       " 841: 'airth',\n",
       " 842: 'engaged',\n",
       " 843: 'whittling',\n",
       " 844: 'guess',\n",
       " 845: 'done',\n",
       " 846: 'break',\n",
       " 847: 'broke',\n",
       " 848: 'understand',\n",
       " 849: 'certain',\n",
       " 850: 'demand',\n",
       " 851: 'selling',\n",
       " 852: 'sir',\n",
       " 853: 'string',\n",
       " 854: 'mystery',\n",
       " 855: 'showed',\n",
       " 856: 'dangerous',\n",
       " 857: 'flukes',\n",
       " 858: 'slept',\n",
       " 859: 'big',\n",
       " 860: 'sam',\n",
       " 861: 'lighted',\n",
       " 862: 'wo',\n",
       " 863: 'stairs',\n",
       " 864: 'placing',\n",
       " 865: 'double',\n",
       " 866: 'eyeing',\n",
       " 867: 'belonging',\n",
       " 868: 'papered',\n",
       " 869: 'parcel',\n",
       " 870: 'tried',\n",
       " 871: 'satisfactory',\n",
       " 872: 'concerning',\n",
       " 873: 'edges',\n",
       " 874: 'stuck',\n",
       " 875: 'gave',\n",
       " 876: 'neck',\n",
       " 877: 'sleeves',\n",
       " 878: 'undressed',\n",
       " 879: 'remembering',\n",
       " 880: 'jumped',\n",
       " 881: 'pantaloons',\n",
       " 882: 'blowing',\n",
       " 883: 'doze',\n",
       " 884: 'pretty',\n",
       " 885: 'heavy',\n",
       " 886: 'save',\n",
       " 887: 'infernal',\n",
       " 888: 'peddler',\n",
       " 889: 'yellow',\n",
       " 890: 'colour',\n",
       " 891: 'dreadfully',\n",
       " 892: 'sticking',\n",
       " 893: 'cheeks',\n",
       " 894: 'truth',\n",
       " 895: 'remembered',\n",
       " 896: 'whaleman',\n",
       " 897: 'tattooed',\n",
       " 898: 'concluded',\n",
       " 899: 'lying',\n",
       " 900: 'tanning',\n",
       " 901: 'hot',\n",
       " 902: 'produced',\n",
       " 903: 'beaver',\n",
       " 904: 'singing',\n",
       " 905: 'bolted',\n",
       " 906: 'arms',\n",
       " 907: 'running',\n",
       " 908: 'curious',\n",
       " 909: 'hunch',\n",
       " 910: 'congo',\n",
       " 911: 'ill',\n",
       " 912: 'takes',\n",
       " 913: 'biscuit',\n",
       " 914: 'top',\n",
       " 915: 'lamp',\n",
       " 916: 'succeeded',\n",
       " 917: 'polite',\n",
       " 918: 'guttural',\n",
       " 919: 'pagan',\n",
       " 920: 'spell',\n",
       " 921: 'tobacco',\n",
       " 922: 'grunt',\n",
       " 923: 'whatever',\n",
       " 924: 'ee',\n",
       " 925: 'horrid',\n",
       " 926: 'pipe',\n",
       " 927: 'smoking',\n",
       " 928: 'complied',\n",
       " 929: 'patchwork',\n",
       " 930: 'figure',\n",
       " 931: 'shade',\n",
       " 932: 'quilt',\n",
       " 933: 'hugging',\n",
       " 934: 'sensations',\n",
       " 935: 'explain',\n",
       " 936: 'remember',\n",
       " 937: 'circumstance',\n",
       " 938: 'reality',\n",
       " 939: 'stepmother',\n",
       " 940: 'sixteen',\n",
       " 941: 'abed',\n",
       " 942: 'troubled',\n",
       " 943: 'supernatural',\n",
       " 944: 'ages',\n",
       " 945: 'awful',\n",
       " 946: 'consciousness',\n",
       " 947: 'observing',\n",
       " 948: 'creature',\n",
       " 949: 'dress',\n",
       " 950: 'watching',\n",
       " 951: 'probably',\n",
       " 952: 'toilet',\n",
       " 953: 'wrapped',\n",
       " 954: 'precisely',\n",
       " 955: 'jacket',\n",
       " 956: 'call',\n",
       " 957: 'shore',\n",
       " 958: 'watery',\n",
       " 959: 'driving',\n",
       " 960: 'spleen',\n",
       " 961: 'regulating',\n",
       " 962: 'circulation',\n",
       " 963: 'growing',\n",
       " 964: 'grim',\n",
       " 965: 'drizzly',\n",
       " 966: 'november',\n",
       " 967: 'bringing',\n",
       " 968: 'rear',\n",
       " 969: 'funeral',\n",
       " 970: 'meet',\n",
       " 971: 'hypos',\n",
       " 972: 'upper',\n",
       " 973: 'moral',\n",
       " 974: 'principle',\n",
       " 975: 'prevent',\n",
       " 976: 'deliberately',\n",
       " 977: 'stepping',\n",
       " 978: 'methodically',\n",
       " 979: 'knocking',\n",
       " 980: 'hats',\n",
       " 981: 'substitute',\n",
       " 982: 'pistol',\n",
       " 983: 'ball',\n",
       " 984: 'philosophical',\n",
       " 985: 'flourish',\n",
       " 986: 'cato',\n",
       " 987: 'throws',\n",
       " 988: 'surprising',\n",
       " 989: 'cherish',\n",
       " 990: 'feelings',\n",
       " 991: 'insular',\n",
       " 992: 'manhattoes',\n",
       " 993: 'belted',\n",
       " 994: 'wharves',\n",
       " 995: 'isles',\n",
       " 996: 'coral',\n",
       " 997: 'reefs',\n",
       " 998: 'commerce',\n",
       " 999: 'surrounds',\n",
       " 1000: 'surf',\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956 : call\n",
      "14 : me\n",
      "263 : ishmael\n",
      "51 : some\n",
      "261 : years\n",
      "408 : ago\n",
      "87 : never\n",
      "219 : mind\n",
      "129 : how\n",
      "111 : long\n",
      "954 : precisely\n",
      "260 : having\n",
      "50 : little\n",
      "43 : or\n",
      "38 : no\n",
      "315 : money\n",
      "7 : in\n",
      "23 : my\n",
      "546 : purse\n",
      "3 : and\n",
      "150 : nothing\n",
      "259 : particular\n",
      "6 : to\n",
      "2712 : interest\n",
      "14 : me\n",
      "24 : on\n"
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "    print(f\"{i} : {tokenizer.index_word[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('call', 27),\n",
       "             ('me', 2471),\n",
       "             ('ishmael', 133),\n",
       "             ('some', 758),\n",
       "             ('years', 135),\n",
       "             ('ago', 84),\n",
       "             ('never', 449),\n",
       "             ('mind', 164),\n",
       "             ('how', 321),\n",
       "             ('long', 374),\n",
       "             ('precisely', 37),\n",
       "             ('having', 142),\n",
       "             ('little', 767),\n",
       "             ('or', 950),\n",
       "             ('no', 1003),\n",
       "             ('money', 120),\n",
       "             ('in', 5647),\n",
       "             ('my', 1786),\n",
       "             ('purse', 71),\n",
       "             ('and', 9646),\n",
       "             ('nothing', 281),\n",
       "             ('particular', 152),\n",
       "             ('to', 6497),\n",
       "             ('interest', 24),\n",
       "             ('on', 1716),\n",
       "             ('shore', 26),\n",
       "             ('i', 7150),\n",
       "             ('thought', 676),\n",
       "             ('would', 702),\n",
       "             ('sail', 104),\n",
       "             ('about', 1014),\n",
       "             ('a', 10377),\n",
       "             ('see', 416),\n",
       "             ('the', 15540),\n",
       "             ('watery', 26),\n",
       "             ('part', 234),\n",
       "             ('of', 8287),\n",
       "             ('world', 234),\n",
       "             ('it', 4238),\n",
       "             ('is', 1950),\n",
       "             ('way', 390),\n",
       "             ('have', 806),\n",
       "             ('driving', 26),\n",
       "             ('off', 416),\n",
       "             ('spleen', 26),\n",
       "             ('regulating', 26),\n",
       "             ('circulation', 26),\n",
       "             ('whenever', 130),\n",
       "             ('find', 78),\n",
       "             ('myself', 416),\n",
       "             ('growing', 26),\n",
       "             ('grim', 26),\n",
       "             ('mouth', 130),\n",
       "             ('damp', 78),\n",
       "             ('drizzly', 26),\n",
       "             ('november', 26),\n",
       "             ('soul', 78),\n",
       "             ('involuntarily', 52),\n",
       "             ('pausing', 52),\n",
       "             ('before', 364),\n",
       "             ('coffin', 104),\n",
       "             ('warehouses', 52),\n",
       "             ('bringing', 26),\n",
       "             ('up', 1237),\n",
       "             ('rear', 26),\n",
       "             ('every', 182),\n",
       "             ('funeral', 26),\n",
       "             ('meet', 26),\n",
       "             ('especially', 104),\n",
       "             ('hypos', 26),\n",
       "             ('get', 364),\n",
       "             ('such', 572),\n",
       "             ('an', 806),\n",
       "             ('upper', 26),\n",
       "             ('hand', 312),\n",
       "             ('that', 3770),\n",
       "             ('requires', 52),\n",
       "             ('strong', 78),\n",
       "             ('moral', 26),\n",
       "             ('principle', 26),\n",
       "             ('prevent', 26),\n",
       "             ('from', 1508),\n",
       "             ('deliberately', 26),\n",
       "             ('stepping', 26),\n",
       "             ('into', 988),\n",
       "             ('street', 104),\n",
       "             ('methodically', 26),\n",
       "             ('knocking', 26),\n",
       "             ('people', 52),\n",
       "             (\"'s\", 1691),\n",
       "             ('hats', 26),\n",
       "             ('then', 832),\n",
       "             ('account', 78),\n",
       "             ('high', 130),\n",
       "             ('time', 520),\n",
       "             ('sea', 546),\n",
       "             ('as', 2366),\n",
       "             ('soon', 234),\n",
       "             ('can', 338),\n",
       "             ('this', 2158),\n",
       "             ('substitute', 26),\n",
       "             ('for', 1820),\n",
       "             ('pistol', 26),\n",
       "             ('ball', 26),\n",
       "             ('with', 2392),\n",
       "             ('philosophical', 26),\n",
       "             ('flourish', 26),\n",
       "             ('cato', 26),\n",
       "             ('throws', 26),\n",
       "             ('himself', 338),\n",
       "             ('upon', 780),\n",
       "             ('his', 3139),\n",
       "             ('sword', 78),\n",
       "             ('quietly', 78),\n",
       "             ('take', 260),\n",
       "             ('ship', 182),\n",
       "             ('there', 1456),\n",
       "             ('surprising', 26),\n",
       "             ('if', 728),\n",
       "             ('they', 728),\n",
       "             ('but', 2652),\n",
       "             ('knew', 130),\n",
       "             ('almost', 286),\n",
       "             ('all', 1872),\n",
       "             ('men', 130),\n",
       "             ('their', 390),\n",
       "             ('degree', 78),\n",
       "             ('other', 494),\n",
       "             ('cherish', 26),\n",
       "             ('very', 494),\n",
       "             ('nearly', 52),\n",
       "             ('same', 312),\n",
       "             ('feelings', 26),\n",
       "             ('towards', 260),\n",
       "             ('ocean', 52),\n",
       "             ('now', 1040),\n",
       "             ('your', 442),\n",
       "             ('insular', 26),\n",
       "             ('city', 104),\n",
       "             ('manhattoes', 26),\n",
       "             ('belted', 26),\n",
       "             ('round', 364),\n",
       "             ('by', 962),\n",
       "             ('wharves', 26),\n",
       "             ('indian', 52),\n",
       "             ('isles', 26),\n",
       "             ('coral', 26),\n",
       "             ('reefs', 26),\n",
       "             ('commerce', 26),\n",
       "             ('surrounds', 26),\n",
       "             ('her', 156),\n",
       "             ('surf', 26),\n",
       "             ('right', 156),\n",
       "             ('left', 78),\n",
       "             ('streets', 208),\n",
       "             ('you', 2158),\n",
       "             ('waterward', 52),\n",
       "             ('its', 156),\n",
       "             ('extreme', 26),\n",
       "             ('downtown', 26),\n",
       "             ('battery', 52),\n",
       "             ('where', 364),\n",
       "             ('noble', 52),\n",
       "             ('mole', 26),\n",
       "             ('washed', 52),\n",
       "             ('waves', 26),\n",
       "             ('cooled', 26),\n",
       "             ('breezes', 26),\n",
       "             ('which', 572),\n",
       "             ('few', 104),\n",
       "             ('hours', 130),\n",
       "             ('previous', 104),\n",
       "             ('were', 962),\n",
       "             ('out', 956),\n",
       "             ('sight', 104),\n",
       "             ('land', 208),\n",
       "             ('look', 156),\n",
       "             ('at', 2184),\n",
       "             ('crowds', 52),\n",
       "             ('water', 234),\n",
       "             ('gazers', 26),\n",
       "             ('circumambulate', 26),\n",
       "             ('dreamy', 26),\n",
       "             ('sabbath', 52),\n",
       "             ('afternoon', 52),\n",
       "             ('go', 494),\n",
       "             ('corlears', 26),\n",
       "             ('hook', 26),\n",
       "             ('coenties', 26),\n",
       "             ('slip', 26),\n",
       "             ('thence', 52),\n",
       "             ('whitehall', 26),\n",
       "             ('northward', 26),\n",
       "             ('what', 1118),\n",
       "             ('do', 702),\n",
       "             ('see?--posted', 26),\n",
       "             ('like', 732),\n",
       "             ('silent', 52),\n",
       "             ('sentinels', 26),\n",
       "             ('around', 78),\n",
       "             ('town', 156),\n",
       "             ('stand', 182),\n",
       "             ('thousands', 52),\n",
       "             ('mortal', 26),\n",
       "             ('fixed', 78),\n",
       "             ('reveries', 52),\n",
       "             ('leaning', 52),\n",
       "             ('against', 234),\n",
       "             ('spiles', 26),\n",
       "             ('seated', 52),\n",
       "             ('pier', 26),\n",
       "             ('heads', 338),\n",
       "             ('looking', 312),\n",
       "             ('over', 702),\n",
       "             ('bulwarks', 52),\n",
       "             ('ships', 78),\n",
       "             ('china', 26),\n",
       "             ('aloft', 52),\n",
       "             ('rigging', 26),\n",
       "             ('striving', 26),\n",
       "             ('still', 364),\n",
       "             ('better', 208),\n",
       "             ('seaward', 26),\n",
       "             ('peep', 26),\n",
       "             ('these', 494),\n",
       "             ('are', 416),\n",
       "             ('landsmen', 26),\n",
       "             ('week', 52),\n",
       "             ('days', 104),\n",
       "             ('pent', 26),\n",
       "             ('lath', 26),\n",
       "             ('plaster', 52),\n",
       "             ('tied', 26),\n",
       "             ('counters', 26),\n",
       "             ('nailed', 26),\n",
       "             ('benches', 26),\n",
       "             ('clinched', 26),\n",
       "             ('desks', 26),\n",
       "             ('green', 130),\n",
       "             ('fields', 26),\n",
       "             ('gone', 52),\n",
       "             ('here', 598),\n",
       "             ('come', 338),\n",
       "             ('more', 494),\n",
       "             ('pacing', 26),\n",
       "             ('straight', 104),\n",
       "             ('seemingly', 26),\n",
       "             ('bound', 52),\n",
       "             ('dive', 26),\n",
       "             ('strange', 182),\n",
       "             ('will', 260),\n",
       "             ('content', 52),\n",
       "             ('them', 442),\n",
       "             ('extremest', 26),\n",
       "             ('limit', 26),\n",
       "             ('loitering', 26),\n",
       "             ('under', 260),\n",
       "             ('shady', 26),\n",
       "             ('lee', 26),\n",
       "             ('yonder', 52),\n",
       "             ('not', 1534),\n",
       "             ('suffice', 26),\n",
       "             ('must', 442),\n",
       "             ('just', 390),\n",
       "             ('nigh', 104),\n",
       "             ('possibly', 26),\n",
       "             ('without', 182),\n",
       "             ('falling', 52),\n",
       "             ('miles', 78),\n",
       "             ('leagues', 26),\n",
       "             ('inlanders', 26),\n",
       "             ('lanes', 26),\n",
       "             ('alleys', 26),\n",
       "             ('avenues', 26),\n",
       "             ('north', 52),\n",
       "             ('east', 26),\n",
       "             ('south', 156),\n",
       "             ('west', 26),\n",
       "             ('yet', 416),\n",
       "             ('unite', 26),\n",
       "             ('tell', 442),\n",
       "             ('does', 156),\n",
       "             ('magnetic', 26),\n",
       "             ('virtue', 26),\n",
       "             ('needles', 26),\n",
       "             ('compasses', 26),\n",
       "             ('those', 234),\n",
       "             ('attract', 26),\n",
       "             ('thither', 26),\n",
       "             ('once', 208),\n",
       "             ('say', 286),\n",
       "             ('country', 78),\n",
       "             ('lakes', 26),\n",
       "             ('any', 364),\n",
       "             ('path', 26),\n",
       "             ('please', 52),\n",
       "             ('ten', 52),\n",
       "             ('one', 1300),\n",
       "             ('carries', 26),\n",
       "             ('down', 468),\n",
       "             ('dale', 26),\n",
       "             ('leaves', 52),\n",
       "             ('pool', 26),\n",
       "             ('stream', 78),\n",
       "             ('magic', 52),\n",
       "             ('let', 156),\n",
       "             ('most', 468),\n",
       "             ('absent', 26),\n",
       "             ('minded', 26),\n",
       "             ('be', 1716),\n",
       "             ('plunged', 52),\n",
       "             ('deepest', 26),\n",
       "             ('man', 572),\n",
       "             ('legs', 104),\n",
       "             ('set', 156),\n",
       "             ('feet', 182),\n",
       "             ('going', 260),\n",
       "             ('he', 3247),\n",
       "             ('infallibly', 26),\n",
       "             ('lead', 78),\n",
       "             ('region', 26),\n",
       "             ('should', 286),\n",
       "             ('ever', 338),\n",
       "             ('athirst', 26),\n",
       "             ('great', 376),\n",
       "             ('american', 78),\n",
       "             ('desert', 26),\n",
       "             ('try', 104),\n",
       "             ('experiment', 26),\n",
       "             ('caravan', 26),\n",
       "             ('happen', 26),\n",
       "             ('supplied', 26),\n",
       "             ('metaphysical', 52),\n",
       "             ('professor', 26),\n",
       "             ('yes', 104),\n",
       "             ('knows', 26),\n",
       "             ('meditation', 26),\n",
       "             ('wedded', 26),\n",
       "             ('artist', 78),\n",
       "             ('desires', 26),\n",
       "             ('paint', 26),\n",
       "             ('dreamiest', 26),\n",
       "             ('shadiest', 26),\n",
       "             ('quietest', 26),\n",
       "             ('enchanting', 26),\n",
       "             ('bit', 130),\n",
       "             ('romantic', 26),\n",
       "             ('landscape', 26),\n",
       "             ('valley', 26),\n",
       "             ('saco', 26),\n",
       "             ('chief', 52),\n",
       "             ('element', 26),\n",
       "             ('employs', 26),\n",
       "             ('trees', 26),\n",
       "             ('each', 78),\n",
       "             ('hollow', 26),\n",
       "             ('trunk', 52),\n",
       "             ('hermit', 26),\n",
       "             ('crucifix', 26),\n",
       "             ('within', 130),\n",
       "             ('sleeps', 26),\n",
       "             ('meadow', 52),\n",
       "             ('sleep', 416),\n",
       "             ('cattle', 26),\n",
       "             ('cottage', 26),\n",
       "             ('goes', 78),\n",
       "             ('sleepy', 26),\n",
       "             ('smoke', 52),\n",
       "             ('deep', 78),\n",
       "             ('distant', 78),\n",
       "             ('woodlands', 26),\n",
       "             ('winds', 78),\n",
       "             ('mazy', 26),\n",
       "             ('reaching', 52),\n",
       "             ('overlapping', 26),\n",
       "             ('spurs', 26),\n",
       "             ('mountains', 26),\n",
       "             ('bathed', 26),\n",
       "             ('hill', 52),\n",
       "             ('side', 286),\n",
       "             ('blue', 78),\n",
       "             ('though', 494),\n",
       "             ('picture', 130),\n",
       "             ('lies', 26),\n",
       "             ('thus', 52),\n",
       "             ('tranced', 26),\n",
       "             ('pine', 52),\n",
       "             ('tree', 26),\n",
       "             ('shakes', 26),\n",
       "             ('sighs', 52),\n",
       "             ('shepherd', 52),\n",
       "             ('head', 598),\n",
       "             ('vain', 26),\n",
       "             ('unless', 104),\n",
       "             ('eye', 26),\n",
       "             ('him', 1092),\n",
       "             ('visit', 26),\n",
       "             ('prairies', 26),\n",
       "             ('june', 52),\n",
       "             ('when', 650),\n",
       "             ('scores', 52),\n",
       "             ('wade', 26),\n",
       "             ('knee', 26),\n",
       "             ('among', 78),\n",
       "             ('tiger', 26),\n",
       "             ('lilies', 26),\n",
       "             ('charm', 26),\n",
       "             ('wanting?--water', 26),\n",
       "             ('drop', 26),\n",
       "             ('niagara', 26),\n",
       "             ('cataract', 26),\n",
       "             ('sand', 26),\n",
       "             ('travel', 26),\n",
       "             ('thousand', 52),\n",
       "             ('why', 286),\n",
       "             ('did', 572),\n",
       "             ('poor', 104),\n",
       "             ('poet', 26),\n",
       "             ('tennessee', 26),\n",
       "             ('suddenly', 78),\n",
       "             ('receiving', 26),\n",
       "             ('two', 338),\n",
       "             ('handfuls', 26),\n",
       "             ('silver', 26),\n",
       "             ('deliberate', 26),\n",
       "             ('whether', 182),\n",
       "             ('buy', 26),\n",
       "             ('coat', 104),\n",
       "             ('sadly', 52),\n",
       "             ('needed', 26),\n",
       "             ('invest', 26),\n",
       "             ('pedestrian', 26),\n",
       "             ('trip', 26),\n",
       "             ('rockaway', 26),\n",
       "             ('beach', 26),\n",
       "             ('robust', 52),\n",
       "             ('healthy', 52),\n",
       "             ('boy', 52),\n",
       "             ('crazy', 52),\n",
       "             ('first', 494),\n",
       "             ('voyage', 208),\n",
       "             ('passenger', 104),\n",
       "             ('yourself', 156),\n",
       "             ('feel', 78),\n",
       "             ('mystical', 26),\n",
       "             ('vibration', 26),\n",
       "             ('told', 130),\n",
       "             ('old', 754),\n",
       "             ('persians', 26),\n",
       "             ('hold', 52),\n",
       "             ('holy', 52),\n",
       "             ('greeks', 26),\n",
       "             ('give', 208),\n",
       "             ('separate', 26),\n",
       "             ('deity', 26),\n",
       "             ('own', 286),\n",
       "             ('brother', 52),\n",
       "             ('jove', 26),\n",
       "             ('surely', 26),\n",
       "             ('meaning', 78),\n",
       "             ('deeper', 26),\n",
       "             ('story', 130),\n",
       "             ('narcissus', 26),\n",
       "             ('who', 416),\n",
       "             ('because', 182),\n",
       "             ('could', 650),\n",
       "             ('grasp', 26),\n",
       "             ('tormenting', 26),\n",
       "             ('mild', 26),\n",
       "             ('image', 156),\n",
       "             ('saw', 156),\n",
       "             ('fountain', 26),\n",
       "             ('was', 2886),\n",
       "             ('drowned', 26),\n",
       "             ('we', 286),\n",
       "             ('ourselves', 52),\n",
       "             ('rivers', 26),\n",
       "             ('oceans', 26),\n",
       "             ('ungraspable', 26),\n",
       "             ('phantom', 78),\n",
       "             ('life', 78),\n",
       "             ('key', 26),\n",
       "             ('am', 156),\n",
       "             ('habit', 26),\n",
       "             ('begin', 52),\n",
       "             ('grow', 52),\n",
       "             ('hazy', 26),\n",
       "             ('eyes', 182),\n",
       "             ('conscious', 26),\n",
       "             ('lungs', 26),\n",
       "             ('mean', 130),\n",
       "             ('inferred', 52),\n",
       "             ('needs', 52),\n",
       "             ('rag', 26),\n",
       "             ('something', 312),\n",
       "             ('besides', 156),\n",
       "             ('passengers', 78),\n",
       "             ('sick', 26),\n",
       "             ('quarrelsome', 26),\n",
       "             (\"don't\", 52),\n",
       "             ('nights', 26),\n",
       "             ('enjoy', 26),\n",
       "             ('themselves', 52),\n",
       "             ('much', 442),\n",
       "             ('general', 26),\n",
       "             ('thing;--no', 26),\n",
       "             ('nor', 78),\n",
       "             ('salt', 26),\n",
       "             ('commodore', 52),\n",
       "             ('captain', 52),\n",
       "             ('cook', 52),\n",
       "             ('abandon', 26),\n",
       "             ('glory', 52),\n",
       "             ('distinction', 26),\n",
       "             ('offices', 26),\n",
       "             ('abominate', 26),\n",
       "             ('honourable', 26),\n",
       "             ('respectable', 26),\n",
       "             ('toils', 26),\n",
       "             ('trials', 26),\n",
       "             ('tribulations', 26),\n",
       "             ('kind', 78),\n",
       "             ('whatsoever', 52),\n",
       "             ('quite', 78),\n",
       "             ('care', 78),\n",
       "             ('taking', 104),\n",
       "             ('barques', 26),\n",
       "             ('brigs', 26),\n",
       "             ('schooners', 26),\n",
       "             ('cook,--though', 26),\n",
       "             ('confess', 52),\n",
       "             ('considerable', 26),\n",
       "             ('being', 390),\n",
       "             ('sort', 494),\n",
       "             ('officer', 52),\n",
       "             ('board', 78),\n",
       "             ('somehow', 78),\n",
       "             ('fancied', 26),\n",
       "             ('broiling', 26),\n",
       "             ('fowls;--though', 26),\n",
       "             ('broiled', 78),\n",
       "             ('judiciously', 26),\n",
       "             ('buttered', 26),\n",
       "             ('judgmatically', 26),\n",
       "             ('salted', 26),\n",
       "             ('peppered', 26),\n",
       "             ('speak', 130),\n",
       "             ('respectfully', 52),\n",
       "             ('reverentially', 26),\n",
       "             ('fowl', 26),\n",
       "             ('than', 390),\n",
       "             ('idolatrous', 26),\n",
       "             ('dotings', 26),\n",
       "             ('egyptians', 26),\n",
       "             ('ibis', 26),\n",
       "             ('roasted', 26),\n",
       "             ('river', 26),\n",
       "             ('horse', 52),\n",
       "             ('mummies', 26),\n",
       "             ('creatures', 26),\n",
       "             ('huge', 52),\n",
       "             ('bake', 26),\n",
       "             ('houses', 52),\n",
       "             ('pyramids', 26),\n",
       "             ('simple', 26),\n",
       "             ('sailor', 156),\n",
       "             ('mast', 78),\n",
       "             ('plumb', 26),\n",
       "             ('forecastle', 52),\n",
       "             ('royal', 26),\n",
       "             ('true', 104),\n",
       "             ('rather', 208),\n",
       "             ('order', 130),\n",
       "             ('make', 260),\n",
       "             ('jump', 52),\n",
       "             ('spar', 52),\n",
       "             ('grasshopper', 26),\n",
       "             ('may', 312),\n",
       "             ('thing', 104),\n",
       "             ('unpleasant', 26),\n",
       "             ('enough', 338),\n",
       "             ('touches', 26),\n",
       "             ('sense', 78),\n",
       "             ('honour', 26),\n",
       "             ('particularly', 52),\n",
       "             ('established', 26),\n",
       "             ('family', 26),\n",
       "             ('van', 26),\n",
       "             ('rensselaers', 26),\n",
       "             ('randolphs', 26),\n",
       "             ('hardicanutes', 26),\n",
       "             ('putting', 52),\n",
       "             ('tar', 52),\n",
       "             ('pot', 26),\n",
       "             ('been', 468),\n",
       "             ('lording', 26),\n",
       "             ('schoolmaster', 52),\n",
       "             ('making', 130),\n",
       "             ('tallest', 26),\n",
       "             ('boys', 52),\n",
       "             ('awe', 26),\n",
       "             ('transition', 52),\n",
       "             ('keen', 26),\n",
       "             ('assure', 26),\n",
       "             ('decoction', 26),\n",
       "             ('seneca', 26),\n",
       "             ('stoics', 26),\n",
       "             ('enable', 26),\n",
       "             ('grin', 52),\n",
       "             ('bear', 52),\n",
       "             ('even', 130),\n",
       "             ('wears', 26),\n",
       "             ('hunks', 52),\n",
       "             ('orders', 26),\n",
       "             ('broom', 26),\n",
       "             ('sweep', 52),\n",
       "             ('decks', 26),\n",
       "             ('indignity', 26),\n",
       "             ('amount', 26),\n",
       "             ('weighed', 52),\n",
       "             ('scales', 26),\n",
       "             ('new', 286),\n",
       "             ('testament', 26),\n",
       "             ('think', 182),\n",
       "             ('archangel', 26),\n",
       "             ('gabriel', 26),\n",
       "             ('thinks', 182),\n",
       "             ('anything', 52),\n",
       "             ('less', 52),\n",
       "             ('promptly', 26),\n",
       "             ('obey', 26),\n",
       "             ('instance', 26),\n",
       "             ('ai', 104),\n",
       "             (\"n't\", 624),\n",
       "             ('slave', 26),\n",
       "             ('well', 208),\n",
       "             ('however', 208),\n",
       "             ('captains', 26),\n",
       "             ('thump', 52),\n",
       "             ('punch', 26),\n",
       "             ('satisfaction', 26),\n",
       "             ('knowing', 78),\n",
       "             ('everybody', 26),\n",
       "             ('else', 208),\n",
       "             ('served', 26),\n",
       "             ('either', 78),\n",
       "             ('physical', 26),\n",
       "             ('point', 52),\n",
       "             ('view', 52),\n",
       "             ('so', 1066),\n",
       "             ('universal', 26),\n",
       "             ('passed', 78),\n",
       "             ('hands', 78),\n",
       "             ('rub', 26),\n",
       "             ('shoulder', 26),\n",
       "             ('blades', 26),\n",
       "             ('again', 286),\n",
       "             ('always', 104),\n",
       "             ('paying', 78),\n",
       "             ('trouble', 26),\n",
       "             ('whereas', 26),\n",
       "             ('pay', 78),\n",
       "             ('single', 52),\n",
       "             ('penny', 78),\n",
       "             ('heard', 208),\n",
       "             ('contrary', 26),\n",
       "             ('difference', 52),\n",
       "             ('between', 234),\n",
       "             ('paid', 26),\n",
       "             ('act', 52),\n",
       "             ('perhaps', 130),\n",
       "             ('uncomfortable', 52),\n",
       "             ('infliction', 26),\n",
       "             ('orchard', 26),\n",
       "             ('thieves', 26),\n",
       "             ('entailed', 26),\n",
       "             ('us', 104),\n",
       "             ('paid,--what', 26),\n",
       "             ('compare', 52),\n",
       "             ('urbane', 26),\n",
       "             ('activity', 26),\n",
       "             ('receives', 26),\n",
       "             ('really', 104),\n",
       "             ('marvellous', 104),\n",
       "             ('considering', 26),\n",
       "             ('earnestly', 26),\n",
       "             ('believe', 26),\n",
       "             ('root', 26),\n",
       "             ('earthly', 52),\n",
       "             ('ills', 26),\n",
       "             ('monied', 26),\n",
       "             ('enter', 52),\n",
       "             ('heaven', 104),\n",
       "             ('ah', 26),\n",
       "             ('cheerfully', 26),\n",
       "             ('consign', 26),\n",
       "             ('perdition', 26),\n",
       "             ('finally', 26),\n",
       "             ('wholesome', 26),\n",
       "             ('exercise', 26),\n",
       "             ('pure', 26),\n",
       "             ('air', 104),\n",
       "             ('fore', 26),\n",
       "             ('castle', 26),\n",
       "             ('deck', 52),\n",
       "             ('far', 104),\n",
       "             ('prevalent', 26),\n",
       "             ('astern', 26),\n",
       "             ('violate', 26),\n",
       "             ('pythagorean', 26),\n",
       "             ('maxim', 26),\n",
       "             ('quarter', 52),\n",
       "             ('gets', 26),\n",
       "             ('atmosphere', 26),\n",
       "             ('second', 104),\n",
       "             ('sailors', 78),\n",
       "             ('breathes', 26),\n",
       "             ('commonalty', 26),\n",
       "             ('leaders', 52),\n",
       "             ('many', 104),\n",
       "             ('things', 130),\n",
       "             ('suspect', 26),\n",
       "             ('wherefore', 26),\n",
       "             ('after', 234),\n",
       "             ('repeatedly', 26),\n",
       "             ('smelt', 52),\n",
       "             ('merchant', 26),\n",
       "             ('whaling', 234),\n",
       "             ('invisible', 26),\n",
       "             ('police', 26),\n",
       "             ('fates', 52),\n",
       "             ('has', 104),\n",
       "             ('constant', 26),\n",
       "             ('surveillance', 26),\n",
       "             ('secretly', 26),\n",
       "             ('dogs', 26),\n",
       "             ('influences', 26),\n",
       "             ('unaccountable', 104),\n",
       "             ('answer', 130),\n",
       "             ('doubtless', 52),\n",
       "             ('formed', 52),\n",
       "             ('grand', 104),\n",
       "             ('programme', 26),\n",
       "             ('providence', 26),\n",
       "             ('drawn', 26),\n",
       "             ('came', 286),\n",
       "             ('brief', 26),\n",
       "             ('interlude', 26),\n",
       "             ('solo', 26),\n",
       "             ('extensive', 26),\n",
       "             ('performances', 26),\n",
       "             ('bill', 26),\n",
       "             ('run', 52),\n",
       "             ('contested', 26),\n",
       "             ('election', 26),\n",
       "             ('presidency', 26),\n",
       "             ('united', 26),\n",
       "             ('states', 26),\n",
       "             ('bloody', 26),\n",
       "             ('battle', 26),\n",
       "             ('affghanistan', 26),\n",
       "             ('exactly', 78),\n",
       "             ('stage', 52),\n",
       "             ('managers', 26),\n",
       "             ('put', 208),\n",
       "             ('shabby', 52),\n",
       "             ('others', 52),\n",
       "             ('magnificent', 26),\n",
       "             ('parts', 130),\n",
       "             ('tragedies', 26),\n",
       "             ('short', 78),\n",
       "             ('easy', 78),\n",
       "             ('genteel', 26),\n",
       "             ('comedies', 26),\n",
       "             ('jolly', 104),\n",
       "             ('farces', 26),\n",
       "             ('recall', 26),\n",
       "             ('circumstances', 52),\n",
       "             ('springs', 26),\n",
       "             ('motives', 52),\n",
       "             ('cunningly', 26),\n",
       "             ('presented', 26),\n",
       "             ('various', 52),\n",
       "             ('disguises', 26),\n",
       "             ('induced', 26),\n",
       "             ('performing', 26),\n",
       "             ('cajoling', 26),\n",
       "             ('delusion', 26),\n",
       "             ('choice', 26),\n",
       "             ('resulting', 26),\n",
       "             ('unbiased', 26),\n",
       "             ('freewill', 26),\n",
       "             ('discriminating', 26),\n",
       "             ('judgment', 26),\n",
       "             ('overwhelming', 26),\n",
       "             ('idea', 182),\n",
       "             ('whale', 260),\n",
       "             ('portentous', 78),\n",
       "             ('mysterious', 52),\n",
       "             ('monster', 26),\n",
       "             ('roused', 26),\n",
       "             ('curiosity', 52),\n",
       "             ('wild', 130),\n",
       "             ('seas', 156),\n",
       "             ('rolled', 156),\n",
       "             ('island', 78),\n",
       "             ('bulk', 26),\n",
       "             ('undeliverable', 26),\n",
       "             ('nameless', 78),\n",
       "             ('perils', 26),\n",
       "             ('attending', 26),\n",
       "             ('marvels', 26),\n",
       "             ('patagonian', 26),\n",
       "             ('sights', 26),\n",
       "             ('sounds', 78),\n",
       "             ('helped', 26),\n",
       "             ('sway', 26),\n",
       "             ('wish', 26),\n",
       "             ('inducements', 26),\n",
       "             ('tormented', 52),\n",
       "             ('everlasting', 52),\n",
       "             ('itch', 26),\n",
       "             ('remote', 26),\n",
       "             ('love', 26),\n",
       "             ('forbidden', 26),\n",
       "             ('barbarous', 26),\n",
       "             ('coasts', 26),\n",
       "             ('ignoring', 26),\n",
       "             ('good', 442),\n",
       "             ('quick', 26),\n",
       "             ('perceive', 26),\n",
       "             ('horror', 26),\n",
       "             ('social', 26),\n",
       "             ('since', 78),\n",
       "             ('friendly', 26),\n",
       "             ('terms', 26),\n",
       "             ('inmates', 26),\n",
       "             ('place', 390),\n",
       "             ('lodges', 26),\n",
       "             ('reason', 130),\n",
       "             ('welcome', 26),\n",
       "             ('flood', 26),\n",
       "             ('gates', 26),\n",
       "             ('wonder', 52),\n",
       "             ('swung', 26),\n",
       "             ('open', 104),\n",
       "             ('conceits', 26),\n",
       "             ('swayed', 26),\n",
       "             ('purpose', 52),\n",
       "             ('floated', 52),\n",
       "             ('inmost', 26),\n",
       "             ('endless', 26),\n",
       "             ('processions', 26),\n",
       "             ('mid', 26),\n",
       "             ('hooded', 26),\n",
       "             ('snow', 78),\n",
       "             ('stuffed', 52),\n",
       "             ('shirt', 104),\n",
       "             ('carpet', 26),\n",
       "             ('bag', 182),\n",
       "             ('tucked', 26),\n",
       "             ('arm', 286),\n",
       "             ('started', 26),\n",
       "             ('cape', 104),\n",
       "             ('horn', 52),\n",
       "             ('pacific', 26),\n",
       "             ('quitting', 26),\n",
       "             ('manhatto', 26),\n",
       "             ('duly', 26),\n",
       "             ('arrived', 52),\n",
       "             ('bedford', 104),\n",
       "             ('saturday', 78),\n",
       "             ('night', 624),\n",
       "             ('december', 26),\n",
       "             ('disappointed', 26),\n",
       "             ('learning', 26),\n",
       "             ('packet', 26),\n",
       "             ('nantucket', 182),\n",
       "             ('had', 858),\n",
       "             ('already', 26),\n",
       "             ('sailed', 26),\n",
       "             ('offer', 52),\n",
       "             ('till', 156),\n",
       "             ('following', 52),\n",
       "             ('monday', 26),\n",
       "             ('young', 130),\n",
       "             ('candidates', 26),\n",
       "             ('pains', 26),\n",
       "             ('penalties', 26),\n",
       "             ('stop', 208),\n",
       "             ('embark', 52),\n",
       "             ('related', 26),\n",
       "             ('doing', 26),\n",
       "             ('made', 338),\n",
       "             ('craft', 130),\n",
       "             ('fine', 104),\n",
       "             ('boisterous', 26),\n",
       "             ('everything', 26),\n",
       "             ('connected', 26),\n",
       "             ('famous', 26),\n",
       "             ('amazingly', 26),\n",
       "             ('pleased', 52),\n",
       "             ('late', 182),\n",
       "             ('gradually', 26),\n",
       "             ('monopolising', 26),\n",
       "             ('business', 130),\n",
       "             ('matter', 78),\n",
       "             ('behind', 26),\n",
       "             ('original', 52),\n",
       "             ('tyre', 26),\n",
       "             ('carthage;--the', 26),\n",
       "             ('dead', 130),\n",
       "             ('stranded', 52),\n",
       "             ('aboriginal', 26),\n",
       "             ('whalemen', 26),\n",
       "             ('red', 78),\n",
       "             ('sally', 26),\n",
       "             ('canoes', 26),\n",
       "             ('chase', 26),\n",
       "             ('leviathan', 52),\n",
       "             ('too', 364),\n",
       "             ('adventurous', 26),\n",
       "             ('sloop', 26),\n",
       "             ('forth', 26),\n",
       "             ('partly', 78),\n",
       "             ('laden', 26),\n",
       "             ('imported', 26),\n",
       "             ('cobblestones', 26),\n",
       "             ('throw', 26),\n",
       "             ('whales', 52),\n",
       "             ('discover', 26),\n",
       "             ('risk', 26),\n",
       "             ('harpoon', 135),\n",
       "             ('bowsprit', 26),\n",
       "             ('day', 156),\n",
       "             ('another', 130),\n",
       "             ('ere', 78),\n",
       "             ('destined', 26),\n",
       "             ('port', 26),\n",
       "             ('became', 78),\n",
       "             ('concernment', 26),\n",
       "             ('eat', 26),\n",
       "             ('meanwhile', 78),\n",
       "             ('dubious', 26),\n",
       "             ('nay', 52),\n",
       "             ('dark', 208),\n",
       "             ('dismal', 52),\n",
       "             ('bitingly', 26),\n",
       "             ('cold', 182),\n",
       "             ('cheerless', 26),\n",
       "             ('anxious', 26),\n",
       "             ('grapnels', 26),\n",
       "             ('sounded', 26),\n",
       "             ('pocket', 78),\n",
       "             ('only', 364),\n",
       "             ('brought', 26),\n",
       "             ('pieces', 26),\n",
       "             ('silver,--so', 26),\n",
       "             ('wherever', 52),\n",
       "             ('said', 494),\n",
       "             ('stood', 260),\n",
       "             ('middle', 130),\n",
       "             ('dreary', 52),\n",
       "             ('shouldering', 26),\n",
       "             ('comparing', 26),\n",
       "             ('gloom', 26),\n",
       "             ('darkness', 78),\n",
       "             ('wisdom', 26),\n",
       "             ('conclude', 26),\n",
       "             ('lodge', 26),\n",
       "             ('dear', 26),\n",
       "             ('sure', 130),\n",
       "             ('inquire', 26),\n",
       "             ('price', 26),\n",
       "             ('halting', 26),\n",
       "             ('steps', 26),\n",
       "             ('paced', 26),\n",
       "             ('sign', 156),\n",
       "             ('crossed', 52),\n",
       "             ('harpoons\"--but', 26),\n",
       "             ('looked', 156),\n",
       "             ('expensive', 52),\n",
       "             ('further', 104),\n",
       "             ('bright', 52),\n",
       "             ('windows', 52),\n",
       "             ('fish', 78),\n",
       "             ('inn', 78),\n",
       "             ('fervent', 26),\n",
       "             ('rays', 26),\n",
       "             ('seemed', 416),\n",
       "             ('melted', 26),\n",
       "             ('packed', 52),\n",
       "             ('ice', 104),\n",
       "             ('house', 286),\n",
       "             ('everywhere', 26),\n",
       "             ('congealed', 26),\n",
       "             ('frost', 104),\n",
       "             ('lay', 234),\n",
       "             ('inches', 52),\n",
       "             ('thick', 52),\n",
       "             ...])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2717"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ..., 2712,   14,   24],\n",
       "       [  14,  263,   51, ...,   14,   24,  957],\n",
       "       [ 263,   51,  261, ...,   24,  957,    5],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,  262,   53,    2],\n",
       "       [  12,  166, 2711, ...,   53,    2, 2717],\n",
       "       [ 166, 2711,    3, ...,    2, 2717,   26]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y,num_classes=vocabulary_size+1)\n",
    "# +1 needed to hold a azero..this is how keras padding works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ...,    6, 2712,   14],\n",
       "       [  14,  263,   51, ..., 2712,   14,   24],\n",
       "       [ 263,   51,  261, ...,   14,   24,  957],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,   11,  262,   53],\n",
       "       [  12,  166, 2711, ...,  262,   53,    2],\n",
       "       [ 166, 2711,    3, ...,   53,    2, 2717]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312, 25)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312, 25)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size,seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size,seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    \n",
    "    model.add(Dense(vocabulary_size,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            67950     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 25, 50)            15200     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2718)              138618    \n",
      "=================================================================\n",
      "Total params: 244,518\n",
      "Trainable params: 244,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "89/89 [==============================] - 5s 61ms/step - loss: 6.9763 - accuracy: 0.0490\n",
      "Epoch 2/2\n",
      "89/89 [==============================] - 6s 66ms/step - loss: 6.3782 - accuracy: 0.0529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ef2448a08>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model training\n",
    "model.fit(X,y,batch_size=128,epochs = 2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_mobydick_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer,open('my_simple_tokenizer','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in NLP.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 7fca373] New code push\n",
      " 1 file changed, 52 insertions(+), 22 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in NLP.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "To https://github.com/Ashishkhurana01/NLP.git\n",
      "   c1607f6..7fca373  main -> main\n"
     ]
    }
   ],
   "source": [
    "! git fetch\n",
    "! git add test.txt\n",
    "! git add NLP.ipynb\n",
    "! git commit -m \"New code push\" NLP.ipynb\n",
    "! git push origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
