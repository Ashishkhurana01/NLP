{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"NLP stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Ashish'\n",
    "\n",
    "# Using the old .format() method:\n",
    "print('His name is {var}.'.format(var=name))\n",
    "\n",
    "# Using f-strings:\n",
    "print(f'His name is {name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = [('Author', 'Topic', 'Pages'), ('Twain', 'Rafting', 601), ('Feynman', 'Physics', 95), ('Hamilton', 'Mythology', 144)]\n",
    "\n",
    "for book in library:\n",
    "    print(f'{book[0]:{10}} {book[1]:{8}} {book[2]:{7}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in library:\n",
    "    print(f'{book[0]:{10}} {book[1]:{10}} {book[2]:.>{7}}') # here .> was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime(year=2018, month=1, day=27)\n",
    "\n",
    "print(f'{today:%B %d, %Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test.txt\n",
    "Hello, this is a quick test file.\n",
    "This is the second line of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('whoops.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text.txt file we created earlier\n",
    "myfile = open('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now read the file\n",
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seek to the start of file (index 0)\n",
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read again\n",
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readlines returns a list of the lines in the file\n",
    "myfile.seek(0)\n",
    "myfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file first\n",
    "myfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylines = myfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in mylines:\n",
    "    print(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('testing again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('test.txt','w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.write('MY BRAND NEW TEXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('test.txt','a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.write('My first line in a+ opening')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile = open('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile.write('try writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('whoops.txt',mode='a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.write('\\nThis is an added line beacuse i used a + mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto closing\n",
    "with open('whoops.txt','r') as mynewfile:\n",
    "    myvar = mynewfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('US_Declaration.pdf', mode = 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_Reader = PyPDF2.PdfFileReader(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_Reader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_one = pdf_Reader.getPage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext=page_one.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('US_Declaration.pdf', mode='rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfreader = PyPDF2.PdfFileReader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_page = pdfreader.getPage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfwriter = PyPDF2.PdfFileWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfwriter.addPage(first_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_output = open('My_brand_new_file.pdf','wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfwriter.write(pdf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_new = open('My_brand_new_file.pdf',mode='rb')\n",
    "\n",
    "pdf_Reader = PyPDF2.PdfFileReader(brand_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_Reader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('US_Declaration.pdf',mode='rb')\n",
    "\n",
    "pdf_text = []\n",
    "\n",
    "pdf_reader = PyPDF2.PdfFileReader(f)\n",
    "\n",
    "for p in range(pdf_reader.numPages):\n",
    "    page = pdf_reader.getPage(p)\n",
    "    pdf_text.append(page.extractText())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in pdf_text:\n",
    "    print(page)\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The phone number of agent is 444-555-1234. Call soon!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_match = re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_match.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_match.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my phone is a phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first match\n",
    "match = re.search(pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the matches\n",
    "all_matches = re.findall('phone',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in re.finditer('phone',text):\n",
    "    print(match.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'My tel number is 444-555-3333'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_num = re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_num.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\d{3}-\\d{3}-\\d{4}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_num = re.search(pattern, text)\n",
    "ph_num.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(\\d{3})-(\\d{3})-(\\d{4})\"\n",
    "ph_num = re.search(pattern, text)\n",
    "for i in ph_num.group():\n",
    "    print(i)\n",
    "ph_num.group(1)\n",
    "#ph_num.group(2)\n",
    "#ph_num.group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r\"man|woman\", \"The woman was here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"..at\",\"The cat with hat sat splat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\d$\",\"This ends with a 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"^\\d\",\"2 This ends with a 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"[^\\d]\",\"There are 2 numbers 35 inside 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"[^\\d]+\",\"There are 2 numbers 35 inside 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punct\n",
    "test_ph = \"This sentence has punct. I need to remove it, although carefully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = re.findall(r\"[^!.? , ]+\",test_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos, token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't looking into startups anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.pos, token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_quote = doc3[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is the second sentence. This is the third sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring = '\"We\\'re moving to L.A.!\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in doc2:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc2.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u\"It is better to give than receive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc8 =nlp(u'Apple to build a factory in HK for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc8:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in doc8.ents:\n",
    "    print(entity)\n",
    "    print(entity.label_)\n",
    "    print(str(spacy.explain(entity.label_)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Apple is going to build a U.K. factory for $6 million.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "displacy.render(doc, style='dep',jupyter=True, options={'distance':110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'This is a sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    print(word + '---->' +p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because i love to run since i ran.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc1:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.lemma,'\\t',token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_:{28}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"I saw ten mice today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['is'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]\n",
    "\n",
    "matcher.add('SolarPower', None, pattern1, pattern2, pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power is good. I like solar-power bike. The SOLARPOWER works.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower',None, pattern1,pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Solarpower is solar-power.!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/reaganomics.txt') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['voodoo economics','supply-side economics','trickle-down economics','free-market economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(phrase_patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('Econmatcher',None, *phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc3)\n",
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc3[start-10:end+10]\n",
    "    print(match_id,string_id,start,end,span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc[4].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc[4].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I read books on NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = word\n",
    "print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I read a book on NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = doc[1]\n",
    "token = word\n",
    "print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts = doc.count_by(spacy.attrs.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f\"{k}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'distance':110,'compact':'True', 'color':'yellow','bg':'#09a3d5','font':'Times'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='dep',jupyter=True, options = options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"This is a sentence. This is another sentence, possibly longer than the other.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = list(doc2.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.serve(spans, style='dep',options = {'distance':110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text + ' - '+ent.label_ + ' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No entities found!')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'May i go now?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entities found!\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I want to visit TajMahal in the month of June 2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TajMahal - ORG - Companies, agencies, institutions, etc.\n",
      "the month of June 2021 - DATE - Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Tesla to build a factory for $6 million in India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla - ORDINAL - \"first\", \"second\", etc.\n",
      "$6 million - MONEY - Monetary values, including unit\n",
      "India - GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG = doc.vocab.strings[u\"ORG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ent = Span(doc,0,1,label=ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E103] Trying to set conflicting doc.ents: '(0, 1, 'ORDINAL')' and '(0, 1, 'ORG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-da081ec4b4ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_ent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E103] Trying to set conflicting doc.ents: '(0, 1, 'ORDINAL')' and '(0, 1, 'ORG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap."
     ]
    }
   ],
   "source": [
    "doc.ents = list(doc.ents) + [new_ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAmed Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Our company created a brand new vacuum cleaner.' \n",
    "          u'This vacuum-cleaner is best in show.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entities found!\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['vacuum cleaner','vacuum-cleaner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('newproduct',None,*phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2689272359382549672, 6, 8), (2689272359382549672, 10, 13)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD = doc.vocab.strings[u\"PRODUCT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2689272359382549672, 6, 8), (2689272359382549672, 10, 13)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ents = [Span(doc,match[1],match[2],label=PROD) for match in found_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "vacuum-cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### render ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Over the last quarter, Apple sold nearly 20 thousand iPhones for a profit of $6 million.\"\n",
    "         u\"By contraast, SOny only sold 8 thousand Walkman music players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " iPhones for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".By contraast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SOny\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " only sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    8 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Walkman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " music players</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " iPhones for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By contraast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SOny\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " only sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    8 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Walkman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " music players</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    displacy.render(nlp(sent.text),style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'ORG':'red'}\n",
    "options = {'ents':['PRODUCT','ORG'],'colors':colors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over the last quarter, \n",
       "<mark class=\"entity\" style=\"background: red; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold nearly 20 thousand iPhones for a profit of $6 million.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By contraast, \n",
       "<mark class=\"entity\" style=\"background: red; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SOny\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " only sold 8 thousand Walkman music players</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    displacy.render(nlp(sent.text),style='ent',jupyter=True,options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"This is the first sentence. This is another sentence. This is the last sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is the first sentence."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'\"Management is doing the right things; leadership is doing the right things.\" - Peter D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Management is doing the right things; leadership is doing the right things.\" - Peter D'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing the right things; leadership is doing the right things.\"\n",
      "\n",
      "\n",
      "- Peter D\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'set_custom_boundaries', 'parser', 'ner']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(set_custom_boundaries,before='parser')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'\"Management is doing the right things; leadership is doing the right things.\" - Peter D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing the right things;\n",
      "leadership is doing the right things.\"\n",
      "- Peter D\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import SentenceSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_newlines(doc):\n",
    "    start = 0\n",
    "    seen_newline = False\n",
    "    \n",
    "    for word in doc:\n",
    "        if seen_newline:\n",
    "            yield doc[start:word.i]\n",
    "            start = word.i\n",
    "            seen_newline = False\n",
    "        elif word.text.startswith('\\n'):\n",
    "            seen_newline = True\n",
    "            \n",
    "    yield doc[start:]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbd = SentenceSegmenter(nlp.vocab,strategy=split_on_newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(sbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence. This is another.\n",
      "\n",
      "\n",
      "This is a \n",
      "\n",
      "third sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users\\khura/Documents/Ashish/Career related/Git/NLP/smsspamcollection.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  message  length  punct\n",
       "0     False    False   False  False\n",
       "1     False    False   False  False\n",
       "2     False    False   False  False\n",
       "3     False    False   False  False\n",
       "4     False    False   False  False\n",
       "...     ...      ...     ...    ...\n",
       "5567  False    False   False  False\n",
       "5568  False    False   False  False\n",
       "5569  False    False   False  False\n",
       "5570  False    False   False  False\n",
       "5571  False    False   False  False\n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "        ... \n",
       "5567    spam\n",
       "5568     ham\n",
       "5569     ham\n",
       "5570     ham\n",
       "5571     ham\n",
       "Name: label, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD9CAYAAABHnDf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAUR0lEQVR4nO3df5DcdZ3n8ec7kCW6C4JkpGICTrDAijBHWMdES9iFwsWAF1GUPXILlyhHxCKU6KkRr+qgtLbK0lXKxTskHBTZqhjDGixg4bxF3QOpgpUJBCbZrEvQrI5JJdngsSn5cUl43x/znWwTOpnu6e7pmc88H1Vd3f3pz/f7fY82r/7k09/+fCMzkSSVZVq3C5AktZ/hLkkFMtwlqUCGuyQVyHCXpAIZ7pJUoFHDPSJOjoi/i4gtEbE5Ij5dtb85Ih6KiGer+xOq9oiIv4yIrRHxTET8Yaf/CEnSa8Vo57lHxCxgVmY+GRHHAhuADwPLgOcz86sR8UXghMxcGREXA9cBFwMLgW9l5sIjHWPmzJnZ29vb8h8jSVPJhg0b/iUze+q9dvRoG2fmDmBH9XhvRGwBZgOXAOdV3VYD/wdYWbX/VQ5/ajweEcdHxKxqP3X19vYyMDDQ+F8kSSIi/vlwrzU15x4RvcDZwN8DJ40EdnX/lqrbbODXNZsNVW2H7mt5RAxExMDu3bubKUOSNIqGwz0i/gBYD1yfmf96pK512l4395OZqzKzPzP7e3rq/qtCkjRGDYV7RExnONjXZOY9VfPOaj5+ZF5+V9U+BJxcs/kcYHt7ypUkNWLUOfeICOAOYEtmfrPmpfuApcBXq/t7a9pXRMT3GP5C9YUjzbdLUqP27dvH0NAQL7/8crdLGVczZsxgzpw5TJ8+veFtRg134H3AlcBgRGys2r7EcKjfHRFXAb8CLqtee5DhM2W2Ai8CH2+4Gkk6gqGhIY499lh6e3sZHneWLzPZs2cPQ0NDzJ07t+HtGjlb5lHqz6MDXFCnfwLXNlyBJDXo5ZdfnlLBDhARnHjiiTR74om/UJU0qUylYB8xlr/ZcJekJmzbto0zzzyz22WMqpE5d0lq2eJbHn3N8/uvO6ft+2xVO2qaKBy5S1KTDhw4wNVXX80ZZ5zBhRdeyEsvvcTtt9/Ou9/9bs466yw++tGP8uKLLwKwbNkyPvWpT3H++edz6qmn8vDDD/OJT3yCefPmsWzZso7VaLhLUpOeffZZrr32WjZv3szxxx/P+vXrufTSS3niiSd4+umnmTdvHnfcccfB/r/97W/5yU9+ws0338zixYv5zGc+w+bNmxkcHGTjxo1HONLYGe6S1KS5c+cyf/58AN71rnexbds2Nm3axLnnnktfXx9r1qxh8+bNB/svXryYiKCvr4+TTjqJvr4+pk2bxhlnnMG2bds6UqPhLklNOuaYYw4+Puqoo9i/fz/Lli3j29/+NoODg9x4442v+aHVSP9p06a9Zttp06axf//+jtRouEtSG+zdu5dZs2axb98+1qxZ0+1yPFtGktrhK1/5CgsXLuRtb3sbfX197N27t6v1jHqxjvHQ39+frucula0dp0Ju2bKFefPmtaukSaXe3x4RGzKzv15/p2UkqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQP2KSNHnd9sft3d8nH27v/rpo1JF7RNwZEbsiYlNN27qI2Fjdto1cWzUieiPipZrXvtPJ4iVpPP3ud7/jgx/8IGeddRZnnnkm69ato7e3l5UrV7JgwQIWLFjA1q1bAbj//vtZuHAhZ599Nu9///vZuXMnADfddBNLly7lwgsvpLe3l3vuuYcvfOEL9PX1sWjRIvbt29eWWhuZlrkLWFTbkJn/ITPnZ+Z8YD1wT83Lz428lpnXtKVKSZoAfvjDH/LWt76Vp59+mk2bNrFo0XA0HnfccfzsZz9jxYoVXH/99QCcc845PP744zz11FNcfvnlfO1rXzu4n+eee44HHniAe++9lyuuuILzzz+fwcFB3vCGN/DAAw+0pdZRwz0zHwGer/daDF/Y70+BtW2pRpImsL6+Pn70ox+xcuVKfvrTn/KmN70JgCVLlhy8f+yxxwAYGhriAx/4AH19fXz9619/zRLAF110EdOnT6evr48DBw4c/JDo6+tr2xLArX6hei6wMzOfrWmbGxFPRcTDEXHu4TaMiOURMRARA81e1VuSuuH0009nw4YN9PX1ccMNN/DlL38ZeO0FrEceX3fddaxYsYLBwUFuu+22wy4BPH369IPbtHMJ4FbDfQmvHbXvAE7JzLOBzwLfjYjj6m2Ymasysz8z+3t6elosQ5I6b/v27bzxjW/kiiuu4HOf+xxPPvkkAOvWrTt4/973vheAF154gdmzZwOwevXqca91zGfLRMTRwKXAu0baMvMV4JXq8YaIeA44HXDJR0mT3uDgIJ///OcPjrhvvfVWPvaxj/HKK6+wcOFCXn31VdauHR7v3nTTTVx22WXMnj2b97znPfzyl78c11obWvI3InqBv8nMM2vaFgE3ZOYf17T1AM9n5oGIOBX4KdCXmXXn7Ee45K9UvlKX/O3t7WVgYICZM2d29DhtX/I3ItYCjwHviIihiLiqeulyXv9F6h8Bz0TE08D3gWtGC3ZJUvuNOi2TmUsO076sTtt6hk+NlKQpoVMXuG6Vyw9IUoEMd0mTykS4NOh4G8vfbLhLmjRmzJjBnj17plTAZyZ79uxhxowZTW3nwmGSJo05c+YwNDTEVPvh44wZM5gzZ05T2xjukiaN6dOnM3fu3G6XMSk4LSNJBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklSgRq6hemdE7IqITTVtN0XEbyJiY3W7uOa1GyJia0T8PCI+0KnCJU1ti2959OBNr9fIyP0uYFGd9pszc351exAgIt7J8IWzz6i2+R8RcVS7ipUkNWbUcM/MR4DnG9zfJcD3MvOVzPwlsBVY0EJ9kqQxaGXOfUVEPFNN25xQtc0Gfl3TZ6hqe52IWB4RAxExMNWuqiJJnTbWcL8VeDswH9gBfKNqjzp9617sMDNXZWZ/Zvb39PSMsQxJUj1jCvfM3JmZBzLzVeB2/m3qZQg4uabrHGB7ayVKkpo1pnCPiFk1Tz8CjJxJcx9weUQcExFzgdOAn7VWoiSpWaNeIDsi1gLnATMjYgi4ETgvIuYzPOWyDfgkQGZujoi7gX8A9gPXZuaBzpQuSTqcUcM9M5fUab7jCP3/HPjzVoqSpPE0cq78/ded0+VK2sdfqEpSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKtCo4R4Rd0bErojYVNP29Yj4x4h4JiJ+EBHHV+29EfFSRGysbt/pZPGSpPoaGbnfBSw6pO0h4MzM/HfAPwE31Lz2XGbOr27XtKdMSVIzRg33zHwEeP6Qtr/NzP3V08eBOR2oTZI0Ru2Yc/8E8L9qns+NiKci4uGIOPdwG0XE8ogYiIiB3bt3t6EMSdKIlsI9Iv4rsB9YUzXtAE7JzLOBzwLfjYjj6m2bmasysz8z+3t6elopQ5J0iDGHe0QsBf498GeZmQCZ+Upm7qkebwCeA05vR6GSNBEtvuVRFt/yaLfLeJ0xhXtELAJWAh/KzBdr2nsi4qjq8anAacAv2lGoJKlxR4/WISLWAucBMyNiCLiR4bNjjgEeigiAx6szY/4I+HJE7AcOANdk5vN1dyxJ6phRwz0zl9RpvuMwfdcD61stStLkNxGnKqYSf6EqSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5J42Q8r7faULhHxJ0RsSsiNtW0vTkiHoqIZ6v7E6r2iIi/jIitEfFMRPxhp4qXJNXX6Mj9LmDRIW1fBH6cmacBP66eA1zE8IWxTwOWA7e2XqYkqRkNhXtmPgIceqHrS4DV1ePVwIdr2v8qhz0OHB8Rs9pRrCSpMa3MuZ+UmTsAqvu3VO2zgV/X9Buq2iRJ46QTX6hGnbZ8XaeI5RExEBEDu3fv7kAZkjR1Hd3CtjsjYlZm7qimXXZV7UPAyTX95gDbD904M1cBqwD6+/tfF/6S1KjaM1Duv+6cLlYycbQycr8PWFo9XgrcW9P+n6qzZt4DvDAyfSNJGh8NjdwjYi1wHjAzIoaAG4GvAndHxFXAr4DLqu4PAhcDW4EXgY+3uWZJ0igaCvfMXHKYly6o0zeBa1spSpLUGn+hKkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBWpl4TBJ6jgXBRsbR+6SVCBH7pK64kgXinaE3jpH7pJUIMNdkgpkuEtSgQx3SSqQX6hKmnCO9GWrGuPIXZIKNOaRe0S8A1hX03Qq8N+A44Grgd1V+5cy88ExVyhJlWZH9KP9AKrkfyGMOdwz8+fAfICIOAr4DfADhi+IfXNm/kVbKpQkNa1d0zIXAM9l5j+3aX+SpBa0K9wvB9bWPF8REc9ExJ0RcUKbjiFJalDL4R4Rvwd8CPjrqulW4O0MT9nsAL5xmO2WR8RARAzs3r27XhdJ0hi1Y+R+EfBkZu4EyMydmXkgM18FbgcW1NsoM1dlZn9m9vf09LShDEnSiHaE+xJqpmQiYlbNax8BNrXhGJKkJrT0I6aIeCPwJ8Ana5q/FhHzgQS2HfKaJHXFyGmPU2XFyZbCPTNfBE48pO3KliqSJLXM5QckqVLSVZ9cfkCSCuTIXVJRRltSYKxLGEy2kbwjd0kqkCN3SRqDib7omCN3SSqQ4S5JBXJaRpLqaMe0Sze/jHXkLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBfIXqpLUhIm+YNiIlsM9IrYBe4EDwP7M7I+INwPrgF6Gr6P6p5n521aPJUlqTLumZc7PzPmZ2V89/yLw48w8Dfhx9VySNE46Ned+CbC6erwa+HCHjiNJE1K3p2/aMeeewN9GRAK3ZeYq4KTM3AGQmTsi4i2HbhQRy4HlAKecckobypCkzul2WDerHeH+vszcXgX4QxHxj41sVH0IrALo7+/PNtQhSV0z0a612nK4Z+b26n5XRPwAWADsjIhZ1ah9FrCr1eNI0mQwUUb4Lc25R8TvR8SxI4+BC4FNwH3A0qrbUuDeVo4jSWpOqyP3k4AfRMTIvr6bmT+MiCeAuyPiKuBXwGUtHkeS1ISWwj0zfwGcVad9D3BBK/uWJI2dyw9IUoEMd0kqkOEuSQUy3CVpnI3H6ZKuCilJHdaNc98duUtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZK6YPEtj3b0/HfDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQGMO94g4OSL+LiK2RMTmiPh01X5TRPwmIjZWt4vbV64kqRGtLPm7H/gvmflkRBwLbIiIh6rXbs7Mv2i9PEnSWIw53DNzB7Cjerw3IrYAs9tVmCRp7Noy5x4RvcDZwN9XTSsi4pmIuDMiTjjMNssjYiAiBnbv3t2OMiRJlZbDPSL+AFgPXJ+Z/wrcCrwdmM/wyP4b9bbLzFWZ2Z+Z/T09Pa2WIUmq0VK4R8R0hoN9TWbeA5CZOzPzQGa+CtwOLGi9TElSM1o5WyaAO4AtmfnNmvZZNd0+Amwae3mSpLFo5WyZ9wFXAoMRsbFq+xKwJCLmAwlsAz7ZUoWSpKa1crbMo0DUeenBsZcjSWoHf6EqSQVqZVpG0iRwuDXD77/unHE5jrrDkbskFciRu6Qjqjcib/eoX+3nyF2SCuTIXVNOs3PDjlI1GTlyl6QCOXKXpijn0stmuEs6yNMZy2G4a9y1I0AcYXaXHwITn+EuTSKGqhpluEujaDRQ/deEJhLDfQLr5ijNoJImN8NdGkeNfGD7wap28Dx3SSqQI3fV5Rd30uRmuEsTjB+saociwt3/GDQR+D7URNKxcI+IRcC3gKOA/5mZX+3UsTT1GKQ6nG/+308ffPzZ47/VxUq6qyPhHhFHAf8d+BNgCHgiIu7LzH/oxPEkqVtqP0wO1c0Pl06N3BcAWzPzFwAR8T3gEsBwl1rQ6SCpt/92BdSh+251v+0YoY/sY2T7Rv73PVKfw+3/0H2Mh8jM9u804mPAosz8z9XzK4GFmbmips9yYHn19B3Azw/ZzUzgX9peXPe9CXihwOO3Y7+t7KPZbRvt30i/Rvr4fp5cx2/Xfse6n0a3e1tm9tR9JTPbfgMuY3iefeT5lcAtTe5joBO1dfsGrCrx+O3Ybyv7aHbbRvs30q/BPr6fJ9Hx27Xfse6nHcfv1I+YhoCTa57PAbZ36FiTzf2FHr8d+21lH81u22j/Rvp1+//Tbur23z6R38+t7Kfl43dqWuZo4J+AC4DfAE8A/zEzNzexj4HM7G97cVIX+H7WeOvIF6qZuT8iVgD/m+FTIe9sJtgrq9pfmdQ1vp81rjoycpckdZcLh0lSgQx3SSqQ4S5JBTLcJalAkyLcI+L3I2J1RNweEX/W7XqkVkTEqRFxR0R8v9u1qFxdC/eIuDMidkXEpkPaF0XEzyNia0R8sWq+FPh+Zl4NfGjci5VG0cz7OTN/kZlXdadSTRXdHLnfBSyqbahZTfIi4J3Akoh4J8O/cP111e3AONYoNeouGn8/Sx3XtXDPzEeA5w9pPriaZGb+P2BkNckhhgMeJslUkqaWJt/PUsdNtKCczb+N0GE41GcD9wAfjYhb6f5aFlKj6r6fI+LEiPgOcHZE3NCd0lS6iXaZvajTlpn5O+Dj412M1KLDvZ/3ANeMdzGaWibayN3VJFUS38/qmokW7k8Ap0XE3Ij4PeBy4L4u1ySNle9ndU03T4VcCzwGvCMihiLiqszcD4ysJrkFuHsMq0lK4873syYaV4WUpAJNtGkZSVIbGO6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXo/wMqLB+Mfvj1QQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15*(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['length'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['length'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15*(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['punct'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['punct'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X features, y labels\n",
    "X = df[['length','punct']]\n",
    "y= df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1672, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1672,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708     ham\n",
       "4338    ham\n",
       "5029    ham\n",
       "4921    ham\n",
       "2592    ham\n",
       "       ... \n",
       "3772    ham\n",
       "5191    ham\n",
       "5226    ham\n",
       "5390    ham\n",
       "860     ham\n",
       "Name: label, Length: 3900, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr_model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245     ham\n",
       "944      ham\n",
       "1044     ham\n",
       "2484     ham\n",
       "812      ham\n",
       "        ... \n",
       "2505     ham\n",
       "2525    spam\n",
       "4975     ham\n",
       "650     spam\n",
       "4463     ham\n",
       "Name: label, Length: 1672, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1404,   44],\n",
       "       [ 219,    5]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1404</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1404    44\n",
       "spam   219     5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['ham','spam'],columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.91      1448\n",
      "        spam       0.10      0.02      0.04       224\n",
      "\n",
      "    accuracy                           0.84      1672\n",
      "   macro avg       0.48      0.50      0.48      1672\n",
      "weighted avg       0.76      0.84      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427033492822966\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1438   10]\n",
      " [ 224    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X_train,y_train)\n",
    "\n",
    "predictions = nb_model.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1438</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1438    10\n",
       "spam   224     0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['ham','spam'],columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8600478468899522\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.92      1448\n",
      "        spam       0.00      0.00      0.00       224\n",
      "\n",
      "    accuracy                           0.86      1672\n",
      "   macro avg       0.43      0.50      0.46      1672\n",
      "weighted avg       0.75      0.86      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1373   75]\n",
      " [ 121  103]]\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(gamma='auto')\n",
    "svc_model.fit(X_train,y_train)\n",
    "predictions = svc_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8827751196172249\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text FEature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khura\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users\\khura/Documents/Ashish/Career related/Git/NLP/smsspamcollection.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khura\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3733x7082 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 49992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfTransformer used to give weights to words which are more important\n",
    "# PAss count vectors in tfidftransformer instance\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1586    7]\n",
      " [  12  234]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.97      0.95      0.96       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.98      0.97      0.98      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989668297988037"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"You wona  lottery of 500000 Rupees, let's gehter togather to celebrete this victrey. TEXT 455500\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie review practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/khura/Documents/Ashish/Career related/Git/NLP/moviereviews.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1965"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking empty strings\n",
    "blanks=[]\n",
    "\n",
    "for i,lb,rv in df.itertuples():\n",
    "    if rv.isspace():\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57,\n",
       " 71,\n",
       " 147,\n",
       " 151,\n",
       " 283,\n",
       " 307,\n",
       " 313,\n",
       " 323,\n",
       " 343,\n",
       " 351,\n",
       " 427,\n",
       " 501,\n",
       " 633,\n",
       " 675,\n",
       " 815,\n",
       " 851,\n",
       " 977,\n",
       " 1079,\n",
       " 1299,\n",
       " 1455,\n",
       " 1493,\n",
       " 1525,\n",
       " 1531,\n",
       " 1763,\n",
       " 1851,\n",
       " 1905,\n",
       " 1993]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blanks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  49]\n",
      " [ 49 283]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.84      0.84       308\n",
      "         pos       0.85      0.85      0.85       332\n",
      "\n",
      "    accuracy                           0.85       640\n",
      "   macro avg       0.85      0.85      0.85       640\n",
      "weighted avg       0.85      0.85      0.85       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word vectors with Spacy and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'fox').vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.049945  ,  0.053725  ,  0.20525   , -0.0105055 , -0.173665  ,\n",
       "        0.31194   , -0.038755  ,  0.108413  ,  0.609482  ,  1.546705  ,\n",
       "       -0.02152   , -0.360115  , -0.47591   , -0.0627449 , -0.347965  ,\n",
       "        0.30854   , -0.0881895 ,  0.49901   , -0.1050725 , -0.340445  ,\n",
       "       -0.34565252,  0.1045825 ,  0.11942   , -0.21643   ,  0.16901049,\n",
       "        0.0925955 , -0.32559502,  0.084052  , -0.169115  , -0.0250445 ,\n",
       "       -0.33641   , -0.07693   ,  0.3783455 , -0.306474  , -0.0187885 ,\n",
       "       -0.07780001, -0.11146501, -0.19961   , -0.06702   ,  0.13874099,\n",
       "        0.0843545 ,  0.45318502, -0.1510275 ,  0.0115    ,  0.1327575 ,\n",
       "        0.1490885 , -0.23852   , -0.22235501, -0.12563501,  0.165457  ,\n",
       "        0.00664   ,  0.121729  ,  0.011205  , -0.1158115 , -0.21391499,\n",
       "        0.10549255,  0.28629   ,  0.39518   , -0.12843099, -0.08453999,\n",
       "        0.00337   ,  0.1745925 , -0.01421499,  0.005781  , -0.031485  ,\n",
       "       -0.57041   ,  0.0769865 ,  0.093595  ,  0.16210599, -0.14208499,\n",
       "       -0.0280945 , -0.22301999, -0.026069  ,  0.006984  , -0.15548399,\n",
       "        0.042615  , -0.11257999,  0.165935  ,  0.047605  ,  0.095661  ,\n",
       "       -0.3116425 , -0.121474  ,  0.19843501, -0.03446001, -0.058295  ,\n",
       "        0.15937   ,  0.739555  ,  0.27352098,  0.387025  , -0.01097   ,\n",
       "        0.23895301,  0.44705498, -0.022375  , -0.85669005,  0.34948   ,\n",
       "       -0.24239501,  0.06134999, -0.019465  ,  0.058985  , -0.01911   ,\n",
       "        0.271445  , -0.00587   , -0.14644599,  0.017975  ,  0.033315  ,\n",
       "       -0.5271    ,  0.07429899,  0.003335  , -0.16397001, -0.1759575 ,\n",
       "       -0.02460499, -0.12524   , -0.15724501, -0.01273499, -0.0065    ,\n",
       "        0.398135  ,  0.0272465 ,  0.133349  ,  0.10507751,  0.1049065 ,\n",
       "        0.1549235 , -0.0372825 ,  0.325995  , -0.60782   , -0.51576   ,\n",
       "        0.065467  ,  0.0023595 ,  0.274515  , -0.21065651, -0.356005  ,\n",
       "       -0.056324  ,  0.28762   ,  0.0145985 ,  0.11610999,  0.045703  ,\n",
       "       -0.2065565 , -0.191125  , -0.12835498,  0.24805   , -0.118665  ,\n",
       "       -1.9667001 , -0.212569  ,  0.31939   , -0.028176  ,  0.42515498,\n",
       "        0.02916   , -0.168135  , -0.348585  , -0.1341665 ,  0.034515  ,\n",
       "       -0.04026   ,  0.11452949,  0.18024701, -0.01863   ,  0.059327  ,\n",
       "       -0.1144065 , -0.23353   ,  0.27453   , -0.145586  ,  0.0883805 ,\n",
       "        0.06223   , -0.3937143 , -0.2274    , -0.053295  ,  0.110396  ,\n",
       "        0.0617285 , -0.31761   , -0.25773   , -0.1563    , -0.20596799,\n",
       "       -0.01689   ,  0.17018971, -0.42855   , -0.038075  , -0.21994   ,\n",
       "        0.32631502,  0.1889    , -0.014415  ,  0.01146   ,  0.350005  ,\n",
       "        0.2385125 , -0.1558207 , -0.095515  ,  0.12649849,  0.1426475 ,\n",
       "        0.238215  ,  0.21388   , -0.070762  ,  0.32891   ,  0.0936221 ,\n",
       "        0.141489  ,  0.122679  ,  0.13614899, -0.10263335, -0.115137  ,\n",
       "        0.28328502, -0.063142  , -0.13279599,  0.193275  , -0.089568  ,\n",
       "       -0.37251002,  0.1470535 , -0.410835  ,  0.103415  ,  0.149254  ,\n",
       "       -0.0833285 , -0.10359301, -0.315535  , -0.0914025 , -0.256005  ,\n",
       "       -0.406275  ,  0.03688999,  0.36357   ,  0.424105  , -0.0439545 ,\n",
       "        0.0897165 , -0.253481  ,  0.271595  , -0.22367   ,  0.206834  ,\n",
       "        0.17470649,  0.0808555 ,  0.0126035 , -0.0534187 , -0.31809577,\n",
       "        0.16239001,  0.611     ,  0.277075  ,  0.268175  ,  0.56304   ,\n",
       "       -0.09004501, -0.137445  ,  0.13364   ,  0.11612301,  0.0670625 ,\n",
       "        0.0125285 ,  0.35744   , -0.1925    , -0.079045  ,  0.387095  ,\n",
       "       -0.1934955 , -0.1697    ,  0.015645  ,  0.158     ,  0.05162   ,\n",
       "       -0.317305  ,  0.12011349,  0.37933502, -0.1531    , -0.1524105 ,\n",
       "        0.109896  , -0.19593   ,  0.05954   ,  0.16069   ,  0.0480475 ,\n",
       "       -0.106784  ,  0.119065  ,  0.063765  , -0.06724   , -0.39038998,\n",
       "        0.54516   ,  0.30905   ,  0.23410001, -0.374215  ,  0.473715  ,\n",
       "       -0.2609965 , -0.0860165 ,  0.01305   ,  0.00689   , -0.11654001,\n",
       "       -0.32248   ,  0.16029501,  0.12455665,  0.28219998,  0.113065  ,\n",
       "        0.02579   ,  0.11029001, -0.082115  , -0.18291003,  0.0098435 ,\n",
       "        0.136485  ,  0.22912   , -0.195376  ,  0.20897   ,  0.104429  ,\n",
       "        0.158918  , -0.061111  , -0.32828498,  0.1030745 , -0.32914   ,\n",
       "       -0.32187   , -0.06835   , -0.3353    ,  0.152425  , -0.159344  ,\n",
       "       -0.43391   ,  0.3846915 , -0.02483   , -0.3084215 , -0.39942002],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'fox runs').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u'lion cat pet horse dog elephant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion lion 1.0\n",
      "lion cat 0.52654374\n",
      "lion pet 0.39923766\n",
      "lion horse 0.45301145\n",
      "lion dog 0.47424486\n",
      "lion elephant 0.71239567\n",
      "cat lion 0.52654374\n",
      "cat cat 1.0\n",
      "cat pet 0.7505456\n",
      "cat horse 0.48473355\n",
      "cat dog 0.80168545\n",
      "cat elephant 0.48571128\n",
      "pet lion 0.39923766\n",
      "pet cat 0.7505456\n",
      "pet pet 1.0\n",
      "pet horse 0.47499648\n",
      "pet dog 0.8057452\n",
      "pet elephant 0.3863391\n",
      "horse lion 0.45301145\n",
      "horse cat 0.48473355\n",
      "horse pet 0.47499648\n",
      "horse horse 1.0\n",
      "horse dog 0.6246276\n",
      "horse elephant 0.49068308\n",
      "dog lion 0.47424486\n",
      "dog cat 0.80168545\n",
      "dog pet 0.8057452\n",
      "dog horse 0.6246276\n",
      "dog dog 1.0\n",
      "dog elephant 0.45768416\n",
      "elephant lion 0.71239567\n",
      "elephant cat 0.48571128\n",
      "elephant pet 0.3863391\n",
      "elephant horse 0.49068308\n",
      "elephant dog 0.45768416\n",
      "elephant elephant 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u'dog cat marcially')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "marcially False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token.text,token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "cosine_similarity = lambda vec1, vec2: 1- spatial.distance.cosine(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = nlp.vocab['king'].vector\n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector = king - man + woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_similarities = []\n",
    "\n",
    "# for all words in vocab , look for new vector similarity\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity = cosine_similarity(new_vector, word.vector)\n",
    "                computed_similarities.append((word,similarity))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_similarities = sorted(computed_similarities, key = lambda item:-item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'woman', 'she', 'lion', 'who', 'fox', 'elephant', 'when', 'dare', 'horse']\n"
     ]
    }
   ],
   "source": [
    "print([t[0].text for t in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis with NLTK (vader lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\khura\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"This is an awesome tv series!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.532, 'pos': 0.468, 'compound': 0.6588}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= \"This was the best, and most awesome move EVER MADE!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.458, 'pos': 0.542, 'compound': 0.8877}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= \"This was the best and worst scenario\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.308, 'neu': 0.376, 'pos': 0.316, 'compound': 0.0258}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/amazonreviews.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>pos</td>\n",
       "      <td>A revelation of life in small town America in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>pos</td>\n",
       "      <td>Great biography of a very interesting journali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>neg</td>\n",
       "      <td>Interesting Subject; Poor Presentation: You'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>neg</td>\n",
       "      <td>Don't buy: The box looked used and it is obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pos</td>\n",
       "      <td>Beautiful Pen and Fast Delivery.: The pen was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                             review\n",
       "0      pos  Stuning even for the non-gamer: This sound tra...\n",
       "1      pos  The best soundtrack ever to anything.: I'm rea...\n",
       "2      pos  Amazing!: This soundtrack is my favorite music...\n",
       "3      pos  Excellent Soundtrack: I truly like this soundt...\n",
       "4      pos  Remember, Pull Your Jaw Off The Floor After He...\n",
       "...    ...                                                ...\n",
       "9995   pos  A revelation of life in small town America in ...\n",
       "9996   pos  Great biography of a very interesting journali...\n",
       "9997   neg  Interesting Subject; Poor Presentation: You'd ...\n",
       "9998   neg  Don't buy: The box looked used and it is obvio...\n",
       "9999   pos  Beautiful Pen and Fast Delivery.: The pen was ...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5097\n",
       "pos    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks=[]\n",
    "for i,lb,rv in df.itertuples():\n",
    "    if type(rv) == str:\n",
    "        if rv.isspace():\n",
    "            blanks.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'compound': 0.9454}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(df.iloc[0]['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['compound'] = df['scores'].apply(lambda d:d['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comp_score'] = df['compound'].apply(lambda score: 'pos' if score>=0 else 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound comp_score  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454        pos  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957        pos  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858        pos  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814        pos  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781        pos  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7091"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['label'],df['comp_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.51      0.64      5097\n",
      "         pos       0.64      0.91      0.75      4903\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.70     10000\n",
      "weighted avg       0.75      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['label'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = pd.read_csv('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11992"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(npr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df = 0.9,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document transform matrix\n",
    "dtm = cv.fit_transform(npr['Article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=7, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54777"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab of words\n",
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rotated'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()[42120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ministerial'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_word_id = random.randint(0,33434)\n",
    "cv.get_feature_names()[random_word_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the topics\n",
    "len(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 54777)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.64332806e+00, 2.38014333e+03, 1.42900522e-01, ...,\n",
       "        1.43006821e-01, 1.42902042e-01, 1.42861626e-01],\n",
       "       [2.76191749e+01, 5.36394437e+02, 1.42857148e-01, ...,\n",
       "        1.42861973e-01, 1.42857147e-01, 1.42906875e-01],\n",
       "       [7.22783888e+00, 8.24033986e+02, 1.42857148e-01, ...,\n",
       "        6.14236247e+00, 2.14061364e+00, 1.42923753e-01],\n",
       "       ...,\n",
       "       [3.11488651e+00, 3.50409655e+02, 1.42857147e-01, ...,\n",
       "        1.42859912e-01, 1.42857146e-01, 1.42866614e-01],\n",
       "       [4.61486388e+01, 5.14408600e+01, 3.14281373e+00, ...,\n",
       "        1.43107628e-01, 1.43902481e-01, 2.14271779e+00],\n",
       "       [4.93991422e-01, 4.18841042e+02, 1.42857151e-01, ...,\n",
       "        1.42857146e-01, 1.43760101e-01, 1.42866201e-01]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.64332806e+00, 2.38014333e+03, 1.42900522e-01, ...,\n",
       "       1.43006821e-01, 1.42902042e-01, 1.42861626e-01])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2475, 18302, 35285, ..., 22673, 42561, 42993], dtype=int64)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowest to highest value\n",
    "single_topic.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33390, 36310, 21228, 10425, 31464,  8149, 36283, 22673, 42561,\n",
       "       42993], dtype=int64)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33390, 36310, 21228, 10425, 31464,  8149, 36283, 22673, 42561,\n",
       "       42993], dtype=int64)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_words = single_topic.argsort()[-10:]\n",
    "top_ten_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n",
      "percent\n",
      "government\n",
      "company\n",
      "million\n",
      "care\n",
      "people\n",
      "health\n",
      "said\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "for index in top_ten_words:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the highest probability words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for a topic #0\n",
      "['companies', 'money', 'year', 'federal', '000', 'new', 'percent', 'government', 'company', 'million', 'care', 'people', 'health', 'said', 'says']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #1\n",
      "['military', 'house', 'security', 'russia', 'government', 'npr', 'reports', 'says', 'news', 'people', 'told', 'police', 'president', 'trump', 'said']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #2\n",
      "['way', 'world', 'family', 'home', 'day', 'time', 'water', 'city', 'new', 'years', 'food', 'just', 'people', 'like', 'says']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #3\n",
      "['time', 'new', 'don', 'years', 'medical', 'disease', 'patients', 'just', 'children', 'study', 'like', 'women', 'health', 'people', 'says']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #4\n",
      "['voters', 'vote', 'election', 'party', 'new', 'obama', 'court', 'republican', 'campaign', 'people', 'state', 'president', 'clinton', 'said', 'trump']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #5\n",
      "['years', 'going', 've', 'life', 'don', 'new', 'way', 'music', 'really', 'time', 'know', 'think', 'people', 'just', 'like']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #6\n",
      "['student', 'years', 'data', 'science', 'university', 'people', 'time', 'schools', 'just', 'education', 'new', 'like', 'students', 'school', 'says']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(LDA.components_):\n",
    "    print(f\"The top 15 words for a topic #{i}\")\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article\n",
       "0      In the Washington of 2016, even when the polic...\n",
       "1        Donald Trump has used Twitter  —   his prefe...\n",
       "2        Donald Trump is unabashedly praising Russian...\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4      From photography, illustration and video, to d...\n",
       "...                                                  ...\n",
       "11987  The number of law enforcement officers shot an...\n",
       "11988    Trump is busy these days with victory tours,...\n",
       "11989  It’s always interesting for the Goats and Soda...\n",
       "11990  The election of Donald Trump was a surprise to...\n",
       "11991  Voters in the English city of Sunderland did s...\n",
       "\n",
       "[11992 rows x 1 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.68, 0.  , 0.  , 0.3 , 0.  , 0.  ])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].round(2)\n",
    "# array([0.02, 0.68, 0.  , 0.  , 0.3 , 0.  , 0.  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the Washington of 2016, even when the policy can be bipartisan, the politics cannot. And in that sense, this year shows little sign of ending on Dec. 31. When President Obama moved to sanction Russia over its alleged interference in the U. S. election just concluded, some Republicans who had long called for similar or more severe measures could scarcely bring themselves to approve. House Speaker Paul Ryan called the Obama measures ”appropriate” but also ”overdue” and ”a prime example of this administration’s ineffective foreign policy that has left America weaker in the eyes of the world.” Other GOP leaders sounded much the same theme. ”[We have] been urging President Obama for years to take strong action to deter Russia’s worldwide aggression, including its   operations,” wrote Rep. Devin Nunes,  . chairman of the House Intelligence Committee. ”Now with just a few weeks left in office, the president has suddenly decided that some stronger measures are indeed warranted.” Appearing on CNN, frequent Obama critic Trent Franks,  . called for ”much tougher” actions and said three times that Obama had ”finally found his tongue.” Meanwhile, at    and on Fox News, various spokesmen for   Trump said Obama’s real target was not the Russians at all but the man poised to take over the White House in less than three weeks. They spoke of Obama trying to ”tie Trump’s hands” or ”box him in,” meaning the   would be forced either to keep the sanctions or be at odds with Republicans who want to be tougher still on Moscow. Throughout 2016, Trump has repeatedly called not for sanctions but for closer ties with Russia, including cooperation in the fight against ISIS. Russia has battled ISIS in Syria on behalf of that country’s embattled dictator, Bashar Assad, bombing the besieged   city of Aleppo that fell to Assad’s forces this week. During the campaign, Trump even urged Russia to ”find” missing emails from the private server of his opponent, Hillary Clinton. He has exchanged public encomiums with Russian President Vladimir Putin on several occasions and added his doubts about the current U. S. levels of support for NATO  —   Putin’s longtime nemesis. There have also been suggestions that Trump’s extensive business dealings with various Russians are the reason he refuses to release his tax returns. All those issues have been disquieting to some Republicans for many months. Sens. John McCain,  . and Lindsay Graham,  . C. prominent senior members of the Armed Services Committee, have accepted the assessment of 17 U. S. intelligence agencies regarding the role of Russia in the hacking of various Democratic committees last year. That includes the FBI and CIA consensus that the Russian goal was not just to discredit American democracy but to defeat Clinton and elect Trump. They say the great majority of their Senate colleagues agree with them, and McCain has slated an Armed Services hearing on cyberthreats for Jan. 5. But the politicizing of the Russian actions  —   the idea that they helped Trump win  —   has also made the issue difficult for Republican leaders. It has allowed Trump supporters to push back on the intelligence agencies and say the entire issue is designed to undermine Trump’s legitimacy. Senate Majority Leader Mitch McConnell has so far resisted calls for a select committee to look into the Russian interference in the 2016 campaign. He has said it is enough for Sen. Richard Burr,  . C. to look into it as chairman of the Senate Intelligence Committee. Typically, Republican leaders and spokesmen say there is no evidence that the actual voting or tallying on Nov. 8 was compromised, and that is true. But it is also a red herring, as interference in those functions has not been alleged and is not the focus of the U. S. intelligence agencies’ concern. For his part, Trump has shown little interest in delving into what happened. He has cast doubt on the U. S. intelligence reports to date and suggested ”no one really knows what happened.” He also has suggested that computers make it very difficult to know who is using them. This week, Trump said it was time to ”get on with our lives and do more important things.” However, at week’s end he did agree to have an intelligence briefing on the subject next week. The   has not wanted the daily intelligence briefings available to him in recent weeks, preferring that they be given to the men he has chosen as his vice president (Mike Pence) and national security adviser (Mike Flynn) with Trump taking them only occasionally. The irony of this controversy arising at the eleventh hour of the Obama presidency can scarcely be overstated, and it defines the dilemma facing both the outgoing president and the incoming party in control. Obama appears to have been reluctant to retaliate against the Russian hacking before the election for fear of seeming to interfere with the election himself. The Republicans, meanwhile, have for years called for greater confrontation with the Russians, with Obama usually resisting. Obama did join with NATO in punishing the Russians with economic sanctions over the annexation of Crimea. Those sanctions may have been painful, coming as they did alongside falling prices for oil  —   the commodity that keeps the Russian economy afloat. On other occasions, despite Russian provocations through surrogates in Syria and elsewhere, Obama did not make overt moves to force Russia’s hand. That includes occasions when Russia was believed to be hacking critical computer systems in neighboring Ukraine, Estonia and Poland. But this week, following a chorus of confirmation from the U. S. intelligence community regarding the Russian role in computer hacking in the political campaign, Obama acted. He imposed a set of mostly diplomatic actions such as sanctioning some Russian officials, closing two diplomatic compounds and expelling 35 Russian diplomats. There may have been more damaging measures taken covertly, and some Russophobes in Washington held out hope for that. But the visible portion of the program scarcely amounted to major retribution. And Putin saw fit to diminish the Obama sanctions further by declining to respond. Although his government has steadfastly denied any interference in the U. S. election, Putin rejected his own foreign minister’s recommended package of    responses. (He even sent an invitation for U. S. diplomats to send their children to a holiday party in Moscow.) That allowed Putin to appear for the moment to be ”the bigger man,” even as he spurned Obama and kept up what has looked like a public bromance with Trump, who tweeted: ”Great move on delay (by V. Putin)   I always knew he was very smart!” At the moment it may seem that the overall Russia question amounts to the first crisis facing the Trump presidency. Whether forced by this campaign interference issue or not, Trump must grasp the nettle of a relationship Mitt Romney once called the greatest threat to U. S. security in the world. To be sure, Trump needs to dispel doubts about his ability to stand up to Putin, who has bullied and cajoled his way to center stage in recent world affairs. But Trump also seems determined to turn the page on past U. S. commitments, from free trade philosophy to funding of NATO and the United Nations. And if his Twitter account is any guide, Trump shows little concern about the conundrum others perceive to be facing him. Above all, Trump has shown himself determined to play by his own rules. A year ago, many were confident that would not work for him in the world of presidential politics. We are about to find out whether it works for him in the Oval Office.'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr['Article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article  Topic\n",
       "0      In the Washington of 2016, even when the polic...      1\n",
       "1        Donald Trump has used Twitter  —   his prefe...      1\n",
       "2        Donald Trump is unabashedly praising Russian...      1\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...      1\n",
       "4      From photography, illustration and video, to d...      2\n",
       "...                                                  ...    ...\n",
       "11987  The number of law enforcement officers shot an...      1\n",
       "11988    Trump is busy these days with victory tours,...      4\n",
       "11989  It’s always interesting for the Goats and Soda...      3\n",
       "11990  The election of Donald Trump was a surprise to...      4\n",
       "11991  Voters in the English city of Sunderland did s...      0\n",
       "\n",
       "[11992 rows x 2 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-neg matrix factorization: unsupervised - dimensionality reduction and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "npr = pd.read_csv('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article\n",
       "0      In the Washington of 2016, even when the polic...\n",
       "1        Donald Trump has used Twitter  —   his prefe...\n",
       "2        Donald Trump is unabashedly praising Russian...\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4      From photography, illustration and video, to d...\n",
       "...                                                  ...\n",
       "11987  The number of law enforcement officers shot an...\n",
       "11988    Trump is busy these days with victory tours,...\n",
       "11989  It’s always interesting for the Goats and Soda...\n",
       "11990  The election of Donald Trump was a surprise to...\n",
       "11991  Voters in the English city of Sunderland did s...\n",
       "\n",
       "[11992 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.95,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tfidf.fit_transform(npr['Article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=7, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alienated'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()[2399]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for a topic #0\n",
      "['new', 'research', 'like', 'patients', 'health', 'disease', 'percent', 'women', 'virus', 'study', 'water', 'food', 'people', 'zika', 'says']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #1\n",
      "['gop', 'pence', 'presidential', 'russia', 'administration', 'election', 'republican', 'obama', 'white', 'house', 'donald', 'campaign', 'said', 'president', 'trump']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #2\n",
      "['senate', 'house', 'people', 'act', 'law', 'tax', 'plan', 'republicans', 'affordable', 'obamacare', 'coverage', 'medicaid', 'insurance', 'care', 'health']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #3\n",
      "['officers', 'syria', 'security', 'department', 'law', 'isis', 'russia', 'government', 'state', 'attack', 'president', 'reports', 'court', 'said', 'police']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #4\n",
      "['primary', 'cruz', 'election', 'democrats', 'percent', 'party', 'delegates', 'vote', 'state', 'democratic', 'hillary', 'campaign', 'voters', 'sanders', 'clinton']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #5\n",
      "['love', 've', 'don', 'album', 'way', 'time', 'song', 'life', 'really', 'know', 'people', 'think', 'just', 'music', 'like']\n",
      "\n",
      "\n",
      "The top 15 words for a topic #6\n",
      "['teacher', 'state', 'high', 'says', 'parents', 'devos', 'children', 'college', 'kids', 'teachers', 'student', 'education', 'schools', 'school', 'students']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"The top 15 words for a topic #{i}\")\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = nmf_model.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Topic\n",
       "0  In the Washington of 2016, even when the polic...      1\n",
       "1    Donald Trump has used Twitter  —   his prefe...      1\n",
       "2    Donald Trump is unabashedly praising Russian...      1\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...      3\n",
       "4  From photography, illustration and video, to d...      6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytopic_dict = {0:'health',1:'election',2:'legis',3:'poli',4:'election',5:'music',6:'edu'}\n",
    "npr['Topic Label'] = npr['Topic'].map(mytopic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>3</td>\n",
       "      <td>poli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>6</td>\n",
       "      <td>edu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Topic Topic Label\n",
       "0  In the Washington of 2016, even when the polic...      1    election\n",
       "1    Donald Trump has used Twitter  —   his prefe...      1    election\n",
       "2    Donald Trump is unabashedly praising Russian...      1    election\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...      3        poli\n",
       "4  From photography, illustration and video, to d...      6         edu"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for target var\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_obj = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_obj.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler_obj.transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler_obj.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_dim=4,activation='relu'))\n",
    "model.add(Dense(8,input_dim=4,activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 - 0s - loss: 1.1131 - accuracy: 0.3500\n",
      "Epoch 2/150\n",
      "4/4 - 0s - loss: 1.0980 - accuracy: 0.3500\n",
      "Epoch 3/150\n",
      "4/4 - 0s - loss: 1.0833 - accuracy: 0.3500\n",
      "Epoch 4/150\n",
      "4/4 - 0s - loss: 1.0703 - accuracy: 0.3500\n",
      "Epoch 5/150\n",
      "4/4 - 0s - loss: 1.0579 - accuracy: 0.3500\n",
      "Epoch 6/150\n",
      "4/4 - 0s - loss: 1.0476 - accuracy: 0.3500\n",
      "Epoch 7/150\n",
      "4/4 - 0s - loss: 1.0373 - accuracy: 0.3600\n",
      "Epoch 8/150\n",
      "4/4 - 0s - loss: 1.0292 - accuracy: 0.3600\n",
      "Epoch 9/150\n",
      "4/4 - 0s - loss: 1.0211 - accuracy: 0.3600\n",
      "Epoch 10/150\n",
      "4/4 - 0s - loss: 1.0149 - accuracy: 0.3500\n",
      "Epoch 11/150\n",
      "4/4 - 0s - loss: 1.0083 - accuracy: 0.3500\n",
      "Epoch 12/150\n",
      "4/4 - 0s - loss: 1.0023 - accuracy: 0.3500\n",
      "Epoch 13/150\n",
      "4/4 - 0s - loss: 0.9961 - accuracy: 0.3400\n",
      "Epoch 14/150\n",
      "4/4 - 0s - loss: 0.9904 - accuracy: 0.3400\n",
      "Epoch 15/150\n",
      "4/4 - 0s - loss: 0.9839 - accuracy: 0.3600\n",
      "Epoch 16/150\n",
      "4/4 - 0s - loss: 0.9777 - accuracy: 0.3600\n",
      "Epoch 17/150\n",
      "4/4 - 0s - loss: 0.9716 - accuracy: 0.3600\n",
      "Epoch 18/150\n",
      "4/4 - 0s - loss: 0.9655 - accuracy: 0.3700\n",
      "Epoch 19/150\n",
      "4/4 - 0s - loss: 0.9599 - accuracy: 0.4100\n",
      "Epoch 20/150\n",
      "4/4 - 0s - loss: 0.9542 - accuracy: 0.4000\n",
      "Epoch 21/150\n",
      "4/4 - 0s - loss: 0.9487 - accuracy: 0.4700\n",
      "Epoch 22/150\n",
      "4/4 - 0s - loss: 0.9430 - accuracy: 0.4800\n",
      "Epoch 23/150\n",
      "4/4 - 0s - loss: 0.9374 - accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "4/4 - 0s - loss: 0.9318 - accuracy: 0.5300\n",
      "Epoch 25/150\n",
      "4/4 - 0s - loss: 0.9263 - accuracy: 0.5600\n",
      "Epoch 26/150\n",
      "4/4 - 0s - loss: 0.9202 - accuracy: 0.5600\n",
      "Epoch 27/150\n",
      "4/4 - 0s - loss: 0.9141 - accuracy: 0.5600\n",
      "Epoch 28/150\n",
      "4/4 - 0s - loss: 0.9077 - accuracy: 0.5900\n",
      "Epoch 29/150\n",
      "4/4 - 0s - loss: 0.9017 - accuracy: 0.6100\n",
      "Epoch 30/150\n",
      "4/4 - 0s - loss: 0.8960 - accuracy: 0.6000\n",
      "Epoch 31/150\n",
      "4/4 - 0s - loss: 0.8903 - accuracy: 0.6100\n",
      "Epoch 32/150\n",
      "4/4 - 0s - loss: 0.8852 - accuracy: 0.6100\n",
      "Epoch 33/150\n",
      "4/4 - 0s - loss: 0.8800 - accuracy: 0.6100\n",
      "Epoch 34/150\n",
      "4/4 - 0s - loss: 0.8753 - accuracy: 0.6200\n",
      "Epoch 35/150\n",
      "4/4 - 0s - loss: 0.8706 - accuracy: 0.6100\n",
      "Epoch 36/150\n",
      "4/4 - 0s - loss: 0.8658 - accuracy: 0.6200\n",
      "Epoch 37/150\n",
      "4/4 - 0s - loss: 0.8611 - accuracy: 0.6200\n",
      "Epoch 38/150\n",
      "4/4 - 0s - loss: 0.8565 - accuracy: 0.6200\n",
      "Epoch 39/150\n",
      "4/4 - 0s - loss: 0.8521 - accuracy: 0.6200\n",
      "Epoch 40/150\n",
      "4/4 - 0s - loss: 0.8480 - accuracy: 0.6300\n",
      "Epoch 41/150\n",
      "4/4 - 0s - loss: 0.8436 - accuracy: 0.6300\n",
      "Epoch 42/150\n",
      "4/4 - 0s - loss: 0.8394 - accuracy: 0.6400\n",
      "Epoch 43/150\n",
      "4/4 - 0s - loss: 0.8354 - accuracy: 0.6400\n",
      "Epoch 44/150\n",
      "4/4 - 0s - loss: 0.8311 - accuracy: 0.6400\n",
      "Epoch 45/150\n",
      "4/4 - 0s - loss: 0.8270 - accuracy: 0.6600\n",
      "Epoch 46/150\n",
      "4/4 - 0s - loss: 0.8231 - accuracy: 0.6600\n",
      "Epoch 47/150\n",
      "4/4 - 0s - loss: 0.8187 - accuracy: 0.6700\n",
      "Epoch 48/150\n",
      "4/4 - 0s - loss: 0.8144 - accuracy: 0.6600\n",
      "Epoch 49/150\n",
      "4/4 - 0s - loss: 0.8104 - accuracy: 0.6800\n",
      "Epoch 50/150\n",
      "4/4 - 0s - loss: 0.8061 - accuracy: 0.6600\n",
      "Epoch 51/150\n",
      "4/4 - 0s - loss: 0.8016 - accuracy: 0.6600\n",
      "Epoch 52/150\n",
      "4/4 - 0s - loss: 0.7973 - accuracy: 0.6600\n",
      "Epoch 53/150\n",
      "4/4 - 0s - loss: 0.7932 - accuracy: 0.6600\n",
      "Epoch 54/150\n",
      "4/4 - 0s - loss: 0.7893 - accuracy: 0.6600\n",
      "Epoch 55/150\n",
      "4/4 - 0s - loss: 0.7852 - accuracy: 0.6600\n",
      "Epoch 56/150\n",
      "4/4 - 0s - loss: 0.7812 - accuracy: 0.6600\n",
      "Epoch 57/150\n",
      "4/4 - 0s - loss: 0.7771 - accuracy: 0.6600\n",
      "Epoch 58/150\n",
      "4/4 - 0s - loss: 0.7732 - accuracy: 0.6600\n",
      "Epoch 59/150\n",
      "4/4 - 0s - loss: 0.7693 - accuracy: 0.6500\n",
      "Epoch 60/150\n",
      "4/4 - 0s - loss: 0.7654 - accuracy: 0.6500\n",
      "Epoch 61/150\n",
      "4/4 - 0s - loss: 0.7615 - accuracy: 0.6500\n",
      "Epoch 62/150\n",
      "4/4 - 0s - loss: 0.7578 - accuracy: 0.6500\n",
      "Epoch 63/150\n",
      "4/4 - 0s - loss: 0.7541 - accuracy: 0.6500\n",
      "Epoch 64/150\n",
      "4/4 - 0s - loss: 0.7501 - accuracy: 0.6500\n",
      "Epoch 65/150\n",
      "4/4 - 0s - loss: 0.7469 - accuracy: 0.6500\n",
      "Epoch 66/150\n",
      "4/4 - 0s - loss: 0.7431 - accuracy: 0.6500\n",
      "Epoch 67/150\n",
      "4/4 - 0s - loss: 0.7396 - accuracy: 0.6500\n",
      "Epoch 68/150\n",
      "4/4 - 0s - loss: 0.7358 - accuracy: 0.6600\n",
      "Epoch 69/150\n",
      "4/4 - 0s - loss: 0.7320 - accuracy: 0.6500\n",
      "Epoch 70/150\n",
      "4/4 - 0s - loss: 0.7280 - accuracy: 0.6500\n",
      "Epoch 71/150\n",
      "4/4 - 0s - loss: 0.7243 - accuracy: 0.6500\n",
      "Epoch 72/150\n",
      "4/4 - 0s - loss: 0.7204 - accuracy: 0.6500\n",
      "Epoch 73/150\n",
      "4/4 - 0s - loss: 0.7171 - accuracy: 0.6500\n",
      "Epoch 74/150\n",
      "4/4 - 0s - loss: 0.7144 - accuracy: 0.6700\n",
      "Epoch 75/150\n",
      "4/4 - 0s - loss: 0.7109 - accuracy: 0.6700\n",
      "Epoch 76/150\n",
      "4/4 - 0s - loss: 0.7073 - accuracy: 0.6700\n",
      "Epoch 77/150\n",
      "4/4 - 0s - loss: 0.7038 - accuracy: 0.6700\n",
      "Epoch 78/150\n",
      "4/4 - 0s - loss: 0.7006 - accuracy: 0.6700\n",
      "Epoch 79/150\n",
      "4/4 - 0s - loss: 0.6972 - accuracy: 0.6900\n",
      "Epoch 80/150\n",
      "4/4 - 0s - loss: 0.6940 - accuracy: 0.7000\n",
      "Epoch 81/150\n",
      "4/4 - 0s - loss: 0.6909 - accuracy: 0.7100\n",
      "Epoch 82/150\n",
      "4/4 - 0s - loss: 0.6876 - accuracy: 0.7200\n",
      "Epoch 83/150\n",
      "4/4 - 0s - loss: 0.6846 - accuracy: 0.7600\n",
      "Epoch 84/150\n",
      "4/4 - 0s - loss: 0.6815 - accuracy: 0.7600\n",
      "Epoch 85/150\n",
      "4/4 - 0s - loss: 0.6785 - accuracy: 0.7800\n",
      "Epoch 86/150\n",
      "4/4 - 0s - loss: 0.6752 - accuracy: 0.7800\n",
      "Epoch 87/150\n",
      "4/4 - 0s - loss: 0.6718 - accuracy: 0.7700\n",
      "Epoch 88/150\n",
      "4/4 - 0s - loss: 0.6686 - accuracy: 0.7700\n",
      "Epoch 89/150\n",
      "4/4 - 0s - loss: 0.6650 - accuracy: 0.7700\n",
      "Epoch 90/150\n",
      "4/4 - 0s - loss: 0.6613 - accuracy: 0.7700\n",
      "Epoch 91/150\n",
      "4/4 - 0s - loss: 0.6578 - accuracy: 0.7700\n",
      "Epoch 92/150\n",
      "4/4 - 0s - loss: 0.6545 - accuracy: 0.7500\n",
      "Epoch 93/150\n",
      "4/4 - 0s - loss: 0.6507 - accuracy: 0.7500\n",
      "Epoch 94/150\n",
      "4/4 - 0s - loss: 0.6473 - accuracy: 0.7400\n",
      "Epoch 95/150\n",
      "4/4 - 0s - loss: 0.6438 - accuracy: 0.7200\n",
      "Epoch 96/150\n",
      "4/4 - 0s - loss: 0.6405 - accuracy: 0.7200\n",
      "Epoch 97/150\n",
      "4/4 - 0s - loss: 0.6371 - accuracy: 0.7400\n",
      "Epoch 98/150\n",
      "4/4 - 0s - loss: 0.6338 - accuracy: 0.7500\n",
      "Epoch 99/150\n",
      "4/4 - 0s - loss: 0.6306 - accuracy: 0.7500\n",
      "Epoch 100/150\n",
      "4/4 - 0s - loss: 0.6275 - accuracy: 0.7600\n",
      "Epoch 101/150\n",
      "4/4 - 0s - loss: 0.6238 - accuracy: 0.7700\n",
      "Epoch 102/150\n",
      "4/4 - 0s - loss: 0.6204 - accuracy: 0.7400\n",
      "Epoch 103/150\n",
      "4/4 - 0s - loss: 0.6181 - accuracy: 0.7200\n",
      "Epoch 104/150\n",
      "4/4 - 0s - loss: 0.6143 - accuracy: 0.7200\n",
      "Epoch 105/150\n",
      "4/4 - 0s - loss: 0.6113 - accuracy: 0.7200\n",
      "Epoch 106/150\n",
      "4/4 - 0s - loss: 0.6085 - accuracy: 0.7100\n",
      "Epoch 107/150\n",
      "4/4 - 0s - loss: 0.6051 - accuracy: 0.7200\n",
      "Epoch 108/150\n",
      "4/4 - 0s - loss: 0.6023 - accuracy: 0.7200\n",
      "Epoch 109/150\n",
      "4/4 - 0s - loss: 0.5993 - accuracy: 0.7200\n",
      "Epoch 110/150\n",
      "4/4 - 0s - loss: 0.5963 - accuracy: 0.7200\n",
      "Epoch 111/150\n",
      "4/4 - 0s - loss: 0.5936 - accuracy: 0.7200\n",
      "Epoch 112/150\n",
      "4/4 - 0s - loss: 0.5903 - accuracy: 0.7200\n",
      "Epoch 113/150\n",
      "4/4 - 0s - loss: 0.5876 - accuracy: 0.7100\n",
      "Epoch 114/150\n",
      "4/4 - 0s - loss: 0.5848 - accuracy: 0.7100\n",
      "Epoch 115/150\n",
      "4/4 - 0s - loss: 0.5817 - accuracy: 0.7100\n",
      "Epoch 116/150\n",
      "4/4 - 0s - loss: 0.5783 - accuracy: 0.7200\n",
      "Epoch 117/150\n",
      "4/4 - 0s - loss: 0.5753 - accuracy: 0.7700\n",
      "Epoch 118/150\n",
      "4/4 - 0s - loss: 0.5724 - accuracy: 0.8100\n",
      "Epoch 119/150\n",
      "4/4 - 0s - loss: 0.5705 - accuracy: 0.8700\n",
      "Epoch 120/150\n",
      "4/4 - 0s - loss: 0.5682 - accuracy: 0.9100\n",
      "Epoch 121/150\n",
      "4/4 - 0s - loss: 0.5652 - accuracy: 0.9200\n",
      "Epoch 122/150\n",
      "4/4 - 0s - loss: 0.5621 - accuracy: 0.9200\n",
      "Epoch 123/150\n",
      "4/4 - 0s - loss: 0.5593 - accuracy: 0.8700\n",
      "Epoch 124/150\n",
      "4/4 - 0s - loss: 0.5561 - accuracy: 0.8300\n",
      "Epoch 125/150\n",
      "4/4 - 0s - loss: 0.5532 - accuracy: 0.8100\n",
      "Epoch 126/150\n",
      "4/4 - 0s - loss: 0.5506 - accuracy: 0.8000\n",
      "Epoch 127/150\n",
      "4/4 - 0s - loss: 0.5482 - accuracy: 0.8100\n",
      "Epoch 128/150\n",
      "4/4 - 0s - loss: 0.5454 - accuracy: 0.8400\n",
      "Epoch 129/150\n",
      "4/4 - 0s - loss: 0.5428 - accuracy: 0.8700\n",
      "Epoch 130/150\n",
      "4/4 - 0s - loss: 0.5404 - accuracy: 0.8700\n",
      "Epoch 131/150\n",
      "4/4 - 0s - loss: 0.5378 - accuracy: 0.8700\n",
      "Epoch 132/150\n",
      "4/4 - 0s - loss: 0.5350 - accuracy: 0.8600\n",
      "Epoch 133/150\n",
      "4/4 - 0s - loss: 0.5323 - accuracy: 0.8600\n",
      "Epoch 134/150\n",
      "4/4 - 0s - loss: 0.5296 - accuracy: 0.8500\n",
      "Epoch 135/150\n",
      "4/4 - 0s - loss: 0.5271 - accuracy: 0.8600\n",
      "Epoch 136/150\n",
      "4/4 - 0s - loss: 0.5243 - accuracy: 0.8500\n",
      "Epoch 137/150\n",
      "4/4 - 0s - loss: 0.5217 - accuracy: 0.8300\n",
      "Epoch 138/150\n",
      "4/4 - 0s - loss: 0.5194 - accuracy: 0.8100\n",
      "Epoch 139/150\n",
      "4/4 - 0s - loss: 0.5168 - accuracy: 0.8000\n",
      "Epoch 140/150\n",
      "4/4 - 0s - loss: 0.5142 - accuracy: 0.8100\n",
      "Epoch 141/150\n",
      "4/4 - 0s - loss: 0.5117 - accuracy: 0.8300\n",
      "Epoch 142/150\n",
      "4/4 - 0s - loss: 0.5095 - accuracy: 0.8300\n",
      "Epoch 143/150\n",
      "4/4 - 0s - loss: 0.5069 - accuracy: 0.8700\n",
      "Epoch 144/150\n",
      "4/4 - 0s - loss: 0.5043 - accuracy: 0.8600\n",
      "Epoch 145/150\n",
      "4/4 - 0s - loss: 0.5019 - accuracy: 0.8400\n",
      "Epoch 146/150\n",
      "4/4 - 0s - loss: 0.4997 - accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150\n",
      "4/4 - 0s - loss: 0.4973 - accuracy: 0.8500\n",
      "Epoch 148/150\n",
      "4/4 - 0s - loss: 0.4947 - accuracy: 0.8500\n",
      "Epoch 149/150\n",
      "4/4 - 0s - loss: 0.4924 - accuracy: 0.8800\n",
      "Epoch 150/150\n",
      "4/4 - 0s - loss: 0.4903 - accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d1819b53c8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train,y_train,epochs=150, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 2, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 2, 0,\n",
       "       0, 1, 2, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict_classes(scaled_X_test) ------deprecated\n",
    "np.argmax(model.predict(scaled_X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0],\n",
       "       [ 0,  9,  6],\n",
       "       [ 0,  0, 16]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.argmax(axis=1),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.60      0.75        15\n",
      "           2       0.73      1.00      0.84        16\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.91      0.87      0.86        50\n",
      "weighted avg       0.91      0.88      0.87        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.argmax(axis=1),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('irismodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('irismodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x2d181012e48>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation with LSTM - using KEras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "        \n",
    "    return str_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file('C:/Users/khura/Documents/Ashish/Career related/Git/NLP/moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en',disable=['parser','tagger','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623\n",
    "# picked 1198623 from full text moby dick book for future scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25 + 1\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956,\n",
       " 14,\n",
       " 263,\n",
       " 51,\n",
       " 261,\n",
       " 408,\n",
       " 87,\n",
       " 219,\n",
       " 129,\n",
       " 111,\n",
       " 954,\n",
       " 260,\n",
       " 50,\n",
       " 43,\n",
       " 38,\n",
       " 315,\n",
       " 7,\n",
       " 23,\n",
       " 546,\n",
       " 3,\n",
       " 150,\n",
       " 259,\n",
       " 6,\n",
       " 2712,\n",
       " 14,\n",
       " 24]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'the',\n",
       " 2: 'a',\n",
       " 3: 'and',\n",
       " 4: 'of',\n",
       " 5: 'i',\n",
       " 6: 'to',\n",
       " 7: 'in',\n",
       " 8: 'it',\n",
       " 9: 'that',\n",
       " 10: 'he',\n",
       " 11: 'his',\n",
       " 12: 'was',\n",
       " 13: 'but',\n",
       " 14: 'me',\n",
       " 15: 'with',\n",
       " 16: 'as',\n",
       " 17: 'at',\n",
       " 18: 'this',\n",
       " 19: 'you',\n",
       " 20: 'is',\n",
       " 21: 'all',\n",
       " 22: 'for',\n",
       " 23: 'my',\n",
       " 24: 'on',\n",
       " 25: 'be',\n",
       " 26: \"'s\",\n",
       " 27: 'not',\n",
       " 28: 'from',\n",
       " 29: 'there',\n",
       " 30: 'one',\n",
       " 31: 'up',\n",
       " 32: 'what',\n",
       " 33: 'him',\n",
       " 34: 'so',\n",
       " 35: 'bed',\n",
       " 36: 'now',\n",
       " 37: 'about',\n",
       " 38: 'no',\n",
       " 39: 'into',\n",
       " 40: 'by',\n",
       " 41: 'were',\n",
       " 42: 'out',\n",
       " 43: 'or',\n",
       " 44: 'harpooneer',\n",
       " 45: 'had',\n",
       " 46: 'then',\n",
       " 47: 'have',\n",
       " 48: 'an',\n",
       " 49: 'upon',\n",
       " 50: 'little',\n",
       " 51: 'some',\n",
       " 52: 'old',\n",
       " 53: 'like',\n",
       " 54: 'if',\n",
       " 55: 'they',\n",
       " 56: 'would',\n",
       " 57: 'do',\n",
       " 58: 'over',\n",
       " 59: 'landlord',\n",
       " 60: 'thought',\n",
       " 61: 'room',\n",
       " 62: 'when',\n",
       " 63: 'could',\n",
       " 64: \"n't\",\n",
       " 65: 'night',\n",
       " 66: 'here',\n",
       " 67: 'head',\n",
       " 68: 'such',\n",
       " 69: 'which',\n",
       " 70: 'man',\n",
       " 71: 'did',\n",
       " 72: 'sea',\n",
       " 73: 'time',\n",
       " 74: 'other',\n",
       " 75: 'very',\n",
       " 76: 'go',\n",
       " 77: 'these',\n",
       " 78: 'more',\n",
       " 79: 'though',\n",
       " 80: 'first',\n",
       " 81: 'sort',\n",
       " 82: 'said',\n",
       " 83: 'last',\n",
       " 84: 'down',\n",
       " 85: 'most',\n",
       " 86: 'been',\n",
       " 87: 'never',\n",
       " 88: 'your',\n",
       " 89: 'them',\n",
       " 90: 'must',\n",
       " 91: 'tell',\n",
       " 92: 'much',\n",
       " 93: 'good',\n",
       " 94: 'see',\n",
       " 95: 'off',\n",
       " 96: 'myself',\n",
       " 97: 'are',\n",
       " 98: 'yet',\n",
       " 99: 'sleep',\n",
       " 100: 'who',\n",
       " 101: 'seemed',\n",
       " 102: 'light',\n",
       " 103: 'way',\n",
       " 104: 'their',\n",
       " 105: 'just',\n",
       " 106: 'being',\n",
       " 107: 'than',\n",
       " 108: 'place',\n",
       " 109: 'queequeg',\n",
       " 110: 'great',\n",
       " 111: 'long',\n",
       " 112: 'before',\n",
       " 113: 'get',\n",
       " 114: 'round',\n",
       " 115: 'where',\n",
       " 116: 'still',\n",
       " 117: 'any',\n",
       " 118: 'too',\n",
       " 119: 'only',\n",
       " 120: 'door',\n",
       " 121: 'can',\n",
       " 122: 'himself',\n",
       " 123: 'heads',\n",
       " 124: 'come',\n",
       " 125: 'ever',\n",
       " 126: 'two',\n",
       " 127: 'enough',\n",
       " 128: 'made',\n",
       " 129: 'how',\n",
       " 130: 'hand',\n",
       " 131: 'same',\n",
       " 132: 'looking',\n",
       " 133: 'something',\n",
       " 134: 'may',\n",
       " 135: \"'\",\n",
       " 136: 'almost',\n",
       " 137: 'say',\n",
       " 138: 'should',\n",
       " 139: 'side',\n",
       " 140: 'why',\n",
       " 141: 'own',\n",
       " 142: 'we',\n",
       " 143: 'new',\n",
       " 144: 'again',\n",
       " 145: 'came',\n",
       " 146: 'arm',\n",
       " 147: 'house',\n",
       " 148: 'away',\n",
       " 149: 'might',\n",
       " 150: 'nothing',\n",
       " 151: 'take',\n",
       " 152: 'towards',\n",
       " 153: 'will',\n",
       " 154: 'under',\n",
       " 155: 'going',\n",
       " 156: 'make',\n",
       " 157: 'whale',\n",
       " 158: 'stood',\n",
       " 159: 'boots',\n",
       " 160: 'ye',\n",
       " 161: 'back',\n",
       " 162: \"'ll\",\n",
       " 163: 'tomahawk',\n",
       " 164: 'part',\n",
       " 165: 'world',\n",
       " 166: 'soon',\n",
       " 167: 'water',\n",
       " 168: 'against',\n",
       " 169: 'those',\n",
       " 170: 'between',\n",
       " 171: 'after',\n",
       " 172: 'whaling',\n",
       " 173: 'lay',\n",
       " 174: 'took',\n",
       " 175: 'half',\n",
       " 176: 'began',\n",
       " 177: 'face',\n",
       " 178: 'streets',\n",
       " 179: 'land',\n",
       " 180: 'better',\n",
       " 181: 'once',\n",
       " 182: 'voyage',\n",
       " 183: 'give',\n",
       " 184: 'rather',\n",
       " 185: 'well',\n",
       " 186: 'however',\n",
       " 187: 'else',\n",
       " 188: 'heard',\n",
       " 189: 'put',\n",
       " 190: 'stop',\n",
       " 191: 'dark',\n",
       " 192: 'went',\n",
       " 193: 'black',\n",
       " 194: 'window',\n",
       " 195: 'cannibal',\n",
       " 196: 'fire',\n",
       " 197: 'every',\n",
       " 198: 'ship',\n",
       " 199: 'stand',\n",
       " 200: 'strange',\n",
       " 201: 'without',\n",
       " 202: 'feet',\n",
       " 203: 'whether',\n",
       " 204: 'because',\n",
       " 205: 'eyes',\n",
       " 206: 'think',\n",
       " 207: 'thinks',\n",
       " 208: 'idea',\n",
       " 209: 'bag',\n",
       " 210: 'nantucket',\n",
       " 211: 'late',\n",
       " 212: 'cold',\n",
       " 213: 'our',\n",
       " 214: 'found',\n",
       " 215: 'full',\n",
       " 216: 'morning',\n",
       " 217: 'sleeping',\n",
       " 218: 'got',\n",
       " 219: 'mind',\n",
       " 220: 'her',\n",
       " 221: 'right',\n",
       " 222: 'its',\n",
       " 223: 'look',\n",
       " 224: 'town',\n",
       " 225: 'south',\n",
       " 226: 'does',\n",
       " 227: 'let',\n",
       " 228: 'set',\n",
       " 229: 'yourself',\n",
       " 230: 'image',\n",
       " 231: 'saw',\n",
       " 232: 'am',\n",
       " 233: 'besides',\n",
       " 234: 'sailor',\n",
       " 235: 'seas',\n",
       " 236: 'rolled',\n",
       " 237: 'till',\n",
       " 238: 'day',\n",
       " 239: 'sign',\n",
       " 240: 'looked',\n",
       " 241: 'hard',\n",
       " 242: 'moment',\n",
       " 243: 'corner',\n",
       " 244: 'entry',\n",
       " 245: 'four',\n",
       " 246: 'wall',\n",
       " 247: 'savage',\n",
       " 248: 'table',\n",
       " 249: 'indeed',\n",
       " 250: 'bench',\n",
       " 251: 'chest',\n",
       " 252: 'while',\n",
       " 253: 'stranger',\n",
       " 254: 'possible',\n",
       " 255: 'feeling',\n",
       " 256: 'floor',\n",
       " 257: 'squares',\n",
       " 258: 'hat',\n",
       " 259: 'particular',\n",
       " 260: 'having',\n",
       " 261: 'years',\n",
       " 262: 'harpoon',\n",
       " 263: 'ishmael',\n",
       " 264: 'whenever',\n",
       " 265: 'mouth',\n",
       " 266: 'high',\n",
       " 267: 'knew',\n",
       " 268: 'men',\n",
       " 269: 'hours',\n",
       " 270: 'green',\n",
       " 271: 'bit',\n",
       " 272: 'within',\n",
       " 273: 'picture',\n",
       " 274: 'told',\n",
       " 275: 'story',\n",
       " 276: 'mean',\n",
       " 277: 'speak',\n",
       " 278: 'order',\n",
       " 279: 'making',\n",
       " 280: 'even',\n",
       " 281: 'perhaps',\n",
       " 282: 'things',\n",
       " 283: 'answer',\n",
       " 284: 'parts',\n",
       " 285: 'wild',\n",
       " 286: 'reason',\n",
       " 287: 'young',\n",
       " 288: 'craft',\n",
       " 289: 'business',\n",
       " 290: 'dead',\n",
       " 291: 'another',\n",
       " 292: 'middle',\n",
       " 293: 'sure',\n",
       " 294: 'candle',\n",
       " 295: 'presently',\n",
       " 296: 'low',\n",
       " 297: 'turned',\n",
       " 298: 'teeth',\n",
       " 299: 'dim',\n",
       " 300: 'euroclydon',\n",
       " 301: 'kept',\n",
       " 302: 'glass',\n",
       " 303: 'afterwards',\n",
       " 304: 'large',\n",
       " 305: 'three',\n",
       " 306: 'telling',\n",
       " 307: 'getting',\n",
       " 308: 'small',\n",
       " 309: 'next',\n",
       " 310: 'seeing',\n",
       " 311: 'sell',\n",
       " 312: 'felt',\n",
       " 313: 'sun',\n",
       " 314: 'e',\n",
       " 315: 'money',\n",
       " 316: 'sail',\n",
       " 317: 'coffin',\n",
       " 318: 'especially',\n",
       " 319: 'street',\n",
       " 320: 'city',\n",
       " 321: 'few',\n",
       " 322: 'previous',\n",
       " 323: 'sight',\n",
       " 324: 'days',\n",
       " 325: 'straight',\n",
       " 326: 'nigh',\n",
       " 327: 'legs',\n",
       " 328: 'try',\n",
       " 329: 'yes',\n",
       " 330: 'unless',\n",
       " 331: 'poor',\n",
       " 332: 'coat',\n",
       " 333: 'passenger',\n",
       " 334: 'taking',\n",
       " 335: 'true',\n",
       " 336: 'thing',\n",
       " 337: 'ai',\n",
       " 338: 'always',\n",
       " 339: 'us',\n",
       " 340: 'really',\n",
       " 341: 'marvellous',\n",
       " 342: 'heaven',\n",
       " 343: 'air',\n",
       " 344: 'far',\n",
       " 345: 'second',\n",
       " 346: 'many',\n",
       " 347: 'has',\n",
       " 348: 'unaccountable',\n",
       " 349: 'grand',\n",
       " 350: 'jolly',\n",
       " 351: 'open',\n",
       " 352: 'shirt',\n",
       " 353: 'cape',\n",
       " 354: 'bedford',\n",
       " 355: 'fine',\n",
       " 356: 'further',\n",
       " 357: 'ice',\n",
       " 358: 'frost',\n",
       " 359: 'foot',\n",
       " 360: 'wide',\n",
       " 361: 'white',\n",
       " 362: 'tall',\n",
       " 363: 'i.',\n",
       " 364: 'wooden',\n",
       " 365: 'worse',\n",
       " 366: 'death',\n",
       " 367: 'mine',\n",
       " 368: 'lazarus',\n",
       " 369: 'keep',\n",
       " 370: 'along',\n",
       " 371: 'hung',\n",
       " 372: 'throwing',\n",
       " 373: 'centre',\n",
       " 374: 'rest',\n",
       " 375: 'fact',\n",
       " 376: 'hair',\n",
       " 377: 'broken',\n",
       " 378: 'kill',\n",
       " 379: 'through',\n",
       " 380: 'chimney',\n",
       " 381: 'fancy',\n",
       " 382: 'bar',\n",
       " 383: 'trying',\n",
       " 384: 'dumplings',\n",
       " 385: 'heavens',\n",
       " 386: 'manner',\n",
       " 387: 'devil',\n",
       " 388: 'together',\n",
       " 389: 'seen',\n",
       " 390: 'deal',\n",
       " 391: 'know',\n",
       " 392: 'skin',\n",
       " 393: 'ca',\n",
       " 394: 'shavings',\n",
       " 395: 'peddling',\n",
       " 396: 'sunday',\n",
       " 397: 'counterpane',\n",
       " 398: 'mat',\n",
       " 399: 'christian',\n",
       " 400: 'commenced',\n",
       " 401: 'thinking',\n",
       " 402: 'similar',\n",
       " 403: 'afraid',\n",
       " 404: 'length',\n",
       " 405: 'idol',\n",
       " 406: 'sabbee',\n",
       " 407: 'waking',\n",
       " 408: 'ago',\n",
       " 409: 'find',\n",
       " 410: 'damp',\n",
       " 411: 'soul',\n",
       " 412: 'strong',\n",
       " 413: 'account',\n",
       " 414: 'sword',\n",
       " 415: 'quietly',\n",
       " 416: 'degree',\n",
       " 417: 'left',\n",
       " 418: 'around',\n",
       " 419: 'fixed',\n",
       " 420: 'ships',\n",
       " 421: 'miles',\n",
       " 422: 'country',\n",
       " 423: 'stream',\n",
       " 424: 'lead',\n",
       " 425: 'american',\n",
       " 426: 'artist',\n",
       " 427: 'each',\n",
       " 428: 'goes',\n",
       " 429: 'deep',\n",
       " 430: 'distant',\n",
       " 431: 'winds',\n",
       " 432: 'blue',\n",
       " 433: 'among',\n",
       " 434: 'suddenly',\n",
       " 435: 'feel',\n",
       " 436: 'meaning',\n",
       " 437: 'phantom',\n",
       " 438: 'life',\n",
       " 439: 'passengers',\n",
       " 440: 'nor',\n",
       " 441: 'kind',\n",
       " 442: 'quite',\n",
       " 443: 'care',\n",
       " 444: 'board',\n",
       " 445: 'somehow',\n",
       " 446: 'broiled',\n",
       " 447: 'mast',\n",
       " 448: 'sense',\n",
       " 449: 'knowing',\n",
       " 450: 'either',\n",
       " 451: 'passed',\n",
       " 452: 'hands',\n",
       " 453: 'paying',\n",
       " 454: 'pay',\n",
       " 455: 'penny',\n",
       " 456: 'sailors',\n",
       " 457: 'exactly',\n",
       " 458: 'short',\n",
       " 459: 'easy',\n",
       " 460: 'portentous',\n",
       " 461: 'island',\n",
       " 462: 'nameless',\n",
       " 463: 'sounds',\n",
       " 464: 'since',\n",
       " 465: 'snow',\n",
       " 466: 'saturday',\n",
       " 467: 'matter',\n",
       " 468: 'red',\n",
       " 469: 'partly',\n",
       " 470: 'ere',\n",
       " 471: 'became',\n",
       " 472: 'meanwhile',\n",
       " 473: 'pocket',\n",
       " 474: 'darkness',\n",
       " 475: 'fish',\n",
       " 476: 'inn',\n",
       " 477: 'watch',\n",
       " 478: 'broad',\n",
       " 479: 'entering',\n",
       " 480: 'ha',\n",
       " 481: 'ashes',\n",
       " 482: 'opened',\n",
       " 483: 'spouter',\n",
       " 484: 'name',\n",
       " 485: 'suppose',\n",
       " 486: 'quiet',\n",
       " 487: 'best',\n",
       " 488: 'tempestuous',\n",
       " 489: 'says',\n",
       " 490: 'thou',\n",
       " 491: 'both',\n",
       " 492: 'occurred',\n",
       " 493: 'dives',\n",
       " 494: 'holding',\n",
       " 495: 'frozen',\n",
       " 496: 'altogether',\n",
       " 497: 'plain',\n",
       " 498: 'whom',\n",
       " 499: 'clean',\n",
       " 500: 'human',\n",
       " 501: 'entered',\n",
       " 502: 'wrinkled',\n",
       " 503: 'shelf',\n",
       " 504: 'jonah',\n",
       " 505: 'blanket',\n",
       " 506: \"goin'\",\n",
       " 507: 'bitter',\n",
       " 508: 'supper',\n",
       " 509: 'sat',\n",
       " 510: 'settle',\n",
       " 511: 'chap',\n",
       " 512: 'help',\n",
       " 513: 'spend',\n",
       " 514: 'landed',\n",
       " 515: 'standing',\n",
       " 516: 'held',\n",
       " 517: 'somewhat',\n",
       " 518: 'sober',\n",
       " 519: 'whole',\n",
       " 520: 'dam',\n",
       " 521: 'brown',\n",
       " 522: 'bulkington',\n",
       " 523: \"o'clock\",\n",
       " 524: 'none',\n",
       " 525: 'coming',\n",
       " 526: \"'ve\",\n",
       " 527: 'wait',\n",
       " 528: 'plane',\n",
       " 529: 'saying',\n",
       " 530: 'grinning',\n",
       " 531: 'placed',\n",
       " 532: 'shouted',\n",
       " 533: 'bedfellow',\n",
       " 534: 'zealand',\n",
       " 535: 'sal',\n",
       " 536: 'wash',\n",
       " 537: 'thrown',\n",
       " 538: 'purplish',\n",
       " 539: 'turn',\n",
       " 540: 'completely',\n",
       " 541: 'fear',\n",
       " 542: 'grego',\n",
       " 543: 'baby',\n",
       " 544: 'slowly',\n",
       " 545: 'civilized',\n",
       " 546: 'purse',\n",
       " 547: 'monkey',\n",
       " 548: 'involuntarily',\n",
       " 549: 'pausing',\n",
       " 550: 'warehouses',\n",
       " 551: 'requires',\n",
       " 552: 'people',\n",
       " 553: 'nearly',\n",
       " 554: 'ocean',\n",
       " 555: 'indian',\n",
       " 556: 'waterward',\n",
       " 557: 'battery',\n",
       " 558: 'noble',\n",
       " 559: 'washed',\n",
       " 560: 'crowds',\n",
       " 561: 'sabbath',\n",
       " 562: 'afternoon',\n",
       " 563: 'thence',\n",
       " 564: 'silent',\n",
       " 565: 'thousands',\n",
       " 566: 'reveries',\n",
       " 567: 'leaning',\n",
       " 568: 'seated',\n",
       " 569: 'bulwarks',\n",
       " 570: 'aloft',\n",
       " 571: 'week',\n",
       " 572: 'plaster',\n",
       " 573: 'gone',\n",
       " 574: 'bound',\n",
       " 575: 'content',\n",
       " 576: 'yonder',\n",
       " 577: 'falling',\n",
       " 578: 'north',\n",
       " 579: 'please',\n",
       " 580: 'ten',\n",
       " 581: 'leaves',\n",
       " 582: 'magic',\n",
       " 583: 'plunged',\n",
       " 584: 'metaphysical',\n",
       " 585: 'chief',\n",
       " 586: 'trunk',\n",
       " 587: 'meadow',\n",
       " 588: 'smoke',\n",
       " 589: 'reaching',\n",
       " 590: 'hill',\n",
       " 591: 'thus',\n",
       " 592: 'pine',\n",
       " 593: 'sighs',\n",
       " 594: 'shepherd',\n",
       " 595: 'june',\n",
       " 596: 'scores',\n",
       " 597: 'thousand',\n",
       " 598: 'sadly',\n",
       " 599: 'robust',\n",
       " 600: 'healthy',\n",
       " 601: 'boy',\n",
       " 602: 'crazy',\n",
       " 603: 'hold',\n",
       " 604: 'holy',\n",
       " 605: 'brother',\n",
       " 606: 'ourselves',\n",
       " 607: 'begin',\n",
       " 608: 'grow',\n",
       " 609: 'inferred',\n",
       " 610: 'needs',\n",
       " 611: \"don't\",\n",
       " 612: 'themselves',\n",
       " 613: 'commodore',\n",
       " 614: 'captain',\n",
       " 615: 'cook',\n",
       " 616: 'glory',\n",
       " 617: 'whatsoever',\n",
       " 618: 'confess',\n",
       " 619: 'officer',\n",
       " 620: 'respectfully',\n",
       " 621: 'horse',\n",
       " 622: 'huge',\n",
       " 623: 'houses',\n",
       " 624: 'forecastle',\n",
       " 625: 'jump',\n",
       " 626: 'spar',\n",
       " 627: 'particularly',\n",
       " 628: 'putting',\n",
       " 629: 'tar',\n",
       " 630: 'schoolmaster',\n",
       " 631: 'boys',\n",
       " 632: 'transition',\n",
       " 633: 'grin',\n",
       " 634: 'bear',\n",
       " 635: 'hunks',\n",
       " 636: 'sweep',\n",
       " 637: 'weighed',\n",
       " 638: 'anything',\n",
       " 639: 'less',\n",
       " 640: 'thump',\n",
       " 641: 'point',\n",
       " 642: 'view',\n",
       " 643: 'single',\n",
       " 644: 'difference',\n",
       " 645: 'act',\n",
       " 646: 'uncomfortable',\n",
       " 647: 'compare',\n",
       " 648: 'earthly',\n",
       " 649: 'enter',\n",
       " 650: 'deck',\n",
       " 651: 'quarter',\n",
       " 652: 'leaders',\n",
       " 653: 'smelt',\n",
       " 654: 'fates',\n",
       " 655: 'doubtless',\n",
       " 656: 'formed',\n",
       " 657: 'run',\n",
       " 658: 'stage',\n",
       " 659: 'shabby',\n",
       " 660: 'others',\n",
       " 661: 'circumstances',\n",
       " 662: 'motives',\n",
       " 663: 'various',\n",
       " 664: 'mysterious',\n",
       " 665: 'curiosity',\n",
       " 666: 'tormented',\n",
       " 667: 'everlasting',\n",
       " 668: 'wonder',\n",
       " 669: 'purpose',\n",
       " 670: 'floated',\n",
       " 671: 'stuffed',\n",
       " 672: 'horn',\n",
       " 673: 'arrived',\n",
       " 674: 'offer',\n",
       " 675: 'following',\n",
       " 676: 'embark',\n",
       " 677: 'pleased',\n",
       " 678: 'original',\n",
       " 679: 'stranded',\n",
       " 680: 'leviathan',\n",
       " 681: 'whales',\n",
       " 682: 'nay',\n",
       " 683: 'dismal',\n",
       " 684: 'wherever',\n",
       " 685: 'dreary',\n",
       " 686: 'crossed',\n",
       " 687: 'expensive',\n",
       " 688: 'bright',\n",
       " 689: 'windows',\n",
       " 690: 'packed',\n",
       " 691: 'inches',\n",
       " 692: 'thick',\n",
       " 693: 'hear',\n",
       " 694: 'tinkling',\n",
       " 695: 'glasses',\n",
       " 696: 'blackness',\n",
       " 697: 'moving',\n",
       " 698: 'hour',\n",
       " 699: 'proved',\n",
       " 700: 'meant',\n",
       " 701: 'public',\n",
       " 702: 'box',\n",
       " 703: 'flying',\n",
       " 704: 'harpoons',\n",
       " 705: 'trap',\n",
       " 706: 'loud',\n",
       " 707: 'voice',\n",
       " 708: 'sitting',\n",
       " 709: 'beyond',\n",
       " 710: 'negro',\n",
       " 711: 'creaking',\n",
       " 712: 'swinging',\n",
       " 713: 'painting',\n",
       " 714: 'representing',\n",
       " 715: 'connexion',\n",
       " 716: 'peter',\n",
       " 717: 'itself',\n",
       " 718: 'carted',\n",
       " 719: 'burnt',\n",
       " 720: 'spot',\n",
       " 721: 'queer',\n",
       " 722: 'gable',\n",
       " 723: 'ended',\n",
       " 724: 'sharp',\n",
       " 725: 'wind',\n",
       " 726: 'howling',\n",
       " 727: 'nevertheless',\n",
       " 728: 'called',\n",
       " 729: 'outside',\n",
       " 730: 'passage',\n",
       " 731: 'body',\n",
       " 732: 'curbstone',\n",
       " 733: 'corn',\n",
       " 734: 'pooh',\n",
       " 735: 'northern',\n",
       " 736: 'lights',\n",
       " 737: 'summer',\n",
       " 738: 'lengthwise',\n",
       " 739: 'gods',\n",
       " 740: 'lie',\n",
       " 741: 'plenty',\n",
       " 742: 'study',\n",
       " 743: 'series',\n",
       " 744: 'arrive',\n",
       " 745: 'shadows',\n",
       " 746: 'dint',\n",
       " 747: 'conclusion',\n",
       " 748: 'confounded',\n",
       " 749: 'limber',\n",
       " 750: 'truly',\n",
       " 751: 'drive',\n",
       " 752: 'unimaginable',\n",
       " 753: 'midnight',\n",
       " 754: 'unnatural',\n",
       " 755: 'breaking',\n",
       " 756: 'design',\n",
       " 757: 'opposite',\n",
       " 758: 'monstrous',\n",
       " 759: 'knots',\n",
       " 760: 'vast',\n",
       " 761: 'handle',\n",
       " 762: 'wondered',\n",
       " 763: 'mixed',\n",
       " 764: 'deformed',\n",
       " 765: 'flung',\n",
       " 766: 'iron',\n",
       " 767: 'arched',\n",
       " 768: 'cut',\n",
       " 769: 'times',\n",
       " 770: 'beneath',\n",
       " 771: 'covered',\n",
       " 772: 'gathered',\n",
       " 773: 'stands',\n",
       " 774: 'rude',\n",
       " 775: 'bone',\n",
       " 776: 'abominable',\n",
       " 777: 'measure',\n",
       " 778: 'seamen',\n",
       " 779: 'skrimshander',\n",
       " 780: 'sought',\n",
       " 781: 'added',\n",
       " 782: 'forehead',\n",
       " 783: 'objections',\n",
       " 784: \"'d\",\n",
       " 785: 'used',\n",
       " 786: 'depend',\n",
       " 787: 'decent',\n",
       " 788: 'want',\n",
       " 789: 'ready',\n",
       " 790: 'working',\n",
       " 791: 'space',\n",
       " 792: 'lips',\n",
       " 793: 'fingers',\n",
       " 794: 'fare',\n",
       " 795: 'fellow',\n",
       " 796: 'nightmare',\n",
       " 797: 'nt',\n",
       " 798: 'complexioned',\n",
       " 799: 'eats',\n",
       " 800: \"'em\",\n",
       " 801: 'afore',\n",
       " 802: 'resolved',\n",
       " 803: 'noise',\n",
       " 804: 'offing',\n",
       " 805: 'shaggy',\n",
       " 806: 'woollen',\n",
       " 807: 'stiff',\n",
       " 808: 'labrador',\n",
       " 809: 'wake',\n",
       " 810: 'bad',\n",
       " 811: 'mounted',\n",
       " 812: 'generally',\n",
       " 813: 'shipmates',\n",
       " 814: 'become',\n",
       " 815: 'height',\n",
       " 816: 'seem',\n",
       " 817: 'plan',\n",
       " 818: 'private',\n",
       " 819: 'unknown',\n",
       " 820: 'apartment',\n",
       " 821: 'hammock',\n",
       " 822: 'linen',\n",
       " 823: 'home',\n",
       " 824: 'hole',\n",
       " 825: 'mattress',\n",
       " 826: 'planing',\n",
       " 827: 'knot',\n",
       " 828: 'near',\n",
       " 829: 'sake',\n",
       " 830: 'chair',\n",
       " 831: 'narrow',\n",
       " 832: 'leaving',\n",
       " 833: 'interval',\n",
       " 834: 'met',\n",
       " 835: 'inside',\n",
       " 836: 'violent',\n",
       " 837: 'ones',\n",
       " 838: 'comprehension',\n",
       " 839: 'bird',\n",
       " 840: 'airley',\n",
       " 841: 'airth',\n",
       " 842: 'engaged',\n",
       " 843: 'whittling',\n",
       " 844: 'guess',\n",
       " 845: 'done',\n",
       " 846: 'break',\n",
       " 847: 'broke',\n",
       " 848: 'understand',\n",
       " 849: 'certain',\n",
       " 850: 'demand',\n",
       " 851: 'selling',\n",
       " 852: 'sir',\n",
       " 853: 'string',\n",
       " 854: 'mystery',\n",
       " 855: 'showed',\n",
       " 856: 'dangerous',\n",
       " 857: 'flukes',\n",
       " 858: 'slept',\n",
       " 859: 'big',\n",
       " 860: 'sam',\n",
       " 861: 'lighted',\n",
       " 862: 'wo',\n",
       " 863: 'stairs',\n",
       " 864: 'placing',\n",
       " 865: 'double',\n",
       " 866: 'eyeing',\n",
       " 867: 'belonging',\n",
       " 868: 'papered',\n",
       " 869: 'parcel',\n",
       " 870: 'tried',\n",
       " 871: 'satisfactory',\n",
       " 872: 'concerning',\n",
       " 873: 'edges',\n",
       " 874: 'stuck',\n",
       " 875: 'gave',\n",
       " 876: 'neck',\n",
       " 877: 'sleeves',\n",
       " 878: 'undressed',\n",
       " 879: 'remembering',\n",
       " 880: 'jumped',\n",
       " 881: 'pantaloons',\n",
       " 882: 'blowing',\n",
       " 883: 'doze',\n",
       " 884: 'pretty',\n",
       " 885: 'heavy',\n",
       " 886: 'save',\n",
       " 887: 'infernal',\n",
       " 888: 'peddler',\n",
       " 889: 'yellow',\n",
       " 890: 'colour',\n",
       " 891: 'dreadfully',\n",
       " 892: 'sticking',\n",
       " 893: 'cheeks',\n",
       " 894: 'truth',\n",
       " 895: 'remembered',\n",
       " 896: 'whaleman',\n",
       " 897: 'tattooed',\n",
       " 898: 'concluded',\n",
       " 899: 'lying',\n",
       " 900: 'tanning',\n",
       " 901: 'hot',\n",
       " 902: 'produced',\n",
       " 903: 'beaver',\n",
       " 904: 'singing',\n",
       " 905: 'bolted',\n",
       " 906: 'arms',\n",
       " 907: 'running',\n",
       " 908: 'curious',\n",
       " 909: 'hunch',\n",
       " 910: 'congo',\n",
       " 911: 'ill',\n",
       " 912: 'takes',\n",
       " 913: 'biscuit',\n",
       " 914: 'top',\n",
       " 915: 'lamp',\n",
       " 916: 'succeeded',\n",
       " 917: 'polite',\n",
       " 918: 'guttural',\n",
       " 919: 'pagan',\n",
       " 920: 'spell',\n",
       " 921: 'tobacco',\n",
       " 922: 'grunt',\n",
       " 923: 'whatever',\n",
       " 924: 'ee',\n",
       " 925: 'horrid',\n",
       " 926: 'pipe',\n",
       " 927: 'smoking',\n",
       " 928: 'complied',\n",
       " 929: 'patchwork',\n",
       " 930: 'figure',\n",
       " 931: 'shade',\n",
       " 932: 'quilt',\n",
       " 933: 'hugging',\n",
       " 934: 'sensations',\n",
       " 935: 'explain',\n",
       " 936: 'remember',\n",
       " 937: 'circumstance',\n",
       " 938: 'reality',\n",
       " 939: 'stepmother',\n",
       " 940: 'sixteen',\n",
       " 941: 'abed',\n",
       " 942: 'troubled',\n",
       " 943: 'supernatural',\n",
       " 944: 'ages',\n",
       " 945: 'awful',\n",
       " 946: 'consciousness',\n",
       " 947: 'observing',\n",
       " 948: 'creature',\n",
       " 949: 'dress',\n",
       " 950: 'watching',\n",
       " 951: 'probably',\n",
       " 952: 'toilet',\n",
       " 953: 'wrapped',\n",
       " 954: 'precisely',\n",
       " 955: 'jacket',\n",
       " 956: 'call',\n",
       " 957: 'shore',\n",
       " 958: 'watery',\n",
       " 959: 'driving',\n",
       " 960: 'spleen',\n",
       " 961: 'regulating',\n",
       " 962: 'circulation',\n",
       " 963: 'growing',\n",
       " 964: 'grim',\n",
       " 965: 'drizzly',\n",
       " 966: 'november',\n",
       " 967: 'bringing',\n",
       " 968: 'rear',\n",
       " 969: 'funeral',\n",
       " 970: 'meet',\n",
       " 971: 'hypos',\n",
       " 972: 'upper',\n",
       " 973: 'moral',\n",
       " 974: 'principle',\n",
       " 975: 'prevent',\n",
       " 976: 'deliberately',\n",
       " 977: 'stepping',\n",
       " 978: 'methodically',\n",
       " 979: 'knocking',\n",
       " 980: 'hats',\n",
       " 981: 'substitute',\n",
       " 982: 'pistol',\n",
       " 983: 'ball',\n",
       " 984: 'philosophical',\n",
       " 985: 'flourish',\n",
       " 986: 'cato',\n",
       " 987: 'throws',\n",
       " 988: 'surprising',\n",
       " 989: 'cherish',\n",
       " 990: 'feelings',\n",
       " 991: 'insular',\n",
       " 992: 'manhattoes',\n",
       " 993: 'belted',\n",
       " 994: 'wharves',\n",
       " 995: 'isles',\n",
       " 996: 'coral',\n",
       " 997: 'reefs',\n",
       " 998: 'commerce',\n",
       " 999: 'surrounds',\n",
       " 1000: 'surf',\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956 : call\n",
      "14 : me\n",
      "263 : ishmael\n",
      "51 : some\n",
      "261 : years\n",
      "408 : ago\n",
      "87 : never\n",
      "219 : mind\n",
      "129 : how\n",
      "111 : long\n",
      "954 : precisely\n",
      "260 : having\n",
      "50 : little\n",
      "43 : or\n",
      "38 : no\n",
      "315 : money\n",
      "7 : in\n",
      "23 : my\n",
      "546 : purse\n",
      "3 : and\n",
      "150 : nothing\n",
      "259 : particular\n",
      "6 : to\n",
      "2712 : interest\n",
      "14 : me\n",
      "24 : on\n"
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "    print(f\"{i} : {tokenizer.index_word[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('call', 27),\n",
       "             ('me', 2471),\n",
       "             ('ishmael', 133),\n",
       "             ('some', 758),\n",
       "             ('years', 135),\n",
       "             ('ago', 84),\n",
       "             ('never', 449),\n",
       "             ('mind', 164),\n",
       "             ('how', 321),\n",
       "             ('long', 374),\n",
       "             ('precisely', 37),\n",
       "             ('having', 142),\n",
       "             ('little', 767),\n",
       "             ('or', 950),\n",
       "             ('no', 1003),\n",
       "             ('money', 120),\n",
       "             ('in', 5647),\n",
       "             ('my', 1786),\n",
       "             ('purse', 71),\n",
       "             ('and', 9646),\n",
       "             ('nothing', 281),\n",
       "             ('particular', 152),\n",
       "             ('to', 6497),\n",
       "             ('interest', 24),\n",
       "             ('on', 1716),\n",
       "             ('shore', 26),\n",
       "             ('i', 7150),\n",
       "             ('thought', 676),\n",
       "             ('would', 702),\n",
       "             ('sail', 104),\n",
       "             ('about', 1014),\n",
       "             ('a', 10377),\n",
       "             ('see', 416),\n",
       "             ('the', 15540),\n",
       "             ('watery', 26),\n",
       "             ('part', 234),\n",
       "             ('of', 8287),\n",
       "             ('world', 234),\n",
       "             ('it', 4238),\n",
       "             ('is', 1950),\n",
       "             ('way', 390),\n",
       "             ('have', 806),\n",
       "             ('driving', 26),\n",
       "             ('off', 416),\n",
       "             ('spleen', 26),\n",
       "             ('regulating', 26),\n",
       "             ('circulation', 26),\n",
       "             ('whenever', 130),\n",
       "             ('find', 78),\n",
       "             ('myself', 416),\n",
       "             ('growing', 26),\n",
       "             ('grim', 26),\n",
       "             ('mouth', 130),\n",
       "             ('damp', 78),\n",
       "             ('drizzly', 26),\n",
       "             ('november', 26),\n",
       "             ('soul', 78),\n",
       "             ('involuntarily', 52),\n",
       "             ('pausing', 52),\n",
       "             ('before', 364),\n",
       "             ('coffin', 104),\n",
       "             ('warehouses', 52),\n",
       "             ('bringing', 26),\n",
       "             ('up', 1237),\n",
       "             ('rear', 26),\n",
       "             ('every', 182),\n",
       "             ('funeral', 26),\n",
       "             ('meet', 26),\n",
       "             ('especially', 104),\n",
       "             ('hypos', 26),\n",
       "             ('get', 364),\n",
       "             ('such', 572),\n",
       "             ('an', 806),\n",
       "             ('upper', 26),\n",
       "             ('hand', 312),\n",
       "             ('that', 3770),\n",
       "             ('requires', 52),\n",
       "             ('strong', 78),\n",
       "             ('moral', 26),\n",
       "             ('principle', 26),\n",
       "             ('prevent', 26),\n",
       "             ('from', 1508),\n",
       "             ('deliberately', 26),\n",
       "             ('stepping', 26),\n",
       "             ('into', 988),\n",
       "             ('street', 104),\n",
       "             ('methodically', 26),\n",
       "             ('knocking', 26),\n",
       "             ('people', 52),\n",
       "             (\"'s\", 1691),\n",
       "             ('hats', 26),\n",
       "             ('then', 832),\n",
       "             ('account', 78),\n",
       "             ('high', 130),\n",
       "             ('time', 520),\n",
       "             ('sea', 546),\n",
       "             ('as', 2366),\n",
       "             ('soon', 234),\n",
       "             ('can', 338),\n",
       "             ('this', 2158),\n",
       "             ('substitute', 26),\n",
       "             ('for', 1820),\n",
       "             ('pistol', 26),\n",
       "             ('ball', 26),\n",
       "             ('with', 2392),\n",
       "             ('philosophical', 26),\n",
       "             ('flourish', 26),\n",
       "             ('cato', 26),\n",
       "             ('throws', 26),\n",
       "             ('himself', 338),\n",
       "             ('upon', 780),\n",
       "             ('his', 3139),\n",
       "             ('sword', 78),\n",
       "             ('quietly', 78),\n",
       "             ('take', 260),\n",
       "             ('ship', 182),\n",
       "             ('there', 1456),\n",
       "             ('surprising', 26),\n",
       "             ('if', 728),\n",
       "             ('they', 728),\n",
       "             ('but', 2652),\n",
       "             ('knew', 130),\n",
       "             ('almost', 286),\n",
       "             ('all', 1872),\n",
       "             ('men', 130),\n",
       "             ('their', 390),\n",
       "             ('degree', 78),\n",
       "             ('other', 494),\n",
       "             ('cherish', 26),\n",
       "             ('very', 494),\n",
       "             ('nearly', 52),\n",
       "             ('same', 312),\n",
       "             ('feelings', 26),\n",
       "             ('towards', 260),\n",
       "             ('ocean', 52),\n",
       "             ('now', 1040),\n",
       "             ('your', 442),\n",
       "             ('insular', 26),\n",
       "             ('city', 104),\n",
       "             ('manhattoes', 26),\n",
       "             ('belted', 26),\n",
       "             ('round', 364),\n",
       "             ('by', 962),\n",
       "             ('wharves', 26),\n",
       "             ('indian', 52),\n",
       "             ('isles', 26),\n",
       "             ('coral', 26),\n",
       "             ('reefs', 26),\n",
       "             ('commerce', 26),\n",
       "             ('surrounds', 26),\n",
       "             ('her', 156),\n",
       "             ('surf', 26),\n",
       "             ('right', 156),\n",
       "             ('left', 78),\n",
       "             ('streets', 208),\n",
       "             ('you', 2158),\n",
       "             ('waterward', 52),\n",
       "             ('its', 156),\n",
       "             ('extreme', 26),\n",
       "             ('downtown', 26),\n",
       "             ('battery', 52),\n",
       "             ('where', 364),\n",
       "             ('noble', 52),\n",
       "             ('mole', 26),\n",
       "             ('washed', 52),\n",
       "             ('waves', 26),\n",
       "             ('cooled', 26),\n",
       "             ('breezes', 26),\n",
       "             ('which', 572),\n",
       "             ('few', 104),\n",
       "             ('hours', 130),\n",
       "             ('previous', 104),\n",
       "             ('were', 962),\n",
       "             ('out', 956),\n",
       "             ('sight', 104),\n",
       "             ('land', 208),\n",
       "             ('look', 156),\n",
       "             ('at', 2184),\n",
       "             ('crowds', 52),\n",
       "             ('water', 234),\n",
       "             ('gazers', 26),\n",
       "             ('circumambulate', 26),\n",
       "             ('dreamy', 26),\n",
       "             ('sabbath', 52),\n",
       "             ('afternoon', 52),\n",
       "             ('go', 494),\n",
       "             ('corlears', 26),\n",
       "             ('hook', 26),\n",
       "             ('coenties', 26),\n",
       "             ('slip', 26),\n",
       "             ('thence', 52),\n",
       "             ('whitehall', 26),\n",
       "             ('northward', 26),\n",
       "             ('what', 1118),\n",
       "             ('do', 702),\n",
       "             ('see?--posted', 26),\n",
       "             ('like', 732),\n",
       "             ('silent', 52),\n",
       "             ('sentinels', 26),\n",
       "             ('around', 78),\n",
       "             ('town', 156),\n",
       "             ('stand', 182),\n",
       "             ('thousands', 52),\n",
       "             ('mortal', 26),\n",
       "             ('fixed', 78),\n",
       "             ('reveries', 52),\n",
       "             ('leaning', 52),\n",
       "             ('against', 234),\n",
       "             ('spiles', 26),\n",
       "             ('seated', 52),\n",
       "             ('pier', 26),\n",
       "             ('heads', 338),\n",
       "             ('looking', 312),\n",
       "             ('over', 702),\n",
       "             ('bulwarks', 52),\n",
       "             ('ships', 78),\n",
       "             ('china', 26),\n",
       "             ('aloft', 52),\n",
       "             ('rigging', 26),\n",
       "             ('striving', 26),\n",
       "             ('still', 364),\n",
       "             ('better', 208),\n",
       "             ('seaward', 26),\n",
       "             ('peep', 26),\n",
       "             ('these', 494),\n",
       "             ('are', 416),\n",
       "             ('landsmen', 26),\n",
       "             ('week', 52),\n",
       "             ('days', 104),\n",
       "             ('pent', 26),\n",
       "             ('lath', 26),\n",
       "             ('plaster', 52),\n",
       "             ('tied', 26),\n",
       "             ('counters', 26),\n",
       "             ('nailed', 26),\n",
       "             ('benches', 26),\n",
       "             ('clinched', 26),\n",
       "             ('desks', 26),\n",
       "             ('green', 130),\n",
       "             ('fields', 26),\n",
       "             ('gone', 52),\n",
       "             ('here', 598),\n",
       "             ('come', 338),\n",
       "             ('more', 494),\n",
       "             ('pacing', 26),\n",
       "             ('straight', 104),\n",
       "             ('seemingly', 26),\n",
       "             ('bound', 52),\n",
       "             ('dive', 26),\n",
       "             ('strange', 182),\n",
       "             ('will', 260),\n",
       "             ('content', 52),\n",
       "             ('them', 442),\n",
       "             ('extremest', 26),\n",
       "             ('limit', 26),\n",
       "             ('loitering', 26),\n",
       "             ('under', 260),\n",
       "             ('shady', 26),\n",
       "             ('lee', 26),\n",
       "             ('yonder', 52),\n",
       "             ('not', 1534),\n",
       "             ('suffice', 26),\n",
       "             ('must', 442),\n",
       "             ('just', 390),\n",
       "             ('nigh', 104),\n",
       "             ('possibly', 26),\n",
       "             ('without', 182),\n",
       "             ('falling', 52),\n",
       "             ('miles', 78),\n",
       "             ('leagues', 26),\n",
       "             ('inlanders', 26),\n",
       "             ('lanes', 26),\n",
       "             ('alleys', 26),\n",
       "             ('avenues', 26),\n",
       "             ('north', 52),\n",
       "             ('east', 26),\n",
       "             ('south', 156),\n",
       "             ('west', 26),\n",
       "             ('yet', 416),\n",
       "             ('unite', 26),\n",
       "             ('tell', 442),\n",
       "             ('does', 156),\n",
       "             ('magnetic', 26),\n",
       "             ('virtue', 26),\n",
       "             ('needles', 26),\n",
       "             ('compasses', 26),\n",
       "             ('those', 234),\n",
       "             ('attract', 26),\n",
       "             ('thither', 26),\n",
       "             ('once', 208),\n",
       "             ('say', 286),\n",
       "             ('country', 78),\n",
       "             ('lakes', 26),\n",
       "             ('any', 364),\n",
       "             ('path', 26),\n",
       "             ('please', 52),\n",
       "             ('ten', 52),\n",
       "             ('one', 1300),\n",
       "             ('carries', 26),\n",
       "             ('down', 468),\n",
       "             ('dale', 26),\n",
       "             ('leaves', 52),\n",
       "             ('pool', 26),\n",
       "             ('stream', 78),\n",
       "             ('magic', 52),\n",
       "             ('let', 156),\n",
       "             ('most', 468),\n",
       "             ('absent', 26),\n",
       "             ('minded', 26),\n",
       "             ('be', 1716),\n",
       "             ('plunged', 52),\n",
       "             ('deepest', 26),\n",
       "             ('man', 572),\n",
       "             ('legs', 104),\n",
       "             ('set', 156),\n",
       "             ('feet', 182),\n",
       "             ('going', 260),\n",
       "             ('he', 3247),\n",
       "             ('infallibly', 26),\n",
       "             ('lead', 78),\n",
       "             ('region', 26),\n",
       "             ('should', 286),\n",
       "             ('ever', 338),\n",
       "             ('athirst', 26),\n",
       "             ('great', 376),\n",
       "             ('american', 78),\n",
       "             ('desert', 26),\n",
       "             ('try', 104),\n",
       "             ('experiment', 26),\n",
       "             ('caravan', 26),\n",
       "             ('happen', 26),\n",
       "             ('supplied', 26),\n",
       "             ('metaphysical', 52),\n",
       "             ('professor', 26),\n",
       "             ('yes', 104),\n",
       "             ('knows', 26),\n",
       "             ('meditation', 26),\n",
       "             ('wedded', 26),\n",
       "             ('artist', 78),\n",
       "             ('desires', 26),\n",
       "             ('paint', 26),\n",
       "             ('dreamiest', 26),\n",
       "             ('shadiest', 26),\n",
       "             ('quietest', 26),\n",
       "             ('enchanting', 26),\n",
       "             ('bit', 130),\n",
       "             ('romantic', 26),\n",
       "             ('landscape', 26),\n",
       "             ('valley', 26),\n",
       "             ('saco', 26),\n",
       "             ('chief', 52),\n",
       "             ('element', 26),\n",
       "             ('employs', 26),\n",
       "             ('trees', 26),\n",
       "             ('each', 78),\n",
       "             ('hollow', 26),\n",
       "             ('trunk', 52),\n",
       "             ('hermit', 26),\n",
       "             ('crucifix', 26),\n",
       "             ('within', 130),\n",
       "             ('sleeps', 26),\n",
       "             ('meadow', 52),\n",
       "             ('sleep', 416),\n",
       "             ('cattle', 26),\n",
       "             ('cottage', 26),\n",
       "             ('goes', 78),\n",
       "             ('sleepy', 26),\n",
       "             ('smoke', 52),\n",
       "             ('deep', 78),\n",
       "             ('distant', 78),\n",
       "             ('woodlands', 26),\n",
       "             ('winds', 78),\n",
       "             ('mazy', 26),\n",
       "             ('reaching', 52),\n",
       "             ('overlapping', 26),\n",
       "             ('spurs', 26),\n",
       "             ('mountains', 26),\n",
       "             ('bathed', 26),\n",
       "             ('hill', 52),\n",
       "             ('side', 286),\n",
       "             ('blue', 78),\n",
       "             ('though', 494),\n",
       "             ('picture', 130),\n",
       "             ('lies', 26),\n",
       "             ('thus', 52),\n",
       "             ('tranced', 26),\n",
       "             ('pine', 52),\n",
       "             ('tree', 26),\n",
       "             ('shakes', 26),\n",
       "             ('sighs', 52),\n",
       "             ('shepherd', 52),\n",
       "             ('head', 598),\n",
       "             ('vain', 26),\n",
       "             ('unless', 104),\n",
       "             ('eye', 26),\n",
       "             ('him', 1092),\n",
       "             ('visit', 26),\n",
       "             ('prairies', 26),\n",
       "             ('june', 52),\n",
       "             ('when', 650),\n",
       "             ('scores', 52),\n",
       "             ('wade', 26),\n",
       "             ('knee', 26),\n",
       "             ('among', 78),\n",
       "             ('tiger', 26),\n",
       "             ('lilies', 26),\n",
       "             ('charm', 26),\n",
       "             ('wanting?--water', 26),\n",
       "             ('drop', 26),\n",
       "             ('niagara', 26),\n",
       "             ('cataract', 26),\n",
       "             ('sand', 26),\n",
       "             ('travel', 26),\n",
       "             ('thousand', 52),\n",
       "             ('why', 286),\n",
       "             ('did', 572),\n",
       "             ('poor', 104),\n",
       "             ('poet', 26),\n",
       "             ('tennessee', 26),\n",
       "             ('suddenly', 78),\n",
       "             ('receiving', 26),\n",
       "             ('two', 338),\n",
       "             ('handfuls', 26),\n",
       "             ('silver', 26),\n",
       "             ('deliberate', 26),\n",
       "             ('whether', 182),\n",
       "             ('buy', 26),\n",
       "             ('coat', 104),\n",
       "             ('sadly', 52),\n",
       "             ('needed', 26),\n",
       "             ('invest', 26),\n",
       "             ('pedestrian', 26),\n",
       "             ('trip', 26),\n",
       "             ('rockaway', 26),\n",
       "             ('beach', 26),\n",
       "             ('robust', 52),\n",
       "             ('healthy', 52),\n",
       "             ('boy', 52),\n",
       "             ('crazy', 52),\n",
       "             ('first', 494),\n",
       "             ('voyage', 208),\n",
       "             ('passenger', 104),\n",
       "             ('yourself', 156),\n",
       "             ('feel', 78),\n",
       "             ('mystical', 26),\n",
       "             ('vibration', 26),\n",
       "             ('told', 130),\n",
       "             ('old', 754),\n",
       "             ('persians', 26),\n",
       "             ('hold', 52),\n",
       "             ('holy', 52),\n",
       "             ('greeks', 26),\n",
       "             ('give', 208),\n",
       "             ('separate', 26),\n",
       "             ('deity', 26),\n",
       "             ('own', 286),\n",
       "             ('brother', 52),\n",
       "             ('jove', 26),\n",
       "             ('surely', 26),\n",
       "             ('meaning', 78),\n",
       "             ('deeper', 26),\n",
       "             ('story', 130),\n",
       "             ('narcissus', 26),\n",
       "             ('who', 416),\n",
       "             ('because', 182),\n",
       "             ('could', 650),\n",
       "             ('grasp', 26),\n",
       "             ('tormenting', 26),\n",
       "             ('mild', 26),\n",
       "             ('image', 156),\n",
       "             ('saw', 156),\n",
       "             ('fountain', 26),\n",
       "             ('was', 2886),\n",
       "             ('drowned', 26),\n",
       "             ('we', 286),\n",
       "             ('ourselves', 52),\n",
       "             ('rivers', 26),\n",
       "             ('oceans', 26),\n",
       "             ('ungraspable', 26),\n",
       "             ('phantom', 78),\n",
       "             ('life', 78),\n",
       "             ('key', 26),\n",
       "             ('am', 156),\n",
       "             ('habit', 26),\n",
       "             ('begin', 52),\n",
       "             ('grow', 52),\n",
       "             ('hazy', 26),\n",
       "             ('eyes', 182),\n",
       "             ('conscious', 26),\n",
       "             ('lungs', 26),\n",
       "             ('mean', 130),\n",
       "             ('inferred', 52),\n",
       "             ('needs', 52),\n",
       "             ('rag', 26),\n",
       "             ('something', 312),\n",
       "             ('besides', 156),\n",
       "             ('passengers', 78),\n",
       "             ('sick', 26),\n",
       "             ('quarrelsome', 26),\n",
       "             (\"don't\", 52),\n",
       "             ('nights', 26),\n",
       "             ('enjoy', 26),\n",
       "             ('themselves', 52),\n",
       "             ('much', 442),\n",
       "             ('general', 26),\n",
       "             ('thing;--no', 26),\n",
       "             ('nor', 78),\n",
       "             ('salt', 26),\n",
       "             ('commodore', 52),\n",
       "             ('captain', 52),\n",
       "             ('cook', 52),\n",
       "             ('abandon', 26),\n",
       "             ('glory', 52),\n",
       "             ('distinction', 26),\n",
       "             ('offices', 26),\n",
       "             ('abominate', 26),\n",
       "             ('honourable', 26),\n",
       "             ('respectable', 26),\n",
       "             ('toils', 26),\n",
       "             ('trials', 26),\n",
       "             ('tribulations', 26),\n",
       "             ('kind', 78),\n",
       "             ('whatsoever', 52),\n",
       "             ('quite', 78),\n",
       "             ('care', 78),\n",
       "             ('taking', 104),\n",
       "             ('barques', 26),\n",
       "             ('brigs', 26),\n",
       "             ('schooners', 26),\n",
       "             ('cook,--though', 26),\n",
       "             ('confess', 52),\n",
       "             ('considerable', 26),\n",
       "             ('being', 390),\n",
       "             ('sort', 494),\n",
       "             ('officer', 52),\n",
       "             ('board', 78),\n",
       "             ('somehow', 78),\n",
       "             ('fancied', 26),\n",
       "             ('broiling', 26),\n",
       "             ('fowls;--though', 26),\n",
       "             ('broiled', 78),\n",
       "             ('judiciously', 26),\n",
       "             ('buttered', 26),\n",
       "             ('judgmatically', 26),\n",
       "             ('salted', 26),\n",
       "             ('peppered', 26),\n",
       "             ('speak', 130),\n",
       "             ('respectfully', 52),\n",
       "             ('reverentially', 26),\n",
       "             ('fowl', 26),\n",
       "             ('than', 390),\n",
       "             ('idolatrous', 26),\n",
       "             ('dotings', 26),\n",
       "             ('egyptians', 26),\n",
       "             ('ibis', 26),\n",
       "             ('roasted', 26),\n",
       "             ('river', 26),\n",
       "             ('horse', 52),\n",
       "             ('mummies', 26),\n",
       "             ('creatures', 26),\n",
       "             ('huge', 52),\n",
       "             ('bake', 26),\n",
       "             ('houses', 52),\n",
       "             ('pyramids', 26),\n",
       "             ('simple', 26),\n",
       "             ('sailor', 156),\n",
       "             ('mast', 78),\n",
       "             ('plumb', 26),\n",
       "             ('forecastle', 52),\n",
       "             ('royal', 26),\n",
       "             ('true', 104),\n",
       "             ('rather', 208),\n",
       "             ('order', 130),\n",
       "             ('make', 260),\n",
       "             ('jump', 52),\n",
       "             ('spar', 52),\n",
       "             ('grasshopper', 26),\n",
       "             ('may', 312),\n",
       "             ('thing', 104),\n",
       "             ('unpleasant', 26),\n",
       "             ('enough', 338),\n",
       "             ('touches', 26),\n",
       "             ('sense', 78),\n",
       "             ('honour', 26),\n",
       "             ('particularly', 52),\n",
       "             ('established', 26),\n",
       "             ('family', 26),\n",
       "             ('van', 26),\n",
       "             ('rensselaers', 26),\n",
       "             ('randolphs', 26),\n",
       "             ('hardicanutes', 26),\n",
       "             ('putting', 52),\n",
       "             ('tar', 52),\n",
       "             ('pot', 26),\n",
       "             ('been', 468),\n",
       "             ('lording', 26),\n",
       "             ('schoolmaster', 52),\n",
       "             ('making', 130),\n",
       "             ('tallest', 26),\n",
       "             ('boys', 52),\n",
       "             ('awe', 26),\n",
       "             ('transition', 52),\n",
       "             ('keen', 26),\n",
       "             ('assure', 26),\n",
       "             ('decoction', 26),\n",
       "             ('seneca', 26),\n",
       "             ('stoics', 26),\n",
       "             ('enable', 26),\n",
       "             ('grin', 52),\n",
       "             ('bear', 52),\n",
       "             ('even', 130),\n",
       "             ('wears', 26),\n",
       "             ('hunks', 52),\n",
       "             ('orders', 26),\n",
       "             ('broom', 26),\n",
       "             ('sweep', 52),\n",
       "             ('decks', 26),\n",
       "             ('indignity', 26),\n",
       "             ('amount', 26),\n",
       "             ('weighed', 52),\n",
       "             ('scales', 26),\n",
       "             ('new', 286),\n",
       "             ('testament', 26),\n",
       "             ('think', 182),\n",
       "             ('archangel', 26),\n",
       "             ('gabriel', 26),\n",
       "             ('thinks', 182),\n",
       "             ('anything', 52),\n",
       "             ('less', 52),\n",
       "             ('promptly', 26),\n",
       "             ('obey', 26),\n",
       "             ('instance', 26),\n",
       "             ('ai', 104),\n",
       "             (\"n't\", 624),\n",
       "             ('slave', 26),\n",
       "             ('well', 208),\n",
       "             ('however', 208),\n",
       "             ('captains', 26),\n",
       "             ('thump', 52),\n",
       "             ('punch', 26),\n",
       "             ('satisfaction', 26),\n",
       "             ('knowing', 78),\n",
       "             ('everybody', 26),\n",
       "             ('else', 208),\n",
       "             ('served', 26),\n",
       "             ('either', 78),\n",
       "             ('physical', 26),\n",
       "             ('point', 52),\n",
       "             ('view', 52),\n",
       "             ('so', 1066),\n",
       "             ('universal', 26),\n",
       "             ('passed', 78),\n",
       "             ('hands', 78),\n",
       "             ('rub', 26),\n",
       "             ('shoulder', 26),\n",
       "             ('blades', 26),\n",
       "             ('again', 286),\n",
       "             ('always', 104),\n",
       "             ('paying', 78),\n",
       "             ('trouble', 26),\n",
       "             ('whereas', 26),\n",
       "             ('pay', 78),\n",
       "             ('single', 52),\n",
       "             ('penny', 78),\n",
       "             ('heard', 208),\n",
       "             ('contrary', 26),\n",
       "             ('difference', 52),\n",
       "             ('between', 234),\n",
       "             ('paid', 26),\n",
       "             ('act', 52),\n",
       "             ('perhaps', 130),\n",
       "             ('uncomfortable', 52),\n",
       "             ('infliction', 26),\n",
       "             ('orchard', 26),\n",
       "             ('thieves', 26),\n",
       "             ('entailed', 26),\n",
       "             ('us', 104),\n",
       "             ('paid,--what', 26),\n",
       "             ('compare', 52),\n",
       "             ('urbane', 26),\n",
       "             ('activity', 26),\n",
       "             ('receives', 26),\n",
       "             ('really', 104),\n",
       "             ('marvellous', 104),\n",
       "             ('considering', 26),\n",
       "             ('earnestly', 26),\n",
       "             ('believe', 26),\n",
       "             ('root', 26),\n",
       "             ('earthly', 52),\n",
       "             ('ills', 26),\n",
       "             ('monied', 26),\n",
       "             ('enter', 52),\n",
       "             ('heaven', 104),\n",
       "             ('ah', 26),\n",
       "             ('cheerfully', 26),\n",
       "             ('consign', 26),\n",
       "             ('perdition', 26),\n",
       "             ('finally', 26),\n",
       "             ('wholesome', 26),\n",
       "             ('exercise', 26),\n",
       "             ('pure', 26),\n",
       "             ('air', 104),\n",
       "             ('fore', 26),\n",
       "             ('castle', 26),\n",
       "             ('deck', 52),\n",
       "             ('far', 104),\n",
       "             ('prevalent', 26),\n",
       "             ('astern', 26),\n",
       "             ('violate', 26),\n",
       "             ('pythagorean', 26),\n",
       "             ('maxim', 26),\n",
       "             ('quarter', 52),\n",
       "             ('gets', 26),\n",
       "             ('atmosphere', 26),\n",
       "             ('second', 104),\n",
       "             ('sailors', 78),\n",
       "             ('breathes', 26),\n",
       "             ('commonalty', 26),\n",
       "             ('leaders', 52),\n",
       "             ('many', 104),\n",
       "             ('things', 130),\n",
       "             ('suspect', 26),\n",
       "             ('wherefore', 26),\n",
       "             ('after', 234),\n",
       "             ('repeatedly', 26),\n",
       "             ('smelt', 52),\n",
       "             ('merchant', 26),\n",
       "             ('whaling', 234),\n",
       "             ('invisible', 26),\n",
       "             ('police', 26),\n",
       "             ('fates', 52),\n",
       "             ('has', 104),\n",
       "             ('constant', 26),\n",
       "             ('surveillance', 26),\n",
       "             ('secretly', 26),\n",
       "             ('dogs', 26),\n",
       "             ('influences', 26),\n",
       "             ('unaccountable', 104),\n",
       "             ('answer', 130),\n",
       "             ('doubtless', 52),\n",
       "             ('formed', 52),\n",
       "             ('grand', 104),\n",
       "             ('programme', 26),\n",
       "             ('providence', 26),\n",
       "             ('drawn', 26),\n",
       "             ('came', 286),\n",
       "             ('brief', 26),\n",
       "             ('interlude', 26),\n",
       "             ('solo', 26),\n",
       "             ('extensive', 26),\n",
       "             ('performances', 26),\n",
       "             ('bill', 26),\n",
       "             ('run', 52),\n",
       "             ('contested', 26),\n",
       "             ('election', 26),\n",
       "             ('presidency', 26),\n",
       "             ('united', 26),\n",
       "             ('states', 26),\n",
       "             ('bloody', 26),\n",
       "             ('battle', 26),\n",
       "             ('affghanistan', 26),\n",
       "             ('exactly', 78),\n",
       "             ('stage', 52),\n",
       "             ('managers', 26),\n",
       "             ('put', 208),\n",
       "             ('shabby', 52),\n",
       "             ('others', 52),\n",
       "             ('magnificent', 26),\n",
       "             ('parts', 130),\n",
       "             ('tragedies', 26),\n",
       "             ('short', 78),\n",
       "             ('easy', 78),\n",
       "             ('genteel', 26),\n",
       "             ('comedies', 26),\n",
       "             ('jolly', 104),\n",
       "             ('farces', 26),\n",
       "             ('recall', 26),\n",
       "             ('circumstances', 52),\n",
       "             ('springs', 26),\n",
       "             ('motives', 52),\n",
       "             ('cunningly', 26),\n",
       "             ('presented', 26),\n",
       "             ('various', 52),\n",
       "             ('disguises', 26),\n",
       "             ('induced', 26),\n",
       "             ('performing', 26),\n",
       "             ('cajoling', 26),\n",
       "             ('delusion', 26),\n",
       "             ('choice', 26),\n",
       "             ('resulting', 26),\n",
       "             ('unbiased', 26),\n",
       "             ('freewill', 26),\n",
       "             ('discriminating', 26),\n",
       "             ('judgment', 26),\n",
       "             ('overwhelming', 26),\n",
       "             ('idea', 182),\n",
       "             ('whale', 260),\n",
       "             ('portentous', 78),\n",
       "             ('mysterious', 52),\n",
       "             ('monster', 26),\n",
       "             ('roused', 26),\n",
       "             ('curiosity', 52),\n",
       "             ('wild', 130),\n",
       "             ('seas', 156),\n",
       "             ('rolled', 156),\n",
       "             ('island', 78),\n",
       "             ('bulk', 26),\n",
       "             ('undeliverable', 26),\n",
       "             ('nameless', 78),\n",
       "             ('perils', 26),\n",
       "             ('attending', 26),\n",
       "             ('marvels', 26),\n",
       "             ('patagonian', 26),\n",
       "             ('sights', 26),\n",
       "             ('sounds', 78),\n",
       "             ('helped', 26),\n",
       "             ('sway', 26),\n",
       "             ('wish', 26),\n",
       "             ('inducements', 26),\n",
       "             ('tormented', 52),\n",
       "             ('everlasting', 52),\n",
       "             ('itch', 26),\n",
       "             ('remote', 26),\n",
       "             ('love', 26),\n",
       "             ('forbidden', 26),\n",
       "             ('barbarous', 26),\n",
       "             ('coasts', 26),\n",
       "             ('ignoring', 26),\n",
       "             ('good', 442),\n",
       "             ('quick', 26),\n",
       "             ('perceive', 26),\n",
       "             ('horror', 26),\n",
       "             ('social', 26),\n",
       "             ('since', 78),\n",
       "             ('friendly', 26),\n",
       "             ('terms', 26),\n",
       "             ('inmates', 26),\n",
       "             ('place', 390),\n",
       "             ('lodges', 26),\n",
       "             ('reason', 130),\n",
       "             ('welcome', 26),\n",
       "             ('flood', 26),\n",
       "             ('gates', 26),\n",
       "             ('wonder', 52),\n",
       "             ('swung', 26),\n",
       "             ('open', 104),\n",
       "             ('conceits', 26),\n",
       "             ('swayed', 26),\n",
       "             ('purpose', 52),\n",
       "             ('floated', 52),\n",
       "             ('inmost', 26),\n",
       "             ('endless', 26),\n",
       "             ('processions', 26),\n",
       "             ('mid', 26),\n",
       "             ('hooded', 26),\n",
       "             ('snow', 78),\n",
       "             ('stuffed', 52),\n",
       "             ('shirt', 104),\n",
       "             ('carpet', 26),\n",
       "             ('bag', 182),\n",
       "             ('tucked', 26),\n",
       "             ('arm', 286),\n",
       "             ('started', 26),\n",
       "             ('cape', 104),\n",
       "             ('horn', 52),\n",
       "             ('pacific', 26),\n",
       "             ('quitting', 26),\n",
       "             ('manhatto', 26),\n",
       "             ('duly', 26),\n",
       "             ('arrived', 52),\n",
       "             ('bedford', 104),\n",
       "             ('saturday', 78),\n",
       "             ('night', 624),\n",
       "             ('december', 26),\n",
       "             ('disappointed', 26),\n",
       "             ('learning', 26),\n",
       "             ('packet', 26),\n",
       "             ('nantucket', 182),\n",
       "             ('had', 858),\n",
       "             ('already', 26),\n",
       "             ('sailed', 26),\n",
       "             ('offer', 52),\n",
       "             ('till', 156),\n",
       "             ('following', 52),\n",
       "             ('monday', 26),\n",
       "             ('young', 130),\n",
       "             ('candidates', 26),\n",
       "             ('pains', 26),\n",
       "             ('penalties', 26),\n",
       "             ('stop', 208),\n",
       "             ('embark', 52),\n",
       "             ('related', 26),\n",
       "             ('doing', 26),\n",
       "             ('made', 338),\n",
       "             ('craft', 130),\n",
       "             ('fine', 104),\n",
       "             ('boisterous', 26),\n",
       "             ('everything', 26),\n",
       "             ('connected', 26),\n",
       "             ('famous', 26),\n",
       "             ('amazingly', 26),\n",
       "             ('pleased', 52),\n",
       "             ('late', 182),\n",
       "             ('gradually', 26),\n",
       "             ('monopolising', 26),\n",
       "             ('business', 130),\n",
       "             ('matter', 78),\n",
       "             ('behind', 26),\n",
       "             ('original', 52),\n",
       "             ('tyre', 26),\n",
       "             ('carthage;--the', 26),\n",
       "             ('dead', 130),\n",
       "             ('stranded', 52),\n",
       "             ('aboriginal', 26),\n",
       "             ('whalemen', 26),\n",
       "             ('red', 78),\n",
       "             ('sally', 26),\n",
       "             ('canoes', 26),\n",
       "             ('chase', 26),\n",
       "             ('leviathan', 52),\n",
       "             ('too', 364),\n",
       "             ('adventurous', 26),\n",
       "             ('sloop', 26),\n",
       "             ('forth', 26),\n",
       "             ('partly', 78),\n",
       "             ('laden', 26),\n",
       "             ('imported', 26),\n",
       "             ('cobblestones', 26),\n",
       "             ('throw', 26),\n",
       "             ('whales', 52),\n",
       "             ('discover', 26),\n",
       "             ('risk', 26),\n",
       "             ('harpoon', 135),\n",
       "             ('bowsprit', 26),\n",
       "             ('day', 156),\n",
       "             ('another', 130),\n",
       "             ('ere', 78),\n",
       "             ('destined', 26),\n",
       "             ('port', 26),\n",
       "             ('became', 78),\n",
       "             ('concernment', 26),\n",
       "             ('eat', 26),\n",
       "             ('meanwhile', 78),\n",
       "             ('dubious', 26),\n",
       "             ('nay', 52),\n",
       "             ('dark', 208),\n",
       "             ('dismal', 52),\n",
       "             ('bitingly', 26),\n",
       "             ('cold', 182),\n",
       "             ('cheerless', 26),\n",
       "             ('anxious', 26),\n",
       "             ('grapnels', 26),\n",
       "             ('sounded', 26),\n",
       "             ('pocket', 78),\n",
       "             ('only', 364),\n",
       "             ('brought', 26),\n",
       "             ('pieces', 26),\n",
       "             ('silver,--so', 26),\n",
       "             ('wherever', 52),\n",
       "             ('said', 494),\n",
       "             ('stood', 260),\n",
       "             ('middle', 130),\n",
       "             ('dreary', 52),\n",
       "             ('shouldering', 26),\n",
       "             ('comparing', 26),\n",
       "             ('gloom', 26),\n",
       "             ('darkness', 78),\n",
       "             ('wisdom', 26),\n",
       "             ('conclude', 26),\n",
       "             ('lodge', 26),\n",
       "             ('dear', 26),\n",
       "             ('sure', 130),\n",
       "             ('inquire', 26),\n",
       "             ('price', 26),\n",
       "             ('halting', 26),\n",
       "             ('steps', 26),\n",
       "             ('paced', 26),\n",
       "             ('sign', 156),\n",
       "             ('crossed', 52),\n",
       "             ('harpoons\"--but', 26),\n",
       "             ('looked', 156),\n",
       "             ('expensive', 52),\n",
       "             ('further', 104),\n",
       "             ('bright', 52),\n",
       "             ('windows', 52),\n",
       "             ('fish', 78),\n",
       "             ('inn', 78),\n",
       "             ('fervent', 26),\n",
       "             ('rays', 26),\n",
       "             ('seemed', 416),\n",
       "             ('melted', 26),\n",
       "             ('packed', 52),\n",
       "             ('ice', 104),\n",
       "             ('house', 286),\n",
       "             ('everywhere', 26),\n",
       "             ('congealed', 26),\n",
       "             ('frost', 104),\n",
       "             ('lay', 234),\n",
       "             ('inches', 52),\n",
       "             ('thick', 52),\n",
       "             ...])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2717"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ..., 2712,   14,   24],\n",
       "       [  14,  263,   51, ...,   14,   24,  957],\n",
       "       [ 263,   51,  261, ...,   24,  957,    5],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,  262,   53,    2],\n",
       "       [  12,  166, 2711, ...,   53,    2, 2717],\n",
       "       [ 166, 2711,    3, ...,    2, 2717,   26]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y,num_classes=vocabulary_size+1)\n",
    "# +1 needed to hold a azero..this is how keras padding works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ...,    6, 2712,   14],\n",
       "       [  14,  263,   51, ..., 2712,   14,   24],\n",
       "       [ 263,   51,  261, ...,   14,   24,  957],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,   11,  262,   53],\n",
       "       [  12,  166, 2711, ...,  262,   53,    2],\n",
       "       [ 166, 2711,    3, ...,   53,    2, 2717]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312, 25)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312, 25)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size,seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size,seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    \n",
    "    model.add(Dense(vocabulary_size,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            67950     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 25, 50)            15200     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2718)              138618    \n",
      "=================================================================\n",
      "Total params: 244,518\n",
      "Trainable params: 244,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "89/89 [==============================] - 5s 61ms/step - loss: 6.9763 - accuracy: 0.0490\n",
      "Epoch 2/2\n",
      "89/89 [==============================] - 6s 66ms/step - loss: 6.3782 - accuracy: 0.0529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ef2448a08>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model training\n",
    "model.fit(X,y,batch_size=128,epochs = 2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_mobydick_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer,open('my_simple_tokenizer','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in NLP.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main c1607f6] New code push\n",
      " 1 file changed, 275 insertions(+), 41 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in NLP.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "To https://github.com/Ashishkhurana01/NLP.git\n",
      "   d42ef9c..c1607f6  main -> main\n"
     ]
    }
   ],
   "source": [
    "! git fetch\n",
    "! git add test.txt\n",
    "! git add NLP.ipynb\n",
    "! git commit -m \"New code push\" NLP.ipynb\n",
    "! git push origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
